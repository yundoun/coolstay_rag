"""
CoolStay RAG ì‹œìŠ¤í…œ ë¬¸ì„œ ì²­í‚¹ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œë¥¼ ë‹¤ì–‘í•œ ì „ëµìœ¼ë¡œ ì²­í‚¹í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import logging
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

from langchain_core.documents import Document
from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter

from ..core.config import config, get_domain_config

logger = logging.getLogger(__name__)


class ChunkingStrategy(Enum):
    """ì²­í‚¹ ì „ëµ íƒ€ì…"""
    HEADER_BASED = "header_based"
    SIZE_BASED = "size_based"
    HYBRID = "hybrid"


@dataclass
class ChunkingResult:
    """ì²­í‚¹ ê²°ê³¼"""
    documents: List[Document]
    strategy: ChunkingStrategy
    total_chunks: int
    avg_chunk_size: float
    min_chunk_size: int
    max_chunk_size: int
    metadata: Dict[str, Any]


class MarkdownChunker:
    """ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ì²­í‚¹ í´ë˜ìŠ¤"""

    def __init__(self):
        self.chunking_config = config.chunking_config
        self.optimal_strategies = config.optimal_chunking_strategies

    def chunk_by_headers(self, content: str, domain: str, metadata: Optional[Dict[str, Any]] = None) -> List[Document]:
        """í—¤ë” ê¸°ë°˜ ì²­í‚¹"""
        try:
            # í—¤ë” ê¸°ë°˜ ë¶„í• ê¸° ì„¤ì •
            markdown_splitter = MarkdownHeaderTextSplitter(
                headers_to_split_on=self.chunking_config.headers_to_split,
                strip_headers=False
            )

            # í—¤ë” ê¸°ë°˜ ì²­í‚¹ ì‹¤í–‰
            md_header_splits = markdown_splitter.split_text(content)

            # ë©”íƒ€ë°ì´í„° ê°•í™”
            enhanced_documents = []
            for i, doc in enumerate(md_header_splits):
                # ê¸°ë³¸ ë©”íƒ€ë°ì´í„°ì™€ ë³‘í•©
                enhanced_metadata = {
                    **doc.metadata,
                    "domain": domain,
                    "chunk_type": ChunkingStrategy.HEADER_BASED.value,
                    "chunk_index": i,
                    "chunk_id": f"{domain}_header_{i}",
                    "content_length": len(doc.page_content),
                    "description": get_domain_config(domain).description,
                    "keywords": get_domain_config(domain).keywords,
                }

                # ì¶”ê°€ ë©”íƒ€ë°ì´í„° ë³‘í•©
                if metadata:
                    enhanced_metadata.update(metadata)

                enhanced_documents.append(
                    Document(
                        page_content=doc.page_content,
                        metadata=enhanced_metadata
                    )
                )

            logger.info(f"âœ… {domain} í—¤ë” ê¸°ë°˜ ì²­í‚¹ ì™„ë£Œ: {len(enhanced_documents)}ê°œ ì²­í¬")
            return enhanced_documents

        except Exception as e:
            logger.error(f"í—¤ë” ê¸°ë°˜ ì²­í‚¹ ì‹¤íŒ¨ {domain}: {e}")
            return []

    def chunk_by_size(self, content: str, domain: str, chunk_size: Optional[int] = None,
                     metadata: Optional[Dict[str, Any]] = None) -> List[Document]:
        """í¬ê¸° ê¸°ë°˜ ì²­í‚¹"""
        try:
            # ì²­í¬ í¬ê¸° ê²°ì • (ë„ë©”ì¸ë³„ ìµœì í™” ë˜ëŠ” ê¸°ë³¸ê°’)
            if chunk_size is None:
                chunk_size = config.get_optimal_chunk_size(domain)

            # RecursiveCharacterTextSplitter ì„¤ì •
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=chunk_size,
                chunk_overlap=self.chunking_config.chunk_overlap,
                length_function=len,
                separators=self.chunking_config.separators
            )

            # ì²­í‚¹ ì‹¤í–‰
            chunks = text_splitter.split_text(content)

            # Document ê°ì²´ë¡œ ë³€í™˜í•˜ë©° ë©”íƒ€ë°ì´í„° ì¶”ê°€
            documents = []
            for i, chunk in enumerate(chunks):
                enhanced_metadata = {
                    "domain": domain,
                    "chunk_type": ChunkingStrategy.SIZE_BASED.value,
                    "chunk_index": i,
                    "chunk_id": f"{domain}_size_{i}",
                    "chunk_size": len(chunk),
                    "target_chunk_size": chunk_size,
                    "content_length": len(chunk),
                    "description": get_domain_config(domain).description,
                    "keywords": get_domain_config(domain).keywords,
                }

                # ì¶”ê°€ ë©”íƒ€ë°ì´í„° ë³‘í•©
                if metadata:
                    enhanced_metadata.update(metadata)

                doc = Document(
                    page_content=chunk,
                    metadata=enhanced_metadata
                )
                documents.append(doc)

            logger.info(f"âœ… {domain} í¬ê¸° ê¸°ë°˜ ì²­í‚¹ ì™„ë£Œ: {len(documents)}ê°œ ì²­í¬ (í¬ê¸°: {chunk_size})")
            return documents

        except Exception as e:
            logger.error(f"í¬ê¸° ê¸°ë°˜ ì²­í‚¹ ì‹¤íŒ¨ {domain}: {e}")
            return []

    def chunk_hybrid(self, content: str, domain: str, metadata: Optional[Dict[str, Any]] = None) -> List[Document]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì²­í‚¹ (í—¤ë” + í¬ê¸° ê¸°ë°˜)"""
        try:
            # 1ë‹¨ê³„: í—¤ë” ê¸°ë°˜ ì²­í‚¹
            header_chunks = self.chunk_by_headers(content, domain, metadata)

            # 2ë‹¨ê³„: í° ì²­í¬ë“¤ì„ í¬ê¸° ê¸°ë°˜ìœ¼ë¡œ ì¬ë¶„í• 
            final_documents = []
            max_size = config.get_optimal_chunk_size(domain)

            for i, doc in enumerate(header_chunks):
                if len(doc.page_content) <= max_size:
                    # ì ì ˆí•œ í¬ê¸°ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
                    doc.metadata["chunk_type"] = ChunkingStrategy.HYBRID.value
                    doc.metadata["sub_chunk_index"] = 0
                    final_documents.append(doc)
                else:
                    # í° ì²­í¬ëŠ” ì¶”ê°€ ë¶„í• 
                    size_chunks = self.chunk_by_size(
                        doc.page_content,
                        domain,
                        chunk_size=max_size,
                        metadata=doc.metadata
                    )

                    # í•˜ì´ë¸Œë¦¬ë“œ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                    for j, size_chunk in enumerate(size_chunks):
                        size_chunk.metadata.update({
                            "chunk_type": ChunkingStrategy.HYBRID.value,
                            "parent_chunk_index": i,
                            "sub_chunk_index": j,
                            "chunk_id": f"{domain}_hybrid_{i}_{j}"
                        })
                        final_documents.append(size_chunk)

            logger.info(f"âœ… {domain} í•˜ì´ë¸Œë¦¬ë“œ ì²­í‚¹ ì™„ë£Œ: {len(final_documents)}ê°œ ì²­í¬")
            return final_documents

        except Exception as e:
            logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ì²­í‚¹ ì‹¤íŒ¨ {domain}: {e}")
            return []

    def chunk_with_strategy(self, content: str, domain: str, strategy: ChunkingStrategy,
                           chunk_size: Optional[int] = None,
                           metadata: Optional[Dict[str, Any]] = None) -> List[Document]:
        """ì „ëµë³„ ì²­í‚¹ ì‹¤í–‰"""
        if strategy == ChunkingStrategy.HEADER_BASED:
            return self.chunk_by_headers(content, domain, metadata)
        elif strategy == ChunkingStrategy.SIZE_BASED:
            return self.chunk_by_size(content, domain, chunk_size, metadata)
        elif strategy == ChunkingStrategy.HYBRID:
            return self.chunk_hybrid(content, domain, metadata)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì²­í‚¹ ì „ëµ: {strategy}")

    def chunk_with_optimal_strategy(self, content: str, domain: str,
                                  metadata: Optional[Dict[str, Any]] = None) -> List[Document]:
        """ë„ë©”ì¸ë³„ ìµœì  ì „ëµìœ¼ë¡œ ì²­í‚¹"""
        optimal_config = self.optimal_strategies.get(domain, {})
        strategy_name = optimal_config.get("strategy", "size_based")
        chunk_size = optimal_config.get("chunk_size", config.chunking_config.chunk_size)

        try:
            strategy = ChunkingStrategy(strategy_name)
        except ValueError:
            logger.warning(f"ì˜ëª»ëœ ì „ëµ {strategy_name}, size_basedë¡œ ëŒ€ì²´")
            strategy = ChunkingStrategy.SIZE_BASED

        return self.chunk_with_strategy(content, domain, strategy, chunk_size, metadata)

    def analyze_chunks(self, documents: List[Document], strategy: ChunkingStrategy) -> ChunkingResult:
        """ì²­í‚¹ ê²°ê³¼ ë¶„ì„"""
        if not documents:
            return ChunkingResult(
                documents=documents,
                strategy=strategy,
                total_chunks=0,
                avg_chunk_size=0.0,
                min_chunk_size=0,
                max_chunk_size=0,
                metadata={}
            )

        chunk_sizes = [len(doc.page_content) for doc in documents]

        return ChunkingResult(
            documents=documents,
            strategy=strategy,
            total_chunks=len(documents),
            avg_chunk_size=sum(chunk_sizes) / len(chunk_sizes),
            min_chunk_size=min(chunk_sizes),
            max_chunk_size=max(chunk_sizes),
            metadata={
                "domain": documents[0].metadata.get("domain", "unknown"),
                "total_content_length": sum(chunk_sizes),
                "chunk_distribution": self._analyze_chunk_distribution(chunk_sizes)
            }
        )

    def _analyze_chunk_distribution(self, chunk_sizes: List[int]) -> Dict[str, int]:
        """ì²­í¬ í¬ê¸° ë¶„í¬ ë¶„ì„"""
        distribution = {
            "very_small": 0,    # < 200
            "small": 0,         # 200-500
            "medium": 0,        # 500-1000
            "large": 0,         # 1000-1500
            "very_large": 0     # > 1500
        }

        for size in chunk_sizes:
            if size < 200:
                distribution["very_small"] += 1
            elif size < 500:
                distribution["small"] += 1
            elif size < 1000:
                distribution["medium"] += 1
            elif size < 1500:
                distribution["large"] += 1
            else:
                distribution["very_large"] += 1

        return distribution


class ChunkingExperiment:
    """ì²­í‚¹ ì „ëµ ì‹¤í—˜ í´ë˜ìŠ¤"""

    def __init__(self):
        self.chunker = MarkdownChunker()

    def compare_strategies(self, content: str, domain: str, chunk_sizes: List[int] = None) -> Dict[str, ChunkingResult]:
        """ì—¬ëŸ¬ ì „ëµ ë¹„êµ ì‹¤í—˜"""
        if chunk_sizes is None:
            chunk_sizes = [800, 1000, 1200, 1500]

        results = {}

        # í—¤ë” ê¸°ë°˜ ì²­í‚¹
        try:
            header_docs = self.chunker.chunk_by_headers(content, domain)
            results["header_based"] = self.chunker.analyze_chunks(header_docs, ChunkingStrategy.HEADER_BASED)
        except Exception as e:
            logger.error(f"í—¤ë” ê¸°ë°˜ ì‹¤í—˜ ì‹¤íŒ¨: {e}")

        # ë‹¤ì–‘í•œ í¬ê¸°ë¡œ í¬ê¸° ê¸°ë°˜ ì²­í‚¹
        for size in chunk_sizes:
            try:
                size_docs = self.chunker.chunk_by_size(content, domain, chunk_size=size)
                results[f"size_{size}"] = self.chunker.analyze_chunks(size_docs, ChunkingStrategy.SIZE_BASED)
            except Exception as e:
                logger.error(f"í¬ê¸° ê¸°ë°˜ ì‹¤í—˜ ì‹¤íŒ¨ (í¬ê¸°: {size}): {e}")

        # í•˜ì´ë¸Œë¦¬ë“œ ì²­í‚¹
        try:
            hybrid_docs = self.chunker.chunk_hybrid(content, domain)
            results["hybrid"] = self.chunker.analyze_chunks(hybrid_docs, ChunkingStrategy.HYBRID)
        except Exception as e:
            logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ì‹¤í—˜ ì‹¤íŒ¨: {e}")

        return results

    def find_optimal_strategy(self, content: str, domain: str) -> Tuple[str, ChunkingResult]:
        """ìµœì  ì²­í‚¹ ì „ëµ ì°¾ê¸°"""
        results = self.compare_strategies(content, domain)

        if not results:
            return "size_1000", ChunkingResult([], ChunkingStrategy.SIZE_BASED, 0, 0.0, 0, 0, {})

        # í‰ê°€ ê¸°ì¤€ìœ¼ë¡œ ìµœì  ì „ëµ ì„ íƒ
        best_strategy = None
        best_score = float('inf')

        for strategy_name, result in results.items():
            if result.total_chunks == 0:
                continue

            # ì ìˆ˜ ê³„ì‚° (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            # 1. ì²­í¬ ìˆ˜ê°€ ë„ˆë¬´ ë§ê±°ë‚˜ ì ìœ¼ë©´ íŒ¨ë„í‹°
            chunk_count_penalty = abs(result.total_chunks - 10) * 0.5

            # 2. í‰ê·  í¬ê¸°ê°€ 800-1200 ë²”ìœ„ì—ì„œ ë²—ì–´ë‚˜ë©´ íŒ¨ë„í‹°
            size_penalty = max(0, abs(result.avg_chunk_size - 1000) - 200) * 0.01

            # 3. í¬ê¸° í¸ì°¨ê°€ í´ìˆ˜ë¡ íŒ¨ë„í‹°
            variance_penalty = (result.max_chunk_size - result.min_chunk_size) * 0.001

            total_score = chunk_count_penalty + size_penalty + variance_penalty

            if total_score < best_score:
                best_score = total_score
                best_strategy = strategy_name

        return best_strategy or "size_1000", results.get(best_strategy, results[list(results.keys())[0]])

    def print_comparison_results(self, results: Dict[str, ChunkingResult]) -> None:
        """ë¹„êµ ê²°ê³¼ ì¶œë ¥"""
        print("\nğŸ“Š ì²­í‚¹ ì „ëµ ë¹„êµ ê²°ê³¼")
        print("=" * 80)
        print(f"{'ì „ëµ':<15} {'ì²­í¬ìˆ˜':<8} {'í‰ê· í¬ê¸°':<10} {'ìµœì†Œí¬ê¸°':<10} {'ìµœëŒ€í¬ê¸°':<10} {'ë¶„ì‚°':<10}")
        print("-" * 80)

        for strategy_name, result in results.items():
            if result.total_chunks > 0:
                variance = result.max_chunk_size - result.min_chunk_size
                print(f"{strategy_name:<15} {result.total_chunks:<8} "
                      f"{result.avg_chunk_size:<10.0f} {result.min_chunk_size:<10} "
                      f"{result.max_chunk_size:<10} {variance:<10}")


# í¸ì˜ í•¨ìˆ˜ë“¤
def chunk_document(content: str, domain: str, strategy: str = "optimal",
                  chunk_size: Optional[int] = None) -> List[Document]:
    """ë¬¸ì„œ ì²­í‚¹ í¸ì˜ í•¨ìˆ˜"""
    chunker = MarkdownChunker()

    if strategy == "optimal":
        return chunker.chunk_with_optimal_strategy(content, domain)
    elif strategy == "header":
        return chunker.chunk_by_headers(content, domain)
    elif strategy == "size":
        return chunker.chunk_by_size(content, domain, chunk_size)
    elif strategy == "hybrid":
        return chunker.chunk_hybrid(content, domain)
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì „ëµ: {strategy}")


def analyze_chunking_quality(documents: List[Document]) -> Dict[str, Any]:
    """ì²­í‚¹ í’ˆì§ˆ ë¶„ì„ í¸ì˜ í•¨ìˆ˜"""
    if not documents:
        return {"error": "ë¹ˆ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸"}

    chunker = MarkdownChunker()
    strategy = ChunkingStrategy(documents[0].metadata.get("chunk_type", "size_based"))
    result = chunker.analyze_chunks(documents, strategy)

    return {
        "total_chunks": result.total_chunks,
        "avg_chunk_size": result.avg_chunk_size,
        "min_chunk_size": result.min_chunk_size,
        "max_chunk_size": result.max_chunk_size,
        "strategy": result.strategy.value,
        "chunk_distribution": result.metadata.get("chunk_distribution", {}),
        "quality_score": _calculate_quality_score(result)
    }


def _calculate_quality_score(result: ChunkingResult) -> float:
    """ì²­í‚¹ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0-100, ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)"""
    if result.total_chunks == 0:
        return 0.0

    # ê¸°ë³¸ ì ìˆ˜
    score = 100.0

    # ì²­í¬ ìˆ˜ íŒ¨ë„í‹° (ë„ˆë¬´ ë§ê±°ë‚˜ ì ìœ¼ë©´ ê°ì )
    ideal_chunk_count = 15
    chunk_penalty = abs(result.total_chunks - ideal_chunk_count) * 2
    score -= min(chunk_penalty, 30)

    # í¬ê¸° ì¼ê´€ì„± ì ìˆ˜ (í¸ì°¨ê°€ ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ)
    size_variance = result.max_chunk_size - result.min_chunk_size
    variance_penalty = min(size_variance / 100, 30)
    score -= variance_penalty

    # ì ì • í¬ê¸° ì ìˆ˜ (800-1200ì´ ì´ìƒì )
    avg_size = result.avg_chunk_size
    if 800 <= avg_size <= 1200:
        size_bonus = 10
    else:
        size_penalty = abs(avg_size - 1000) / 100
        size_bonus = -min(size_penalty, 20)
    score += size_bonus

    return max(0.0, min(100.0, score))


if __name__ == "__main__":
    # ì²­í‚¹ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
    print("âœ‚ï¸ CoolStay ì²­í‚¹ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    # ìƒ˜í”Œ ë§ˆí¬ë‹¤ìš´ ë‚´ìš©
    sample_content = """
# í…ŒìŠ¤íŠ¸ ë¬¸ì„œ

## ì„¹ì…˜ 1
ì´ê²ƒì€ ì²« ë²ˆì§¸ ì„¹ì…˜ì…ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ì—¬ëŸ¬ ì¤„ì˜ í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

### í•˜ìœ„ ì„¹ì…˜ 1.1
ë” ì„¸ë¶€ì ì¸ ë‚´ìš©ì´ ì—¬ê¸°ì— ìˆìŠµë‹ˆë‹¤.

## ì„¹ì…˜ 2
ë‘ ë²ˆì§¸ ì„¹ì…˜ì…ë‹ˆë‹¤. ì´ ì„¹ì…˜ì€ ì¡°ê¸ˆ ë” ê¸´ ë‚´ìš©ì„ í¬í•¨í•©ë‹ˆë‹¤.
ì—¬ëŸ¬ ì¤„ì— ê±¸ì³ ì‘ì„±ëœ ë‚´ìš©ìœ¼ë¡œ ì²­í‚¹ í…ŒìŠ¤íŠ¸ì— ì í•©í•©ë‹ˆë‹¤.

### í•˜ìœ„ ì„¹ì…˜ 2.1
ë˜ ë‹¤ë¥¸ í•˜ìœ„ ì„¹ì…˜ì…ë‹ˆë‹¤.

### í•˜ìœ„ ì„¹ì…˜ 2.2
ë§ˆì§€ë§‰ í•˜ìœ„ ì„¹ì…˜ì…ë‹ˆë‹¤.
"""

    # ì²­í‚¹ ì‹¤í—˜ ì‹¤í–‰
    experiment = ChunkingExperiment()
    results = experiment.compare_strategies(sample_content, "test_domain")

    if results:
        experiment.print_comparison_results(results)

        # ìµœì  ì „ëµ ì°¾ê¸°
        best_strategy, best_result = experiment.find_optimal_strategy(sample_content, "test_domain")
        print(f"\nğŸ¯ ìµœì  ì „ëµ: {best_strategy}")
        print(f"   - ì²­í¬ ìˆ˜: {best_result.total_chunks}")
        print(f"   - í‰ê·  í¬ê¸°: {best_result.avg_chunk_size:.0f}ì")
        print(f"   - í’ˆì§ˆ ì ìˆ˜: {_calculate_quality_score(best_result):.1f}/100")
    else:
        print("âŒ ì²­í‚¹ ì‹¤í—˜ ì‹¤íŒ¨")