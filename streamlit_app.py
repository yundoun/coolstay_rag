"""
CoolStay RAG ì‹œìŠ¤í…œ Streamlit ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜

Phase 3: ì„œë¹„ìŠ¤í™” - ì‚¬ìš©ì ì¹œí™”ì ì¸ ì›¹ ì¸í„°í˜ì´ìŠ¤ ì œê³µ
"""

import streamlit as st
import asyncio
import json
import time
from datetime import datetime
from pathlib import Path
import sys
from typing import Optional, Dict, Any, List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ¯ CoolStay RAG Assistant",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #FFB800 0%, #FFA000 100%);
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        text-align: center;
    }
    .status-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #28a745;
        margin: 1rem 0;
    }
    .error-card {
        background: #fff3cd;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #ffc107;
        margin: 1rem 0;
    }
    .success-message {
        color: #28a745;
        font-weight: bold;
    }
    .error-message {
        color: #dc3545;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)


class StreamlitRAGApp:
    """Streamlit RAG ì• í”Œë¦¬ì¼€ì´ì…˜"""

    def __init__(self):
        self.initialize_session_state()

    def initialize_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'messages' not in st.session_state:
            st.session_state.messages = []

        if 'system_initialized' not in st.session_state:
            st.session_state.system_initialized = False

        if 'system_status' not in st.session_state:
            st.session_state.system_status = None

        if 'chat_history' not in st.session_state:
            st.session_state.chat_history = []

        if 'evaluation_counter' not in st.session_state:
            st.session_state.evaluation_counter = 0

    def check_system_dependencies(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ì˜ì¡´ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤"""
        status = {
            "overall_status": "unknown",
            "modules": {},
            "dependencies": {},
            "recommendations": [],
            "vectordb_init": None
        }

        # í•µì‹¬ ëª¨ë“ˆ í™•ì¸
        try:
            from src.core.config import CoolStayConfig
            config = CoolStayConfig()
            status["modules"]["core"] = {"status": "âœ…", "message": "ì •ìƒ"}
            status["config"] = {
                "domains": len(config.get_domains()),
                "data_dir": str(config.data_dir)
            }

            # ë²¡í„° DB ìë™ ì´ˆê¸°í™” (Streamlit Cloudì—ì„œ)
            try:
                from src.utils.cloud_init import initialize_vectordb_if_needed, is_cloud_environment

                if is_cloud_environment():
                    st.info("â˜ï¸ Streamlit Cloud í™˜ê²½ ê°ì§€: ë²¡í„° DB ì´ˆê¸°í™” ì¤‘...")
                    init_result = initialize_vectordb_if_needed(config)
                    status["vectordb_init"] = init_result

                    if init_result["initialized"]:
                        st.success(f"âœ… {init_result['message']}")
                    elif init_result["errors"]:
                        st.warning(f"âš ï¸ ì¼ë¶€ ì´ˆê¸°í™” ì‹¤íŒ¨: {len(init_result['errors'])}ê°œ ì˜¤ë¥˜")
            except Exception as e:
                st.warning(f"âš ï¸ ë²¡í„° DB ìë™ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

        except Exception as e:
            status["modules"]["core"] = {"status": "âŒ", "message": f"ì˜¤ë¥˜: {str(e)}"}

        # LLM ëª¨ë“ˆ í™•ì¸
        try:
            from src.core.llm import get_default_llm
            llm = get_default_llm()
            if llm.is_initialized:
                status["modules"]["llm"] = {"status": "âœ…", "message": f"ëª¨ë¸: {llm.model_name}"}
            else:
                status["modules"]["llm"] = {"status": "âš ï¸", "message": "ì´ˆê¸°í™” ëŒ€ê¸° ì¤‘"}
        except Exception as e:
            status["modules"]["llm"] = {"status": "âŒ", "message": f"ì˜¤ë¥˜: {str(e)}"}
            if "langchain" in str(e).lower():
                status["dependencies"]["langchain"] = "âŒ ì„¤ì¹˜ í•„ìš”"

        # í‰ê°€ ëª¨ë“ˆ í™•ì¸
        try:
            from src.evaluation import ReActEvaluationAgent
            evaluator = ReActEvaluationAgent()
            status["modules"]["evaluation"] = {"status": "âœ…", "message": "ReAct í‰ê°€ ì‹œìŠ¤í…œ"}
        except Exception as e:
            status["modules"]["evaluation"] = {"status": "âŒ", "message": f"ì˜¤ë¥˜: {str(e)}"}

        # ì „ì²´ ìƒíƒœ ê²°ì •
        module_statuses = [m["status"] for m in status["modules"].values()]
        if all("âœ…" in s for s in module_statuses):
            status["overall_status"] = "ì™„ì „ ì •ìƒ"
        elif any("âœ…" in s for s in module_statuses):
            status["overall_status"] = "ë¶€ë¶„ ì •ìƒ"
        else:
            status["overall_status"] = "ì˜¤ë¥˜"

        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        if "langchain" in status.get("dependencies", {}):
            status["recommendations"].append("pip install langchain-community langchain-ollama")

        if status["overall_status"] != "ì™„ì „ ì •ìƒ":
            status["recommendations"].append("ê°€ìƒí™˜ê²½ì—ì„œ requirements.txt ì„¤ì¹˜")

        return status

    def display_header(self):
        """í—¤ë” í‘œì‹œ"""
        st.markdown("""
        <div class="main-header">
            <h1>ğŸ¯ CoolStay RAG Assistant</h1>
            <p>AI ê¸°ë°˜ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì§ˆë¬¸ ì‘ë‹µ ì‹œìŠ¤í…œ</p>
        </div>
        """, unsafe_allow_html=True)

    def display_sidebar(self):
        """ì‚¬ì´ë“œë°” í‘œì‹œ"""
        with st.sidebar:
            st.markdown("## ğŸ› ï¸ ì‹œìŠ¤í…œ ìƒíƒœ")

            # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ë²„íŠ¼
            if st.button("ğŸ”„ ìƒíƒœ í™•ì¸", type="primary"):
                with st.spinner("ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì¤‘..."):
                    st.session_state.system_status = self.check_system_dependencies()

            # ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
            if st.session_state.system_status:
                status = st.session_state.system_status

                # ì „ì²´ ìƒíƒœ
                st.markdown(f"**ì „ì²´ ìƒíƒœ**: {status['overall_status']}")

                # ëª¨ë“ˆë³„ ìƒíƒœ
                st.markdown("### ğŸ“¦ ëª¨ë“ˆ ìƒíƒœ")
                for module_name, module_status in status["modules"].items():
                    st.markdown(f"- **{module_name}**: {module_status['status']} {module_status['message']}")

                # ì„¤ì • ì •ë³´
                if "config" in status:
                    st.markdown("### âš™ï¸ ì„¤ì • ì •ë³´")
                    st.markdown(f"- ë„ë©”ì¸ ìˆ˜: {status['config']['domains']}ê°œ")

                # ê¶Œì¥ì‚¬í•­
                if status.get("recommendations"):
                    st.markdown("### ğŸ’¡ ê¶Œì¥ì‚¬í•­")
                    for rec in status["recommendations"]:
                        st.markdown(f"- {rec}")

            st.markdown("---")

            # ì‹œìŠ¤í…œ ì •ë³´
            st.markdown("## ğŸ“‹ ì‹œìŠ¤í…œ ì •ë³´")
            st.markdown(f"""
            - **í”„ë¡œì íŠ¸**: CoolStay Multi-Agent RAG
            - **ë²„ì „**: Phase 3 (ì„œë¹„ìŠ¤í™”)
            - **ê°œë°œ ìƒíƒœ**: í”„ë¡œí† íƒ€ì…
            - **ì§€ì› ë„ë©”ì¸**: 7ê°œ
            """)

            st.markdown("---")

            # ì‚¬ìš© ê°€ì´ë“œ
            st.markdown("## ğŸ“š ì‚¬ìš© ê°€ì´ë“œ")
            with st.expander("ì‹œì‘í•˜ê¸°"):
                st.markdown("""
                1. **ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸**: ìƒíƒœ í™•ì¸ ë²„íŠ¼ í´ë¦­
                2. **ì§ˆë¬¸ ì…ë ¥**: ë©”ì¸ í™”ë©´ì—ì„œ ì§ˆë¬¸ ì…ë ¥
                3. **ì‘ë‹µ í™•ì¸**: AIê°€ ìƒì„±í•œ ì‘ë‹µ ê²€í† 
                4. **í”¼ë“œë°± ì œê³µ**: ì‘ë‹µ í’ˆì§ˆ í‰ê°€
                """)

            with st.expander("ì§€ì› ë„ë©”ì¸"):
                st.markdown("""
                - **HR ì •ì±…**: ì¸ì‚¬ ê´€ë ¨ ì •ì±… ë° ì ˆì°¨
                - **ê¸°ìˆ  ì •ì±…**: ê¸°ìˆ  í‘œì¤€ ë° ê°€ì´ë“œë¼ì¸
                - **ì•„í‚¤í…ì²˜**: ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„
                - **ì»´í¬ë„ŒíŠ¸**: ì†Œí”„íŠ¸ì›¨ì–´ ì»´í¬ë„ŒíŠ¸
                - **ë°°í¬**: ë°°í¬ ë° ìš´ì˜ ì ˆì°¨
                - **ê°œë°œ**: ê°œë°œ í”„ë¡œì„¸ìŠ¤ ë° ë°©ë²•ë¡ 
                - **ë¹„ì¦ˆë‹ˆìŠ¤ ì •ì±…**: ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì • ë° í”„ë¡œì„¸ìŠ¤
                """)

    def display_chat_interface(self):
        """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ í‘œì‹œ"""
        st.markdown("## ğŸ’¬ AI ì–´ì‹œìŠ¤í„´íŠ¸ì™€ ì±„íŒ…")

        # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

                # ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° í‘œì‹œ
                if message.get("metadata"):
                    with st.expander("ì‘ë‹µ ì„¸ë¶€ ì •ë³´"):
                        st.json(message["metadata"])

        # ì§ˆë¬¸ ì…ë ¥
        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
            print(f"DEBUG: ì§ˆë¬¸ ì…ë ¥ ë°›ìŒ - {prompt}")

            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.messages.append({"role": "user", "content": prompt})

            with st.chat_message("user"):
                st.markdown(prompt)

            # AI ì‘ë‹µ ìƒì„±
            with st.chat_message("assistant"):
                with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
                    print(f"DEBUG: process_question í˜¸ì¶œ ì‹œì‘ - ì§ˆë¬¸: {prompt}")
                    response = self.process_question(prompt)
                    print(f"DEBUG: process_question ì™„ë£Œ - ì‘ë‹µ íƒ€ì…: {type(response)}")

                st.markdown(response["content"])

                # ì‘ë‹µì„ ì„¸ì…˜ì— ì¶”ê°€
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": response["content"],
                    "metadata": response.get("metadata", {})
                })

                # ì‘ë‹µ í‰ê°€ UI
                if response.get("success", True):
                    st.session_state.evaluation_counter += 1
                    self.display_response_evaluation(prompt, response["content"], st.session_state.evaluation_counter)

    def process_question(self, question: str) -> Dict[str, Any]:
        """ì§ˆë¬¸ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤"""
        print(f"DEBUG: process_question ë©”ì†Œë“œ ì‹œì‘ - ì§ˆë¬¸: {question}")
        try:
            print("DEBUG: ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì‹œì‘")
            # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
            if not st.session_state.system_status:
                print("DEBUG: system_statusê°€ Noneì´ë¯€ë¡œ check_system_dependencies í˜¸ì¶œ")
                st.session_state.system_status = self.check_system_dependencies()
            else:
                print("DEBUG: ê¸°ì¡´ system_status ì‚¬ìš©")

            status = st.session_state.system_status
            print(f"DEBUG: ì‹œìŠ¤í…œ ìƒíƒœ - overall_status: {status['overall_status']}")

            if status["overall_status"] == "ì™„ì „ ì •ìƒ":
                print("DEBUG: ì™„ì „ ì •ìƒ - RAG íŒŒì´í”„ë¼ì¸ ì‚¬ìš©")
                # ì‹¤ì œ RAG íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
                return self._process_with_rag_pipeline(question)
            elif status["overall_status"] == "ë¶€ë¶„ ì •ìƒ":
                print("DEBUG: ë¶€ë¶„ ì •ìƒ - ì œí•œì  ê¸°ëŠ¥ ì‚¬ìš©")
                # ì œí•œì  ê¸°ëŠ¥ìœ¼ë¡œ ì²˜ë¦¬
                return self._process_with_limited_functionality(question, status)
            else:
                print(f"DEBUG: ì˜¤ë¥˜ ìƒíƒœ ({status['overall_status']}) - ì˜¤ë¥˜ ì§„ë‹¨ ì‘ë‹µ")
                # ì˜¤ë¥˜ ì§„ë‹¨ ë° ì•ˆë‚´
                return self._generate_error_diagnosis_response(question, status)

        except Exception as e:
            return {
                "content": f"âš ï¸ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "success": False,
                "metadata": {"error": str(e), "error_type": "unexpected"}
            }

    def _process_with_rag_pipeline(self, question: str) -> Dict[str, Any]:
        """ì™„ì „í•œ RAG íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì²˜ë¦¬"""
        try:
            # ì‹¤ì œ IntegratedRAGPipeline ì‚¬ìš©
            import asyncio
            from src.pipeline.rag_pipeline import IntegratedRAGPipeline, PipelineConfig
            from src.core.config import CoolStayConfig

            # RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” (ìºì‹±)
            if not hasattr(self, '_rag_pipeline') or self._rag_pipeline is None:
                config = CoolStayConfig()
                pipeline_config = PipelineConfig(
                    enable_evaluation=False,  # ì›¹ì•±ì—ì„œëŠ” ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´ í‰ê°€ ë¹„í™œì„±í™”
                    enable_hitl=False,       # HITLë„ ë¹„í™œì„±í™”
                    enable_web_search=True,
                    enable_corrective_rag=True,
                    enable_quality_checks=True,  # í’ˆì§ˆ ê²€ì¦ í™œì„±í™”
                    min_confidence_threshold=0.9,  # ë†’ì€ ì‹ ë¢°ë„ ìš”êµ¬ (ê°•ì œë¡œ ì¬êµ¬ì„± ìœ ë°œ)
                    min_quality_threshold=0.95,   # ë†’ì€ í’ˆì§ˆ ìš”êµ¬ (ê°•ì œë¡œ ì¬êµ¬ì„± ìœ ë°œ)
                    max_concurrent_agents=3   # ë™ì‹œ ì‹¤í–‰ ì—ì´ì „íŠ¸ ìˆ˜ ì œí•œ
                )
                self._rag_pipeline = IntegratedRAGPipeline(config, pipeline_config)

            # ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

            try:
                # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
                if not self._rag_pipeline.is_initialized:
                    print("DEBUG: íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹œì‘")
                    print(f"DEBUG: config íƒ€ì…: {type(config)}")
                    initialization_success = loop.run_until_complete(
                        self._rag_pipeline.initialize()
                    )
                    print(f"DEBUG: ì´ˆê¸°í™” ê²°ê³¼: {initialization_success}")
                    print(f"DEBUG: ì´ˆê¸°í™” ì˜¤ë¥˜: {self._rag_pipeline.initialization_error}")
                    if not initialization_success:
                        import traceback
                        traceback.print_exc()
                        raise Exception(f"íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {self._rag_pipeline.initialization_error}")

                # ì§ˆë¬¸ ì²˜ë¦¬
                print(f"DEBUG: ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: {question}")
                result = loop.run_until_complete(
                    self._rag_pipeline.process_question(question)
                )
                print(f"DEBUG: ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ")
                print(f"DEBUG: result type: {type(result)}")
                # ê²°ê³¼ ìƒì„¸ ë¶„ì„ ë¡œê·¸
                print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ [ê²°ê³¼ ë¶„ì„] Pipeline Result ìƒì„¸ ì •ë³´                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“‹ ê¸°ë³¸ ì •ë³´:
   - ì§ˆë¬¸: {result.question}
   - ì„±ê³µ ì—¬ë¶€: {'âœ… ì„±ê³µ' if result.success else 'âŒ ì‹¤íŒ¨'}
   - ì‹ ë¢°ë„: {result.confidence:.2f}
   - ì²˜ë¦¬ ì‹œê°„: {result.execution_time:.2f}ì´ˆ
   - íŒŒì´í”„ë¼ì¸ ëª¨ë“œ: {result.pipeline_mode.value if hasattr(result, 'pipeline_mode') else 'N/A'}

ğŸ¯ ë¼ìš°íŒ… ì •ë³´:
   - ì „ëµ: {result.routing_result.routing_decision.strategy.value if hasattr(result, 'routing_result') and result.routing_result else 'N/A'}
   - í™œì„± ì—ì´ì „íŠ¸: {list(result.routing_result.agent_responses.keys()) if hasattr(result, 'routing_result') and result.routing_result else 'N/A'}
   - ì›¹ ê²€ìƒ‰ ìˆ˜í–‰: {'âœ…' if hasattr(result, 'routing_result') and result.routing_result and result.routing_result.web_response else 'âŒ'}

ğŸ”„ ì‘ë‹µ í†µí•©:
   - í†µí•© ì „ëµ: {result.integrated_response.integration_strategy.value if hasattr(result, 'integrated_response') and result.integrated_response else 'N/A'}
   - ê¸°ì—¬ ì—ì´ì „íŠ¸: {result.integrated_response.contributing_agents if hasattr(result, 'integrated_response') and result.integrated_response else 'N/A'}
   - í’ˆì§ˆ ì ìˆ˜: {result.integrated_response.quality_metrics if hasattr(result, 'integrated_response') and result.integrated_response else 'N/A'}

ğŸ“ ìµœì¢… ë‹µë³€ (ì²˜ìŒ 200ì):
   {result.final_answer[:200]}{'...' if len(result.final_answer) > 200 else ''}

ğŸ ì™„ë£Œëœ ë‹¨ê³„: {[stage.value for stage in result.stages_completed] if hasattr(result, 'stages_completed') else 'N/A'}
""")

                # ê° ì—ì´ì „íŠ¸ë³„ ìƒì„¸ ì‘ë‹µ (ì˜µì…˜)
                if hasattr(result, 'routing_result') and result.routing_result and result.routing_result.agent_responses:
                    print("ğŸ¤– ì—ì´ì „íŠ¸ë³„ ì‘ë‹µ ìš”ì•½:")
                    for agent_name, agent_response in result.routing_result.agent_responses.items():
                        status_icon = "âœ…" if agent_response.status.value == "ready" else "âŒ"
                        confidence = f"{agent_response.confidence_score:.2f}" if agent_response.confidence_score else "N/A"
                        answer_preview = agent_response.answer[:100].replace('\n', ' ') + "..." if len(agent_response.answer) > 100 else agent_response.answer.replace('\n', ' ')
                        print(f"   - {agent_name}: {status_icon} (ì‹ ë¢°ë„: {confidence}) {answer_preview}")

                if hasattr(result, 'routing_result') and result.routing_result and result.routing_result.web_response:
                    web_response = result.routing_result.web_response
                    web_status = "âœ…" if web_response.status.value == "ready" else "âŒ"
                    web_preview = web_response.answer[:100].replace('\n', ' ') + "..." if len(web_response.answer) > 100 else web_response.answer.replace('\n', ' ')
                    print(f"   - ì›¹ê²€ìƒ‰: {web_status} {web_preview}")

                print("â•" * 66)

                # ê²°ê³¼ í¬ë§·íŒ…
                return {
                    "content": f"âœ¨ **CoolStay RAG ì‹œìŠ¤í…œ ì‘ë‹µ**\n\n**ì§ˆë¬¸**: {question}\n\n**ë‹µë³€**: {result.final_answer}\n\n**ì‹ ë¢°ë„**: {result.confidence:.1%}\n**ì²˜ë¦¬ ì‹œê°„**: {result.execution_time:.2f}ì´ˆ",
                    "success": result.success,
                    "metadata": {
                        "pipeline_mode": result.pipeline_mode.value,
                        "processing_time": result.execution_time,
                        "confidence": result.confidence,
                        "stages_completed": [stage.value for stage in result.stages_completed],
                        "routing_info": {
                            "selected_agents": len(result.routing_result.agent_responses) if result.routing_result else 0,
                            "domains_used": list(result.routing_result.agent_responses.keys()) if result.routing_result else []
                        }
                    }
                }

            finally:
                loop.close()

        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒì„¸ ì§„ë‹¨ ì œê³µ
            error_message = str(e)

            # êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ìœ í˜•ì— ë”°ë¥¸ ì²˜ë¦¬
            if "API" in error_message or "key" in error_message.lower():
                return {
                    "content": f"ğŸ”‘ **API í‚¤ ì„¤ì • ì˜¤ë¥˜**\n\nì§ˆë¬¸: '{question}'\n\nâŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\n**í•´ê²° ë°©ë²•**:\n1. `.env` íŒŒì¼ì—ì„œ `OPENAI_API_KEY` í™•ì¸\n2. ìœ íš¨í•œ OpenAI API í‚¤ì¸ì§€ í™•ì¸\n3. ì›¹ì•± ì¬ì‹œì‘\n\n**í˜„ì¬ ì˜¤ë¥˜**: {error_message}",
                    "success": False,
                    "metadata": {"error_type": "api_key", "error": error_message}
                }
            elif "import" in error_message.lower() or "module" in error_message.lower():
                return {
                    "content": f"ğŸ“¦ **ëª¨ë“ˆ ì„í¬íŠ¸ ì˜¤ë¥˜**\n\nì§ˆë¬¸: '{question}'\n\nâŒ í•„ìš”í•œ ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n**í•´ê²° ë°©ë²•**:\n1. ê°€ìƒí™˜ê²½ì´ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\n2. `pip install -r requirements.txt` ì¬ì‹¤í–‰\n3. ì›¹ì•± ì¬ì‹œì‘\n\n**í˜„ì¬ ì˜¤ë¥˜**: {error_message}",
                    "success": False,
                    "metadata": {"error_type": "import_error", "error": error_message}
                }
            else:
                return {
                    "content": f"âš ï¸ **RAG íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜**\n\nì§ˆë¬¸: '{question}'\n\nâŒ RAG ì‹œìŠ¤í…œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n**ì˜¤ë¥˜ ì„¸ë¶€ì‚¬í•­**: {error_message}\n\n**ëŒ€ì•ˆ**: ì œí•œì  ê¸°ëŠ¥ì„ ì‚¬ìš©í•´ë³´ê±°ë‚˜, ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.",
                    "success": False,
                    "metadata": {"error_type": "pipeline_error", "error": error_message}
                }

    def _process_with_limited_functionality(self, question: str, status: Dict[str, Any]) -> Dict[str, Any]:
        """ì œí•œì  ê¸°ëŠ¥ìœ¼ë¡œ ì²˜ë¦¬"""
        try:
            from src.routing.question_analyzer import QuestionAnalyzer

            analyzer = QuestionAnalyzer()
            # ì‹¤ì œë¡œëŠ” LLM í˜¸ì¶œì´ í•„ìš”í•˜ì§€ë§Œ, í˜„ì¬ ìƒíƒœ ê¸°ë°˜ìœ¼ë¡œ ì•ˆë‚´

            working_modules = [name for name, info in status["modules"].items() if "âœ…" in info["status"]]
            failing_modules = [name for name, info in status["modules"].items() if "âŒ" in info["status"]]

            return {
                "content": f"""ğŸ” **ì‹œìŠ¤í…œ ìƒíƒœ ê¸°ë°˜ ì‘ë‹µ**

**ì§ˆë¬¸**: {question}

**í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ**:
- âœ… **ì •ìƒ ì‘ë™ ëª¨ë“ˆ**: {', '.join(working_modules) if working_modules else 'ì—†ìŒ'}
- âŒ **ì˜¤ë¥˜ ëª¨ë“ˆ**: {', '.join(failing_modules) if failing_modules else 'ì—†ìŒ'}

**ì œí•œì  ê¸°ëŠ¥ ì•ˆë‚´**:
- ì¼ë¶€ í•µì‹¬ ëª¨ë“ˆì´ ì •ìƒ ì‘ë™í•˜ì—¬ ê¸°ë³¸ì ì¸ ì§ˆë¬¸ ë¶„ì„ì€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- í•˜ì§€ë§Œ ì™„ì „í•œ RAG ì‘ë‹µì„ ìƒì„±í•˜ê¸° ìœ„í•´ì„œëŠ” ëª¨ë“  ì˜ì¡´ì„±ì´ í•„ìš”í•©ë‹ˆë‹¤.

**í•´ê²° ë°©ë²•**:
{self._generate_troubleshooting_steps(status)}

ğŸ’¡ **ì°¸ê³ **: ì „ì²´ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì˜ ê¶Œì¥ì‚¬í•­ì„ ë”°ë¼ì£¼ì„¸ìš”.
""",
                "success": True,
                "metadata": {
                    "pipeline_mode": "limited",
                    "working_modules": working_modules,
                    "failing_modules": failing_modules,
                    "question_length": len(question)
                }
            }
        except Exception as e:
            return self._generate_error_diagnosis_response(question, status)

    def _generate_error_diagnosis_response(self, question: str, status: Dict[str, Any]) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ì§„ë‹¨ ë° ì•ˆë‚´ ì‘ë‹µ ìƒì„±"""
        # ì£¼ìš” ì˜¤ë¥˜ ì›ì¸ ë¶„ì„
        error_causes = []
        solutions = []

        # ëª¨ë“ˆë³„ ì˜¤ë¥˜ ë¶„ì„
        failing_modules = []
        for module_name, module_info in status.get("modules", {}).items():
            if "âŒ" in module_info["status"]:
                failing_modules.append({
                    "name": module_name,
                    "message": module_info["message"]
                })

                # êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì›ì¸ ë¶„ì„
                if "langchain" in module_info["message"].lower():
                    error_causes.append("LangChain ê´€ë ¨ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
                    solutions.append("pip install langchain-community langchain-ollama")
                elif "api" in module_info["message"].lower():
                    error_causes.append("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŒ")
                    solutions.append(".env íŒŒì¼ì—ì„œ OPENAI_API_KEY í™•ì¸")
                elif "ì´ˆê¸°í™”" in module_info["message"]:
                    error_causes.append(f"{module_name} ëª¨ë“ˆ ì´ˆê¸°í™” ì‹¤íŒ¨")

        # ì˜ì¡´ì„± ë¬¸ì œ ë¶„ì„
        dependency_issues = status.get("dependencies", {})
        for dep, dep_status in dependency_issues.items():
            if "âŒ" in dep_status:
                error_causes.append(f"{dep} íŒ¨í‚¤ì§€ ëˆ„ë½")
                solutions.append(f"pip install {dep}")

        return {
            "content": f"""âŒ **ì‹œìŠ¤í…œ ì˜¤ë¥˜ ì§„ë‹¨**

**ì§ˆë¬¸**: {question}

**âš ï¸ í˜„ì¬ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ëŠ” ì´ìœ **:

**ì£¼ìš” ì˜¤ë¥˜ ëª¨ë“ˆ**:
{self._format_failing_modules(failing_modules)}

**ê°ì§€ëœ ë¬¸ì œ**:
{self._format_error_causes(error_causes)}

**ğŸ”§ í•´ê²° ë°©ë²•**:
{self._format_solutions(solutions)}

**ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
â–¡ ê°€ìƒí™˜ê²½ í™œì„±í™”: `source venv/bin/activate`
â–¡ ì˜ì¡´ì„± ì„¤ì¹˜: `pip install -r requirements.txt`
â–¡ API í‚¤ ì„¤ì •: `.env` íŒŒì¼ì— `OPENAI_API_KEY=your-key` ì¶”ê°€
â–¡ ì‹œìŠ¤í…œ ì¬ì‹œì‘: ì›¹ì•± ì¬ì‹œì‘ í›„ "ğŸ”„ ìƒíƒœ í™•ì¸" í´ë¦­

**ğŸ’¡ ë„ì›€ë§**:
- ì‚¬ì´ë“œë°”ì—ì„œ "ğŸ”„ ìƒíƒœ í™•ì¸"ì„ í´ë¦­í•˜ì—¬ ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”
- `INSTALLATION_GUIDE.md` íŒŒì¼ì„ ì°¸ì¡°í•˜ì—¬ ë‹¨ê³„ë³„ ì„¤ì¹˜ë¥¼ ì§„í–‰í•˜ì„¸ìš”
- ëª¨ë“  ëª¨ë“ˆì´ âœ… ìƒíƒœê°€ ë˜ë©´ ì •ìƒì ì¸ AI ì‘ë‹µì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤

ğŸ¤– **CoolStay RAG ì‹œìŠ¤í…œ ì •ë³´**:
ì´ ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™í•˜ë©´ 7ê°œ ì „ë¬¸ ë„ë©”ì¸ì˜ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
""",
            "success": False,
            "metadata": {
                "pipeline_mode": "error_diagnosis",
                "failing_modules": [m["name"] for m in failing_modules],
                "error_causes": error_causes,
                "solutions": solutions,
                "question_length": len(question)
            }
        }

    def _format_failing_modules(self, failing_modules: List[Dict[str, str]]) -> str:
        """ì‹¤íŒ¨í•œ ëª¨ë“ˆ í¬ë§·íŒ…"""
        if not failing_modules:
            return "- ëª¨ë“  ëª¨ë“ˆì´ ì •ìƒ ì‘ë™ ì¤‘"

        formatted = []
        for module in failing_modules:
            formatted.append(f"- **{module['name']}**: {module['message']}")
        return "\n".join(formatted)

    def _format_error_causes(self, causes: List[str]) -> str:
        """ì˜¤ë¥˜ ì›ì¸ í¬ë§·íŒ…"""
        if not causes:
            return "- êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ì›ì¸ì„ íŠ¹ì •í•  ìˆ˜ ì—†ìŒ"

        formatted = []
        for i, cause in enumerate(set(causes), 1):  # ì¤‘ë³µ ì œê±°
            formatted.append(f"{i}. {cause}")
        return "\n".join(formatted)

    def _format_solutions(self, solutions: List[str]) -> str:
        """í•´ê²°ë°©ë²• í¬ë§·íŒ…"""
        if not solutions:
            return "1. INSTALLATION_GUIDE.md ì°¸ì¡°\n2. ê°€ìƒí™˜ê²½ì—ì„œ requirements.txt ì„¤ì¹˜"

        formatted = []
        for i, solution in enumerate(set(solutions), 1):  # ì¤‘ë³µ ì œê±°
            formatted.append(f"{i}. {solution}")
        return "\n".join(formatted)

    def _generate_troubleshooting_steps(self, status: Dict[str, Any]) -> str:
        """ë¬¸ì œ í•´ê²° ë‹¨ê³„ ìƒì„±"""
        steps = []

        # ì˜ì¡´ì„± ë¬¸ì œê°€ ìˆëŠ” ê²½ìš°
        if status.get("dependencies"):
            steps.append("1. ê°€ìƒí™˜ê²½ì—ì„œ `pip install -r requirements.txt` ì‹¤í–‰")

        # LLM ëª¨ë“ˆ ë¬¸ì œê°€ ìˆëŠ” ê²½ìš°
        llm_status = status.get("modules", {}).get("llm", {})
        if "âŒ" in llm_status.get("status", ""):
            steps.append("2. .env íŒŒì¼ì—ì„œ OPENAI_API_KEY í™•ì¸")

        # ì¼ë°˜ì ì¸ í•´ê²°ì±…
        steps.append("3. ì›¹ì•± ì¬ì‹œì‘ í›„ 'ğŸ”„ ìƒíƒœ í™•ì¸' í´ë¦­")

        return "\n".join(steps) if steps else "ì‚¬ì´ë“œë°”ì˜ ê¶Œì¥ì‚¬í•­ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

    def display_response_evaluation(self, question: str, response: str, evaluation_id: int):
        """ì‘ë‹µ í‰ê°€ UI í‘œì‹œ"""
        st.markdown("---")
        st.markdown("### ğŸ“Š ì‘ë‹µ í‰ê°€")

        col1, col2, col3 = st.columns(3)

        with col1:
            rating = st.slider("ì „ì²´ ë§Œì¡±ë„", 1, 5, 3, key=f"rating_{evaluation_id}")

        with col2:
            relevance = st.selectbox("ê´€ë ¨ì„±", ["ë†’ìŒ", "ë³´í†µ", "ë‚®ìŒ"], index=1, key=f"relevance_{evaluation_id}")

        with col3:
            usefulness = st.selectbox("ì‹¤ìš©ì„±", ["ìœ ìš©í•¨", "ë³´í†µ", "ìœ ìš©í•˜ì§€ ì•ŠìŒ"], index=1, key=f"usefulness_{evaluation_id}")

        feedback = st.text_area("ì¶”ê°€ í”¼ë“œë°±", placeholder="ê°œì„  ì‚¬í•­ì´ë‚˜ ì¶”ê°€ ì˜ê²¬ì„ ì…ë ¥í•´ì£¼ì„¸ìš”...", key=f"feedback_{evaluation_id}")

        if st.button("ğŸ’¾ í”¼ë“œë°± ì €ì¥", key=f"save_feedback_{evaluation_id}"):
            # í”¼ë“œë°± ì €ì¥
            feedback_data = {
                "timestamp": datetime.now().isoformat(),
                "question": question,
                "response": response[:100] + "...",
                "rating": rating,
                "relevance": relevance,
                "usefulness": usefulness,
                "feedback": feedback
            }

            # ì„¸ì…˜ ìƒíƒœì— í”¼ë“œë°± ì €ì¥
            if "feedbacks" not in st.session_state:
                st.session_state.feedbacks = []

            st.session_state.feedbacks.append(feedback_data)

            st.success("âœ… í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")

    def display_analytics(self):
        """ë¶„ì„ ì •ë³´ í‘œì‹œ"""
        st.markdown("## ğŸ“ˆ ì‚¬ìš© ë¶„ì„")

        if hasattr(st.session_state, 'feedbacks') and st.session_state.feedbacks:
            feedbacks = st.session_state.feedbacks

            col1, col2, col3 = st.columns(3)

            with col1:
                avg_rating = sum(f["rating"] for f in feedbacks) / len(feedbacks)
                st.metric("í‰ê·  ë§Œì¡±ë„", f"{avg_rating:.1f}/5")

            with col2:
                total_questions = len(st.session_state.messages) // 2  # user + assistant pairs
                st.metric("ì´ ì§ˆë¬¸ ìˆ˜", total_questions)

            with col3:
                if feedbacks:
                    latest_feedback = feedbacks[-1]
                    st.metric("ìµœê·¼ í‰ê°€", f"{latest_feedback['rating']}/5")

            # í”¼ë“œë°± íˆìŠ¤í† ë¦¬
            st.markdown("### ìµœê·¼ í”¼ë“œë°±")
            for i, feedback in enumerate(reversed(feedbacks[-5:])):  # ìµœê·¼ 5ê°œ
                with st.expander(f"í”¼ë“œë°± {len(feedbacks)-i}: {feedback['question'][:50]}..."):
                    st.json(feedback)
        else:
            st.info("ì•„ì§ í”¼ë“œë°± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ í•˜ê³  í‰ê°€í•´ì£¼ì„¸ìš”!")

    def run(self):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰"""
        self.display_header()
        self.display_sidebar()

        # ë©”ì¸ ì½˜í…ì¸ 
        tab1, tab2 = st.tabs(["ğŸ’¬ ì±„íŒ…", "ğŸ“ˆ ë¶„ì„"])

        with tab1:
            self.display_chat_interface()

        with tab2:
            self.display_analytics()

        # í‘¸í„°
        st.markdown("---")
        st.markdown("""
        <div style="text-align: center; color: #666; padding: 1rem;">
            ğŸ¯ CoolStay RAG Assistant | Phase 3 ì„œë¹„ìŠ¤í™” ë°ëª¨ |
            Built with â¤ï¸ using Streamlit
        </div>
        """, unsafe_allow_html=True)


# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
if __name__ == "__main__":
    app = StreamlitRAGApp()
    app.run()