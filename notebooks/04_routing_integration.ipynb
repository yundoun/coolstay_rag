{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ§­ ê¿€ìŠ¤í…Œì´ RAG - ë¼ìš°íŒ… ë° í†µí•©\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ì§ˆë¬¸ ë¶„ì„, ì—ì´ì „íŠ¸ ë¼ìš°íŒ…, ë©€í‹° ì—ì´ì „íŠ¸ ë‹µë³€ í†µí•©ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ëª©í‘œ\n",
    "1. ì§ˆë¬¸ ë¶„ì„ ë° ë„ë©”ì¸ ë¶„ë¥˜ ì‹œìŠ¤í…œ\n",
    "2. ì ì ˆí•œ ì—ì´ì „íŠ¸ ì„ íƒ ë¡œì§\n",
    "3. ë©€í‹° ì—ì´ì „íŠ¸ ë‹µë³€ ì¡°í•©\n",
    "4. ë§ˆìŠ¤í„° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ êµ¬í˜„\n",
    "5. LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport sys\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Optional, Tuple, Union\nimport logging\nfrom dotenv import load_dotenv\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nimport json\nfrom datetime import datetime\n\n# LangChain ê´€ë ¨\nfrom langchain_openai import ChatOpenAI\nfrom langchain_chroma import Chroma\nfrom langchain_ollama import OllamaEmbeddings\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser, JsonOutputParser\nfrom langchain_core.documents import Document\nfrom langchain_core.runnables import RunnablePassthrough\n\n# LangGraph ê´€ë ¨\nfrom langgraph.graph import StateGraph, END\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom typing_extensions import TypedDict\n\n# ì›¹ ê²€ìƒ‰\nfrom langchain_community.tools import TavilySearchResults\n\n# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (ì ˆëŒ€ ê²½ë¡œ ì§€ì •)\nproject_root = Path(\"/Users/yundoun/Desktop/Project/legal_rag/coolstay_rag\")\nenv_file = project_root / \".env\"\nload_result = load_dotenv(env_file)\nprint(f\"ğŸ“ .env íŒŒì¼ ë¡œë“œ: {load_result} (ê²½ë¡œ: {env_file})\")\n\n# API í‚¤ í™•ì¸\nopenai_key = os.getenv(\"OPENAI_API_KEY\", \"NOT_FOUND\")\ntavily_key = os.getenv(\"TAVILY_API_KEY\", \"NOT_FOUND\")\nprint(f\"ğŸ”‘ OpenAI API Key: {'ì„¤ì •ë¨' if openai_key != 'NOT_FOUND' and openai_key.startswith('sk-') else 'NOT_FOUND'}\")\nprint(f\"ğŸ”‘ Tavily API Key: {'ì„¤ì •ë¨' if tavily_key != 'NOT_FOUND' and tavily_key.startswith('tvly-') else 'NOT_FOUND'}\")\n\n# ë¡œê¹… ì„¤ì •\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nprint(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ê¸°ë³¸ ì„¤ì • ë° ì—ì´ì „íŠ¸ ë¡œë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •\n",
    "PROJECT_ROOT = Path(\"/Users/yundoun/Desktop/Project/legal_rag/coolstay_rag\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "CHROMA_DB_DIR = PROJECT_ROOT / \"chroma_db\"\n",
    "\n",
    "# ë„ë©”ì¸ ì„¤ì •\n",
    "DOMAIN_CONFIG = {\n",
    "    \"hr_policy\": {\n",
    "        \"file\": \"HR_Policy_Guide.md\",\n",
    "        \"description\": \"ì¸ì‚¬ì •ì±…, ê·¼ë¬´ì‹œê°„, íœ´ê°€, ê¸‰ì—¬, ë³µë¦¬í›„ìƒ\",\n",
    "        \"collection_name\": \"hr_policy_db\",\n",
    "        \"agent_name\": \"HR ì •ì±… ì „ë¬¸ê°€\",\n",
    "        \"keywords\": [\"ì¸ì‚¬\", \"HR\", \"ê·¼ë¬´\", \"íœ´ê°€\", \"ì—°ì°¨\", \"ê¸‰ì—¬\", \"ë³´í—˜\", \"ë³µë¦¬í›„ìƒ\", \"ì±„ìš©\", \"í‡´ì‚¬\", \"ìŠ¹ì§„\"]\n",
    "    },\n",
    "    \"tech_policy\": {\n",
    "        \"file\": \"Tech_Policy_Guide.md\",\n",
    "        \"description\": \"ê¸°ìˆ ì •ì±…, ê°œë°œí™˜ê²½, ì½”ë”©í‘œì¤€, ë³´ì•ˆì •ì±…\",\n",
    "        \"collection_name\": \"tech_policy_db\",\n",
    "        \"agent_name\": \"ê¸°ìˆ  ì •ì±… ì „ë¬¸ê°€\",\n",
    "        \"keywords\": [\"ê¸°ìˆ \", \"ê°œë°œ\", \"ì½”ë”©\", \"ì½”ë“œ\", \"í”„ë¡œê·¸ë˜ë°\", \"ë³´ì•ˆ\", \"ê°œë°œí™˜ê²½\", \"IDE\", \"ë„êµ¬\", \"ë¼ì´ë¸ŒëŸ¬ë¦¬\"]\n",
    "    },\n",
    "    \"architecture\": {\n",
    "        \"file\": \"Architecture_Guide.md\",\n",
    "        \"description\": \"CMS ì•„í‚¤í…ì²˜, ì‹œìŠ¤í…œì„¤ê³„, ë ˆì´ì–´êµ¬ì¡°\",\n",
    "        \"collection_name\": \"architecture_db\",\n",
    "        \"agent_name\": \"ì•„í‚¤í…ì²˜ ì „ë¬¸ê°€\",\n",
    "        \"keywords\": [\"ì•„í‚¤í…ì²˜\", \"ì‹œìŠ¤í…œ\", \"ì„¤ê³„\", \"êµ¬ì¡°\", \"ë ˆì´ì–´\", \"ëª¨ë“ˆ\", \"ì„œë¹„ìŠ¤\", \"API\", \"ë°ì´í„°ë² ì´ìŠ¤\", \"ì¸í”„ë¼\"]\n",
    "    },\n",
    "    \"component\": {\n",
    "        \"file\": \"Component_Guide.md\",\n",
    "        \"description\": \"ì»´í¬ë„ŒíŠ¸ ê°€ì´ë“œë¼ì¸, UI/UX í‘œì¤€\",\n",
    "        \"collection_name\": \"component_db\",\n",
    "        \"agent_name\": \"ì»´í¬ë„ŒíŠ¸ ê°œë°œ ì „ë¬¸ê°€\",\n",
    "        \"keywords\": [\"ì»´í¬ë„ŒíŠ¸\", \"UI\", \"UX\", \"ì¸í„°í˜ì´ìŠ¤\", \"ë””ìì¸\", \"í”„ë¡ íŠ¸ì—”ë“œ\", \"ì‚¬ìš©ì\", \"í™”ë©´\", \"í˜ì´ì§€\"]\n",
    "    },\n",
    "    \"deployment\": {\n",
    "        \"file\": \"Deployment_Guide.md\",\n",
    "        \"description\": \"ë°°í¬í”„ë¡œì„¸ìŠ¤, CI/CD, í™˜ê²½ê´€ë¦¬\",\n",
    "        \"collection_name\": \"deployment_db\",\n",
    "        \"agent_name\": \"ë°°í¬ ì „ë¬¸ê°€\",\n",
    "        \"keywords\": [\"ë°°í¬\", \"CI/CD\", \"í™˜ê²½\", \"ì„œë²„\", \"í´ë¼ìš°ë“œ\", \"ë„ì»¤\", \"ì¿ ë²„ë„¤í‹°ìŠ¤\", \"íŒŒì´í”„ë¼ì¸\", \"ìë™í™”\"]\n",
    "    },\n",
    "    \"development\": {\n",
    "        \"file\": \"Development_Process_Guide.md\",\n",
    "        \"description\": \"ê°œë°œí”„ë¡œì„¸ìŠ¤, ì›Œí¬í”Œë¡œìš°, í˜‘ì—…ê·œì¹™\",\n",
    "        \"collection_name\": \"development_db\",\n",
    "        \"agent_name\": \"ê°œë°œ í”„ë¡œì„¸ìŠ¤ ì „ë¬¸ê°€\",\n",
    "        \"keywords\": [\"ê°œë°œí”„ë¡œì„¸ìŠ¤\", \"ì›Œí¬í”Œë¡œìš°\", \"í˜‘ì—…\", \"í”„ë¡œì„¸ìŠ¤\", \"ë°©ë²•ë¡ \", \"ìŠ¤í¬ëŸ¼\", \"ì• ìì¼\", \"ë¦¬ë·°\", \"í…ŒìŠ¤íŠ¸\"]\n",
    "    },\n",
    "    \"business_policy\": {\n",
    "        \"file\": \"Business_Policy_Guide.md\",\n",
    "        \"description\": \"ë¹„ì¦ˆë‹ˆìŠ¤ì •ì±…, ìš´ì˜ê·œì¹™, ì˜ì‚¬ê²°ì •\",\n",
    "        \"collection_name\": \"business_policy_db\",\n",
    "        \"agent_name\": \"ë¹„ì¦ˆë‹ˆìŠ¤ ì •ì±… ì „ë¬¸ê°€\",\n",
    "        \"keywords\": [\"ë¹„ì¦ˆë‹ˆìŠ¤\", \"ì •ì±…\", \"ìš´ì˜\", \"ì˜ì‚¬ê²°ì •\", \"ì „ëµ\", \"ê³„íš\", \"ëª©í‘œ\", \"ì„±ê³¼\", \"ê´€ë¦¬\", \"ì¡°ì§\"]\n",
    "    },\n",
    "    \"web_search\": {\n",
    "        \"description\": \"ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì„ í†µí•œ ìµœì‹  ì •ë³´ ì œê³µ\",\n",
    "        \"agent_name\": \"ì›¹ ê²€ìƒ‰ ì „ë¬¸ê°€\",\n",
    "        \"keywords\": [\"ìµœì‹ \", \"íŠ¸ë Œë“œ\", \"ë‰´ìŠ¤\", \"ë™í–¥\", \"í˜„ì¬\", \"ì‹¤ì‹œê°„\", \"ì—…ë°ì´íŠ¸\", \"ì‹ ê¸°ìˆ \", \"ì™¸ë¶€ì •ë³´\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"âœ… ì„¤ì • ì™„ë£Œ: {len(DOMAIN_CONFIG)}ê°œ ë„ë©”ì¸ (ì›¹ê²€ìƒ‰ í¬í•¨)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ì „ ë…¸íŠ¸ë¶ì—ì„œ êµ¬í˜„í•œ í´ë˜ìŠ¤ë“¤ ì„í¬íŠ¸ (ê°„ì†Œí™”ëœ ë²„ì „)\n",
    "# ì‹¤ì œë¡œëŠ” 03_agents_development.ipynbì˜ ì½”ë“œë¥¼ ì¬ì‚¬ìš©í•˜ê±°ë‚˜ ëª¨ë“ˆë¡œ ë¶„ë¦¬\n",
    "\n",
    "# ê°„ì†Œí™”ëœ RAGResponse í´ë˜ìŠ¤\n",
    "@dataclass\n",
    "class RAGResponse:\n",
    "    answer: str\n",
    "    source_documents: List[Document]\n",
    "    domain: str\n",
    "    quality_assessment: Optional[Any] = None\n",
    "    corrective_iterations: int = 0\n",
    "    confidence_score: float = 0.7  # ê¸°ë³¸ ì‹ ë¢°ë„\n",
    "\n",
    "# ê°„ì†Œí™”ëœ ê¸°ë³¸ ì—ì´ì „íŠ¸\n",
    "class MockRAGAgent:\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ìš© Mock RAG Agent\"\"\"\n",
    "    \n",
    "    def __init__(self, domain: str, llm: ChatOpenAI):\n",
    "        self.domain = domain\n",
    "        self.llm = llm\n",
    "        self.config = DOMAIN_CONFIG.get(domain, {})\n",
    "        self.agent_name = self.config.get(\"agent_name\", f\"{domain} ì „ë¬¸ê°€\")\n",
    "        self.description = self.config.get(\"description\", \"ë„ë©”ì¸ ì „ë¬¸ê°€\")\n",
    "    \n",
    "    def query(self, question: str, enable_corrective: bool = True) -> RAGResponse:\n",
    "        \"\"\"Mock ì§ˆë¬¸ ì²˜ë¦¬ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” 03ë²ˆ ë…¸íŠ¸ë¶ì˜ BaseRAGAgent ì‚¬ìš©)\"\"\"\n",
    "        try:\n",
    "            # ê°„ë‹¨í•œ ë‹µë³€ ìƒì„± (ì‹¤ì œë¡œëŠ” ë²¡í„° ê²€ìƒ‰ + LLM ì²´ì¸ ì‚¬ìš©)\n",
    "            prompt = f\"ë‹¹ì‹ ì€ ê¿€ìŠ¤í…Œì´ì˜ {self.agent_name}ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ì— {self.description} ê´€ì ì—ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”: {question}\"\n",
    "            \n",
    "            answer = self.llm.invoke(prompt).content\n",
    "            \n",
    "            # Mock ì†ŒìŠ¤ ë¬¸ì„œ\n",
    "            source_docs = [\n",
    "                Document(\n",
    "                    page_content=f\"{self.domain} ë„ë©”ì¸ ê´€ë ¨ ì •ë³´\",\n",
    "                    metadata={\"domain\": self.domain, \"source\": \"mock_data\"}\n",
    "                )\n",
    "            ]\n",
    "            \n",
    "            return RAGResponse(\n",
    "                answer=answer,\n",
    "                source_documents=source_docs,\n",
    "                domain=self.domain,\n",
    "                confidence_score=0.8\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Mock ì—ì´ì „íŠ¸ ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨ ({self.domain}): {e}\")\n",
    "            return RAGResponse(\n",
    "                answer=f\"ì£„ì†¡í•©ë‹ˆë‹¤. {self.domain} ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\",\n",
    "                source_documents=[],\n",
    "                domain=self.domain,\n",
    "                confidence_score=0.1\n",
    "            )\n",
    "\n",
    "print(\"âœ… Mock í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM ì´ˆê¸°í™”\n",
    "def initialize_llm():\n",
    "    try:\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.1,\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        \n",
    "        # í…ŒìŠ¤íŠ¸ í˜¸ì¶œ\n",
    "        test_response = llm.invoke(\"Hello\")\n",
    "        print(f\"âœ… LLM ì´ˆê¸°í™” ì„±ê³µ: {llm.model_name}\")\n",
    "        return llm\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# Mock ì—ì´ì „íŠ¸ë“¤ ìƒì„± (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” 03ë²ˆ ë…¸íŠ¸ë¶ì˜ ì‹¤ì œ ì—ì´ì „íŠ¸ ì‚¬ìš©)\n",
    "def create_mock_agents(llm: ChatOpenAI) -> Dict[str, MockRAGAgent]:\n",
    "    \"\"\"Mock ì—ì´ì „íŠ¸ ìƒì„±\"\"\"\n",
    "    agents = {}\n",
    "    \n",
    "    for domain in DOMAIN_CONFIG.keys():\n",
    "        if domain != \"web_search\":  # ì›¹ê²€ìƒ‰ì€ ë³„ë„ ì²˜ë¦¬\n",
    "            agents[domain] = MockRAGAgent(domain, llm)\n",
    "    \n",
    "    print(f\"âœ… Mock ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ: {len(agents)}ê°œ\")\n",
    "    return agents\n",
    "\n",
    "# ì´ˆê¸°í™”\n",
    "llm = initialize_llm()\n",
    "if llm:\n",
    "    mock_agents = create_mock_agents(llm)\n",
    "else:\n",
    "    mock_agents = {}\n",
    "    print(\"âŒ LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ Mock ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì§ˆë¬¸ ë¶„ì„ ë° ë„ë©”ì¸ ë¶„ë¥˜ ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class QuestionAnalysis:\n",
    "    \"\"\"ì§ˆë¬¸ ë¶„ì„ ê²°ê³¼\"\"\"\n",
    "    original_question: str\n",
    "    question_type: str  # \"specific\", \"general\", \"comparison\", \"multi_domain\"\n",
    "    relevant_domains: List[str]  # ê´€ë ¨ ë„ë©”ì¸ ëª©ë¡\n",
    "    confidence_scores: Dict[str, float]  # ë„ë©”ì¸ë³„ ì‹ ë¢°ë„\n",
    "    keywords_found: List[str]  # ë°œê²¬ëœ í‚¤ì›Œë“œ\n",
    "    needs_web_search: bool  # ì›¹ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€\n",
    "    priority_domains: List[str]  # ìš°ì„ ìˆœìœ„ ë„ë©”ì¸\n",
    "    reasoning: str  # ë¶„ì„ ê·¼ê±°\n",
    "\n",
    "class QuestionAnalyzer:\n",
    "    \"\"\"ì§ˆë¬¸ ë¶„ì„ ë° ë„ë©”ì¸ ë¶„ë¥˜ê¸°\"\"\"\n",
    "    \n",
    "    def __init__(self, llm: ChatOpenAI, domain_config: Dict[str, Dict]):\n",
    "        self.llm = llm\n",
    "        self.domain_config = domain_config\n",
    "        \n",
    "        # ë„ë©”ì¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸\n",
    "        self.analysis_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        ë‹¹ì‹ ì€ ê¿€ìŠ¤í…Œì´ íšŒì‚¬ì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ ì „ë¬¸ê°€ ë„ë©”ì¸ì„ ì„ íƒí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "        \n",
    "        **ì‚¬ìš© ê°€ëŠ¥í•œ ë„ë©”ì¸:**\n",
    "        {domain_descriptions}\n",
    "        \n",
    "        **ì§ˆë¬¸:** {question}\n",
    "        \n",
    "        **ë¶„ì„ ìš”ì²­:**\n",
    "        1. ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ (specific/general/comparison/multi_domain)\n",
    "        2. ê´€ë ¨ ë„ë©”ì¸ ì‹ë³„ (1-3ê°œ ì¶”ì²œ)\n",
    "        3. ë„ë©”ì¸ë³„ ê´€ë ¨ë„ ì ìˆ˜ (0.0-1.0)\n",
    "        4. ì›¹ ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨\n",
    "        5. ìš°ì„ ìˆœìœ„ ë„ë©”ì¸ ì„ ì •\n",
    "        \n",
    "        **ë¶„ì„ ê¸°ì¤€:**\n",
    "        - í‚¤ì›Œë“œ ë§¤ì¹­ì„ í†µí•œ ë„ë©”ì¸ ì‹ë³„\n",
    "        - ì§ˆë¬¸ì˜ ë§¥ë½ê³¼ ì˜ë„ íŒŒì•…\n",
    "        - ìµœì‹  ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš° ì›¹ ê²€ìƒ‰ ì¶”ì²œ\n",
    "        - ë³µí•©ì ì¸ ì§ˆë¬¸ì˜ ê²½ìš° ì—¬ëŸ¬ ë„ë©”ì¸ ì„ íƒ\n",
    "        \n",
    "        ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:\n",
    "        {{\n",
    "            \"question_type\": \"specific|general|comparison|multi_domain\",\n",
    "            \"relevant_domains\": [\"domain1\", \"domain2\", ...],\n",
    "            \"confidence_scores\": {{\"domain1\": 0.9, \"domain2\": 0.7, ...}},\n",
    "            \"keywords_found\": [\"keyword1\", \"keyword2\", ...],\n",
    "            \"needs_web_search\": true|false,\n",
    "            \"priority_domains\": [\"domain1\", \"domain2\"],\n",
    "            \"reasoning\": \"ë¶„ì„ ê·¼ê±° ì„¤ëª…\"\n",
    "        }}\n",
    "        \"\"\")\n",
    "        \n",
    "        # ë¶„ì„ ì²´ì¸ êµ¬ì„±\n",
    "        self.analysis_chain = (\n",
    "            self.analysis_prompt\n",
    "            | self.llm\n",
    "            | JsonOutputParser()\n",
    "        )\n",
    "    \n",
    "    def _build_domain_descriptions(self) -> str:\n",
    "        \"\"\"ë„ë©”ì¸ ì„¤ëª… ë¬¸ìì—´ ìƒì„±\"\"\"\n",
    "        descriptions = []\n",
    "        \n",
    "        for domain, config in self.domain_config.items():\n",
    "            agent_name = config.get(\"agent_name\", domain)\n",
    "            description = config.get(\"description\", \"\")\n",
    "            keywords = config.get(\"keywords\", [])\n",
    "            \n",
    "            desc_text = f\"- {domain}: {agent_name} ({description})\"\n",
    "            if keywords:\n",
    "                desc_text += f\" [í‚¤ì›Œë“œ: {', '.join(keywords[:5])}]\"\n",
    "            \n",
    "            descriptions.append(desc_text)\n",
    "        \n",
    "        return \"\\n\".join(descriptions)\n",
    "    \n",
    "    def analyze_question(self, question: str) -> QuestionAnalysis:\n",
    "        \"\"\"ì§ˆë¬¸ ë¶„ì„ ìˆ˜í–‰\"\"\"\n",
    "        try:\n",
    "            domain_descriptions = self._build_domain_descriptions()\n",
    "            \n",
    "            result = self.analysis_chain.invoke({\n",
    "                \"question\": question,\n",
    "                \"domain_descriptions\": domain_descriptions\n",
    "            })\n",
    "            \n",
    "            return QuestionAnalysis(\n",
    "                original_question=question,\n",
    "                question_type=result.get(\"question_type\", \"general\"),\n",
    "                relevant_domains=result.get(\"relevant_domains\", []),\n",
    "                confidence_scores=result.get(\"confidence_scores\", {}),\n",
    "                keywords_found=result.get(\"keywords_found\", []),\n",
    "                needs_web_search=result.get(\"needs_web_search\", False),\n",
    "                priority_domains=result.get(\"priority_domains\", []),\n",
    "                reasoning=result.get(\"reasoning\", \"ë¶„ì„ ì™„ë£Œ\")\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì§ˆë¬¸ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "            # ê¸°ë³¸ê°’ ë°˜í™˜\n",
    "            return QuestionAnalysis(\n",
    "                original_question=question,\n",
    "                question_type=\"general\",\n",
    "                relevant_domains=[\"hr_policy\"],  # ê¸°ë³¸ ë„ë©”ì¸\n",
    "                confidence_scores={\"hr_policy\": 0.5},\n",
    "                keywords_found=[],\n",
    "                needs_web_search=False,\n",
    "                priority_domains=[\"hr_policy\"],\n",
    "                reasoning=\"ë¶„ì„ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ, ê¸°ë³¸ê°’ ì‚¬ìš©\"\n",
    "            )\n",
    "\n",
    "# ì§ˆë¬¸ ë¶„ì„ê¸° ì´ˆê¸°í™”\n",
    "if llm:\n",
    "    question_analyzer = QuestionAnalyzer(llm, DOMAIN_CONFIG)\n",
    "    print(\"âœ… ì§ˆë¬¸ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "else:\n",
    "    question_analyzer = None\n",
    "    print(\"âŒ LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ì§ˆë¬¸ ë¶„ì„ê¸°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì§ˆë¬¸ ë¶„ì„ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤\n",
    "test_questions = [\n",
    "    \"ì—°ì°¨ íœ´ê°€ëŠ” ì–´ë–»ê²Œ ì‹ ì²­í•˜ë‚˜ìš”?\",  # hr_policy\n",
    "    \"ì½”ë”© ìŠ¤íƒ€ì¼ ê°€ì´ë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",  # tech_policy\n",
    "    \"ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ì™€ ë°°í¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”\",  # multi_domain: architecture + deployment\n",
    "    \"2024ë…„ AI ê¸°ìˆ  íŠ¸ë Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",  # web_search\n",
    "    \"íšŒì‚¬ì˜ ê°œë°œ í”„ë¡œì„¸ìŠ¤ì™€ UI ì»´í¬ë„ŒíŠ¸ ê°€ì´ë“œë¼ì¸ì„ ì•Œë ¤ì£¼ì„¸ìš”\"  # multi_domain: development + component\n",
    "]\n",
    "\n",
    "def test_question_analysis(analyzer: QuestionAnalyzer, questions: List[str]):\n",
    "    \"\"\"ì§ˆë¬¸ ë¶„ì„ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” ì§ˆë¬¸ ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹œì‘\\n\")\n",
    "    \n",
    "    for i, question in enumerate(questions, 1):\n",
    "        print(f\"ğŸ“‹ í…ŒìŠ¤íŠ¸ {i}: {question}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        try:\n",
    "            # ì§ˆë¬¸ ë¶„ì„ ìˆ˜í–‰\n",
    "            analysis = analyzer.analyze_question(question)\n",
    "            \n",
    "            # ê²°ê³¼ ì¶œë ¥\n",
    "            print(f\"ğŸ·ï¸  ì§ˆë¬¸ ìœ í˜•: {analysis.question_type}\")\n",
    "            print(f\"ğŸ¯ ê´€ë ¨ ë„ë©”ì¸: {', '.join(analysis.relevant_domains)}\")\n",
    "            print(f\"â­ ìš°ì„ ìˆœìœ„: {', '.join(analysis.priority_domains)}\")\n",
    "            print(f\"ğŸŒ ì›¹ ê²€ìƒ‰ í•„ìš”: {'ì˜ˆ' if analysis.needs_web_search else 'ì•„ë‹ˆì˜¤'}\")\n",
    "            \n",
    "            # ì‹ ë¢°ë„ ì ìˆ˜\n",
    "            if analysis.confidence_scores:\n",
    "                print(f\"ğŸ“Š ì‹ ë¢°ë„ ì ìˆ˜:\")\n",
    "                for domain, score in analysis.confidence_scores.items():\n",
    "                    print(f\"   - {domain}: {score:.2f}\")\n",
    "            \n",
    "            # ë°œê²¬ëœ í‚¤ì›Œë“œ\n",
    "            if analysis.keywords_found:\n",
    "                print(f\"ğŸ”¤ í‚¤ì›Œë“œ: {', '.join(analysis.keywords_found)}\")\n",
    "            \n",
    "            print(f\"ğŸ’­ ë¶„ì„ ê·¼ê±°: {analysis.reasoning}\")\n",
    "            print(f\"âœ… ë¶„ì„ ì™„ë£Œ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# ì§ˆë¬¸ ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "if question_analyzer:\n",
    "    test_question_analysis(question_analyzer, test_questions[:3])  # ì²˜ìŒ 3ê°œë§Œ í…ŒìŠ¤íŠ¸\n",
    "else:\n",
    "    print(\"âŒ ì§ˆë¬¸ ë¶„ì„ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ë©€í‹° ì—ì´ì „íŠ¸ ë‹µë³€ í†µí•© ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class IntegratedResponse:\n",
    "    \"\"\"í†µí•©ëœ ìµœì¢… ì‘ë‹µ\"\"\"\n",
    "    final_answer: str\n",
    "    contributing_domains: List[str]\n",
    "    individual_responses: Dict[str, RAGResponse]\n",
    "    integration_method: str  # \"single\", \"combined\", \"ranked\"\n",
    "    overall_confidence: float\n",
    "    source_summary: List[str]\n",
    "    processing_time: float\n",
    "\n",
    "class ResponseIntegrator:\n",
    "    \"\"\"ë©€í‹° ì—ì´ì „íŠ¸ ì‘ë‹µ í†µí•©ê¸°\"\"\"\n",
    "    \n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "        self.llm = llm\n",
    "        \n",
    "        # ë‹¨ì¼ ì‘ë‹µ ì„ íƒ í”„ë¡¬í”„íŠ¸\n",
    "        self.single_selection_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        ì—¬ëŸ¬ ì „ë¬¸ê°€ì˜ ë‹µë³€ ì¤‘ì—ì„œ ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ë‹µë³€ì„ ì„ íƒí•´ì£¼ì„¸ìš”.\n",
    "        \n",
    "        **ì§ˆë¬¸:** {question}\n",
    "        \n",
    "        **ì „ë¬¸ê°€ ë‹µë³€ë“¤:**\n",
    "        {responses}\n",
    "        \n",
    "        **ì„ íƒ ê¸°ì¤€:**\n",
    "        1. ì§ˆë¬¸ê³¼ì˜ ì§ì ‘ì  ê´€ë ¨ì„±\n",
    "        2. ë‹µë³€ì˜ êµ¬ì²´ì„±ê³¼ ì™„ì„±ë„\n",
    "        3. ì „ë¬¸ê°€ì˜ ì‹ ë¢°ë„\n",
    "        \n",
    "        ê°€ì¥ ì í•©í•œ ë‹µë³€ì„ ì„ íƒí•˜ê³ , í•„ìš”ì‹œ ì•½ê°„ì˜ ìˆ˜ì •ì„ ê°€í•´ ìµœì¢… ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.\n",
    "        \"\"\")\n",
    "        \n",
    "        # ë³µí•© í†µí•© í”„ë¡¬í”„íŠ¸\n",
    "        self.integration_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        ì—¬ëŸ¬ ì „ë¬¸ê°€ì˜ ë‹µë³€ì„ í†µí•©í•˜ì—¬ í¬ê´„ì ì¸ ìµœì¢… ë‹µë³€ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\n",
    "        \n",
    "        **ì§ˆë¬¸:** {question}\n",
    "        \n",
    "        **ì „ë¬¸ê°€ ë‹µë³€ë“¤:**\n",
    "        {responses}\n",
    "        \n",
    "        **í†µí•© ì§€ì¹¨:**\n",
    "        1. ê° ì „ë¬¸ê°€ì˜ ê³ ìœ í•œ ê´€ì ì„ ì¡´ì¤‘í•˜ì—¬ í†µí•©\n",
    "        2. ì¤‘ë³µë˜ëŠ” ë‚´ìš©ì€ ì •ë¦¬í•˜ê³  ë³´ì™„ì ì¸ ë‚´ìš©ì€ ì¡°í•©\n",
    "        3. ì „ë¬¸ ë¶„ì•¼ë³„ë¡œ êµ¬ë¶„í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ êµ¬ì„±\n",
    "        4. ì¼ê´€ì„± ìˆê³  ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ìœ¼ë¡œ ì‘ì„±\n",
    "        5. ê° ì •ë³´ì˜ ì¶œì²˜(ì „ë¬¸ê°€)ë¥¼ ëª…ì‹œ\n",
    "        \n",
    "        í†µí•©ëœ ìµœì¢… ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.\n",
    "        \"\"\")\n",
    "        \n",
    "        # ì²´ì¸ êµ¬ì„±\n",
    "        self.single_chain = self.single_selection_prompt | self.llm | StrOutputParser()\n",
    "        self.integration_chain = self.integration_prompt | self.llm | StrOutputParser()\n",
    "    \n",
    "    def _format_responses(self, responses: Dict[str, RAGResponse]) -> str:\n",
    "        \"\"\"ì‘ë‹µë“¤ì„ í¬ë§·íŒ…\"\"\"\n",
    "        formatted = []\n",
    "        \n",
    "        for domain, response in responses.items():\n",
    "            domain_config = DOMAIN_CONFIG.get(domain, {})\n",
    "            agent_name = domain_config.get(\"agent_name\", f\"{domain} ì „ë¬¸ê°€\")\n",
    "            \n",
    "            formatted.append(\n",
    "                f\"**{agent_name} ({domain})**\\n\"\n",
    "                f\"ì‹ ë¢°ë„: {response.confidence_score:.2f}\\n\"\n",
    "                f\"ë‹µë³€: {response.answer}\\n\"\n",
    "                f\"ì¶œì²˜: {len(response.source_documents)}ê°œ ë¬¸ì„œ\"\n",
    "            )\n",
    "        \n",
    "        return \"\\n\\n\".join(formatted)\n",
    "    \n",
    "    def integrate_responses(self, \n",
    "                          question: str,\n",
    "                          responses: Dict[str, RAGResponse],\n",
    "                          integration_method: str = \"auto\") -> IntegratedResponse:\n",
    "        \"\"\"ì‘ë‹µ í†µí•© ìˆ˜í–‰\"\"\"\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        if not responses:\n",
    "            return IntegratedResponse(\n",
    "                final_answer=\"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\",\n",
    "                contributing_domains=[],\n",
    "                individual_responses={},\n",
    "                integration_method=\"none\",\n",
    "                overall_confidence=0.0,\n",
    "                source_summary=[],\n",
    "                processing_time=0.0\n",
    "            )\n",
    "        \n",
    "        # í†µí•© ë°©ì‹ ê²°ì •\n",
    "        if integration_method == \"auto\":\n",
    "            if len(responses) == 1:\n",
    "                integration_method = \"single\"\n",
    "            elif len(responses) <= 2:\n",
    "                integration_method = \"combined\"\n",
    "            else:\n",
    "                integration_method = \"ranked\"\n",
    "        \n",
    "        try:\n",
    "            formatted_responses = self._format_responses(responses)\n",
    "            \n",
    "            if integration_method == \"single\":\n",
    "                # ë‹¨ì¼ ì‘ë‹µ ì„ íƒ\n",
    "                if len(responses) == 1:\n",
    "                    final_answer = list(responses.values())[0].answer\n",
    "                else:\n",
    "                    final_answer = self.single_chain.invoke({\n",
    "                        \"question\": question,\n",
    "                        \"responses\": formatted_responses\n",
    "                    })\n",
    "            \n",
    "            else:\n",
    "                # ë³µí•© í†µí•©\n",
    "                final_answer = self.integration_chain.invoke({\n",
    "                    \"question\": question,\n",
    "                    \"responses\": formatted_responses\n",
    "                })\n",
    "            \n",
    "            # ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°\n",
    "            confidence_scores = [r.confidence_score for r in responses.values()]\n",
    "            overall_confidence = sum(confidence_scores) / len(confidence_scores)\n",
    "            \n",
    "            # ì¶œì²˜ ìš”ì•½\n",
    "            source_summary = []\n",
    "            for domain, response in responses.items():\n",
    "                source_count = len(response.source_documents)\n",
    "                if source_count > 0:\n",
    "                    agent_name = DOMAIN_CONFIG.get(domain, {}).get(\"agent_name\", domain)\n",
    "                    source_summary.append(f\"{agent_name}: {source_count}ê°œ ë¬¸ì„œ\")\n",
    "            \n",
    "            processing_time = (datetime.now() - start_time).total_seconds()\n",
    "            \n",
    "            return IntegratedResponse(\n",
    "                final_answer=final_answer,\n",
    "                contributing_domains=list(responses.keys()),\n",
    "                individual_responses=responses,\n",
    "                integration_method=integration_method,\n",
    "                overall_confidence=overall_confidence,\n",
    "                source_summary=source_summary,\n",
    "                processing_time=processing_time\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì‘ë‹µ í†µí•© ì‹¤íŒ¨: {e}\")\n",
    "            # ì²« ë²ˆì§¸ ì‘ë‹µì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©\n",
    "            first_response = list(responses.values())[0]\n",
    "            \n",
    "            return IntegratedResponse(\n",
    "                final_answer=first_response.answer,\n",
    "                contributing_domains=list(responses.keys()),\n",
    "                individual_responses=responses,\n",
    "                integration_method=\"fallback\",\n",
    "                overall_confidence=first_response.confidence_score,\n",
    "                source_summary=[f\"ë‹¨ì¼ ì‘ë‹µ: {len(first_response.source_documents)}ê°œ ë¬¸ì„œ\"],\n",
    "                processing_time=(datetime.now() - start_time).total_seconds()\n",
    "            )\n",
    "\n",
    "# ì‘ë‹µ í†µí•©ê¸° ì´ˆê¸°í™”\n",
    "if llm:\n",
    "    response_integrator = ResponseIntegrator(llm)\n",
    "    print(\"âœ… ì‘ë‹µ í†µí•©ê¸° ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "else:\n",
    "    response_integrator = None\n",
    "    print(\"âŒ LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ì‘ë‹µ í†µí•©ê¸°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# LangGraph ìƒíƒœ ì •ì˜\nclass RAGWorkflowState(TypedDict):\n    \"\"\"RAG ì›Œí¬í”Œë¡œìš° ìƒíƒœ\"\"\"\n    question: str\n    question_analysis: Optional[QuestionAnalysis]\n    selected_agents: List[str]\n    agent_responses: Dict[str, RAGResponse]\n    integrated_response: Optional[IntegratedResponse]\n    error_message: Optional[str]\n    processing_start_time: Optional[datetime]\n\nclass CoolStayRAGWorkflow:\n    \"\"\"ê¿€ìŠ¤í…Œì´ RAG ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ì\"\"\"\n    \n    def __init__(self, \n                 question_analyzer: QuestionAnalyzer,\n                 agents: Dict[str, MockRAGAgent],\n                 response_integrator: ResponseIntegrator):\n        \n        self.question_analyzer = question_analyzer\n        self.agents = agents\n        self.response_integrator = response_integrator\n        \n        # ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì„±\n        self._build_workflow()\n    \n    def _build_workflow(self):\n        \"\"\"ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì„±\"\"\"\n        \n        # StateGraph ìƒì„±\n        workflow = StateGraph(RAGWorkflowState)\n        \n        # ë…¸ë“œ ì¶”ê°€\n        workflow.add_node(\"analyze_question\", self._analyze_question)\n        workflow.add_node(\"select_agents\", self._select_agents)\n        workflow.add_node(\"execute_agents\", self._execute_agents)\n        workflow.add_node(\"integrate_responses\", self._integrate_responses)\n        \n        # ì—£ì§€ ì¶”ê°€\n        workflow.set_entry_point(\"analyze_question\")\n        workflow.add_edge(\"analyze_question\", \"select_agents\")\n        workflow.add_edge(\"select_agents\", \"execute_agents\")\n        workflow.add_edge(\"execute_agents\", \"integrate_responses\")\n        workflow.add_edge(\"integrate_responses\", END)\n        \n        # ë©”ëª¨ë¦¬ ì„¤ì • (ì„ íƒì‚¬í•­) - checkpointer ì—†ì´ ì»´íŒŒì¼\n        # memory = MemorySaver()\n        \n        # ì›Œí¬í”Œë¡œìš° ì»´íŒŒì¼ (checkpointer ì œê±°)\n        self.workflow = workflow.compile()\n    \n    def _analyze_question(self, state: RAGWorkflowState) -> RAGWorkflowState:\n        \"\"\"ì§ˆë¬¸ ë¶„ì„ ë‹¨ê³„\"\"\"\n        try:\n            logger.info(\"ì§ˆë¬¸ ë¶„ì„ ì‹œì‘\")\n            \n            analysis = self.question_analyzer.analyze_question(state[\"question\"])\n            \n            state[\"question_analysis\"] = analysis\n            state[\"processing_start_time\"] = datetime.now()\n            \n            logger.info(f\"ì§ˆë¬¸ ë¶„ì„ ì™„ë£Œ: {len(analysis.relevant_domains)}ê°œ ë„ë©”ì¸ ì‹ë³„\")\n            \n        except Exception as e:\n            logger.error(f\"ì§ˆë¬¸ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n            state[\"error_message\"] = f\"ì§ˆë¬¸ ë¶„ì„ ì‹¤íŒ¨: {e}\"\n        \n        return state\n    \n    def _select_agents(self, state: RAGWorkflowState) -> RAGWorkflowState:\n        \"\"\"ì—ì´ì „íŠ¸ ì„ íƒ ë‹¨ê³„\"\"\"\n        try:\n            logger.info(\"ì—ì´ì „íŠ¸ ì„ íƒ ì‹œì‘\")\n            \n            analysis = state.get(\"question_analysis\")\n            if not analysis:\n                # ê¸°ë³¸ ì—ì´ì „íŠ¸ ì„ íƒ\n                selected_agents = [\"hr_policy\"]\n            else:\n                # ìš°ì„ ìˆœìœ„ ë„ë©”ì¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì„ íƒ\n                selected_agents = analysis.priority_domains[:3]  # ìµœëŒ€ 3ê°œ ì—ì´ì „íŠ¸\n                \n                # ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ê²½ìš° ì¶”ê°€\n                if analysis.needs_web_search:\n                    selected_agents.append(\"web_search\")\n            \n            # ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ë§Œ í•„í„°ë§\n            available_agents = []\n            for agent in selected_agents:\n                if agent in self.agents or agent == \"web_search\":\n                    available_agents.append(agent)\n            \n            state[\"selected_agents\"] = available_agents\n            \n            logger.info(f\"ì—ì´ì „íŠ¸ ì„ íƒ ì™„ë£Œ: {available_agents}\")\n            \n        except Exception as e:\n            logger.error(f\"ì—ì´ì „íŠ¸ ì„ íƒ ì‹¤íŒ¨: {e}\")\n            state[\"selected_agents\"] = [\"hr_policy\"]  # ê¸°ë³¸ ì—ì´ì „íŠ¸\n        \n        return state\n    \n    def _execute_agents(self, state: RAGWorkflowState) -> RAGWorkflowState:\n        \"\"\"ì—ì´ì „íŠ¸ ì‹¤í–‰ ë‹¨ê³„\"\"\"\n        try:\n            logger.info(\"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œì‘\")\n            \n            question = state[\"question\"]\n            selected_agents = state.get(\"selected_agents\", [])\n            responses = {}\n            \n            for agent_name in selected_agents:\n                if agent_name == \"web_search\":\n                    # ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì²˜ë¦¬ (Mock)\n                    responses[agent_name] = RAGResponse(\n                        answer=f\"ì›¹ ê²€ìƒ‰ ê²°ê³¼: {question}ì— ëŒ€í•œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤.\",\n                        source_documents=[],\n                        domain=agent_name,\n                        confidence_score=0.7\n                    )\n                elif agent_name in self.agents:\n                    # ì¼ë°˜ RAG ì—ì´ì „íŠ¸ ì‹¤í–‰\n                    agent = self.agents[agent_name]\n                    response = agent.query(question, enable_corrective=True)\n                    responses[agent_name] = response\n                    \n                logger.info(f\"{agent_name} ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ\")\n            \n            state[\"agent_responses\"] = responses\n            \n            logger.info(f\"ëª¨ë“  ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ: {len(responses)}ê°œ ì‘ë‹µ\")\n            \n        except Exception as e:\n            logger.error(f\"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n            state[\"error_message\"] = f\"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}\"\n        \n        return state\n    \n    def _integrate_responses(self, state: RAGWorkflowState) -> RAGWorkflowState:\n        \"\"\"ì‘ë‹µ í†µí•© ë‹¨ê³„\"\"\"\n        try:\n            logger.info(\"ì‘ë‹µ í†µí•© ì‹œì‘\")\n            \n            question = state[\"question\"]\n            agent_responses = state.get(\"agent_responses\", {})\n            \n            if not agent_responses:\n                state[\"error_message\"] = \"í†µí•©í•  ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.\"\n                return state\n            \n            # ì‘ë‹µ í†µí•© ìˆ˜í–‰\n            integrated_response = self.response_integrator.integrate_responses(\n                question=question,\n                responses=agent_responses,\n                integration_method=\"auto\"\n            )\n            \n            state[\"integrated_response\"] = integrated_response\n            \n            logger.info(\"ì‘ë‹µ í†µí•© ì™„ë£Œ\")\n            \n        except Exception as e:\n            logger.error(f\"ì‘ë‹µ í†µí•© ì‹¤íŒ¨: {e}\")\n            state[\"error_message\"] = f\"ì‘ë‹µ í†µí•© ì‹¤íŒ¨: {e}\"\n        \n        return state\n    \n    def process_question(self, question: str) -> IntegratedResponse:\n        \"\"\"ì§ˆë¬¸ ì²˜ë¦¬ (ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰)\"\"\"\n        \n        # ì´ˆê¸° ìƒíƒœ ì„¤ì •\n        initial_state = {\n            \"question\": question,\n            \"question_analysis\": None,\n            \"selected_agents\": [],\n            \"agent_responses\": {},\n            \"integrated_response\": None,\n            \"error_message\": None,\n            \"processing_start_time\": None\n        }\n        \n        try:\n            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (checkpointerê°€ ì—†ìœ¼ë¯€ë¡œ config ë¶ˆí•„ìš”)\n            result = self.workflow.invoke(initial_state)\n            \n            # ê²°ê³¼ ë°˜í™˜\n            if result.get(\"integrated_response\"):\n                return result[\"integrated_response\"]\n            else:\n                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ\n                error_msg = result.get(\"error_message\", \"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜\")\n                return IntegratedResponse(\n                    final_answer=f\"ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}\",\n                    contributing_domains=[],\n                    individual_responses={},\n                    integration_method=\"error\",\n                    overall_confidence=0.0,\n                    source_summary=[],\n                    processing_time=0.0\n                )\n                \n        except Exception as e:\n            logger.error(f\"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n            return IntegratedResponse(\n                final_answer=f\"ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\",\n                contributing_domains=[],\n                individual_responses={},\n                integration_method=\"system_error\",\n                overall_confidence=0.0,\n                source_summary=[],\n                processing_time=0.0\n            )\n\n# ì›Œí¬í”Œë¡œìš° ìƒì„±\nif all([question_analyzer, mock_agents, response_integrator]):\n    rag_workflow = CoolStayRAGWorkflow(\n        question_analyzer=question_analyzer,\n        agents=mock_agents,\n        response_integrator=response_integrator\n    )\n    print(\"âœ… RAG ì›Œí¬í”Œë¡œìš° ìƒì„± ì™„ë£Œ\")\nelse:\n    rag_workflow = None\n    missing = []\n    if not question_analyzer: missing.append(\"ì§ˆë¬¸ ë¶„ì„ê¸°\")\n    if not mock_agents: missing.append(\"ì—ì´ì „íŠ¸\")\n    if not response_integrator: missing.append(\"ì‘ë‹µ í†µí•©ê¸°\")\n    print(f\"âŒ RAG ì›Œí¬í”Œë¡œìš°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëˆ„ë½: {', '.join(missing)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. í†µí•© ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_integrated_workflow(workflow: CoolStayRAGWorkflow, test_questions: List[str]):\n",
    "    \"\"\"í†µí•© ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ í†µí•© RAG ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì‹œì‘\\n\")\n",
    "    \n",
    "    test_results = []\n",
    "    \n",
    "    for i, question in enumerate(test_questions, 1):\n",
    "        print(f\"ğŸ“‹ í…ŒìŠ¤íŠ¸ {i}: {question}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        try:\n",
    "            start_time = datetime.now()\n",
    "            \n",
    "            # í†µí•© ì›Œí¬í”Œë¡œìš° ì‹¤í–‰\n",
    "            result = workflow.process_question(question)\n",
    "            \n",
    "            end_time = datetime.now()\n",
    "            total_time = (end_time - start_time).total_seconds()\n",
    "            \n",
    "            # ê²°ê³¼ ì¶œë ¥\n",
    "            print(f\"\\nğŸ’¬ ìµœì¢… ë‹µë³€:\")\n",
    "            print(result.final_answer[:400] + \"...\" if len(result.final_answer) > 400 else result.final_answer)\n",
    "            \n",
    "            print(f\"\\nğŸ“Š ì²˜ë¦¬ ì •ë³´:\")\n",
    "            print(f\"   - ì°¸ì—¬ ë„ë©”ì¸: {', '.join(result.contributing_domains)}\")\n",
    "            print(f\"   - í†µí•© ë°©ì‹: {result.integration_method}\")\n",
    "            print(f\"   - ì „ì²´ ì‹ ë¢°ë„: {result.overall_confidence:.2f}\")\n",
    "            print(f\"   - ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ\")\n",
    "            \n",
    "            if result.source_summary:\n",
    "                print(f\"   - ì¶œì²˜ ìš”ì•½: {', '.join(result.source_summary)}\")\n",
    "            \n",
    "            # ê°œë³„ ì‘ë‹µ ìš”ì•½\n",
    "            if result.individual_responses:\n",
    "                print(f\"\\nğŸ¤– ê°œë³„ ì—ì´ì „íŠ¸ ì‘ë‹µ:\")\n",
    "                for domain, response in result.individual_responses.items():\n",
    "                    agent_name = DOMAIN_CONFIG.get(domain, {}).get(\"agent_name\", domain)\n",
    "                    print(f\"   - {agent_name}: ì‹ ë¢°ë„ {response.confidence_score:.2f}\")\n",
    "            \n",
    "            # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥\n",
    "            test_result = {\n",
    "                \"question\": question,\n",
    "                \"domains_used\": len(result.contributing_domains),\n",
    "                \"integration_method\": result.integration_method,\n",
    "                \"confidence\": result.overall_confidence,\n",
    "                \"processing_time\": total_time,\n",
    "                \"success\": True\n",
    "            }\n",
    "            test_results.append(test_result)\n",
    "            \n",
    "            print(f\"\\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "            logger.error(f\"ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ({question}): {e}\")\n",
    "            \n",
    "            test_results.append({\n",
    "                \"question\": question,\n",
    "                \"domains_used\": 0,\n",
    "                \"integration_method\": \"error\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"processing_time\": 0.0,\n",
    "                \"success\": False\n",
    "            })\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\n",
    "    print(f\"ğŸ“ˆ ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\")\n",
    "    print(f\"   - ì´ í…ŒìŠ¤íŠ¸: {len(test_results)}ê°œ\")\n",
    "    successful_tests = [r for r in test_results if r['success']]\n",
    "    print(f\"   - ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {len(successful_tests)}ê°œ\")\n",
    "    print(f\"   - ì„±ê³µë¥ : {len(successful_tests)/len(test_results)*100:.1f}%\")\n",
    "    \n",
    "    if successful_tests:\n",
    "        avg_confidence = sum(r['confidence'] for r in successful_tests) / len(successful_tests)\n",
    "        avg_processing_time = sum(r['processing_time'] for r in successful_tests) / len(successful_tests)\n",
    "        avg_domains = sum(r['domains_used'] for r in successful_tests) / len(successful_tests)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š í‰ê·  ì„±ëŠ¥ ì§€í‘œ:\")\n",
    "        print(f\"   - í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.2f}\")\n",
    "        print(f\"   - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_processing_time:.2f}ì´ˆ\")\n",
    "        print(f\"   - í‰ê·  ì‚¬ìš© ë„ë©”ì¸: {avg_domains:.1f}ê°œ\")\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# í†µí•© ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "workflow_test_questions = [\n",
    "    \"ì—°ì°¨ íœ´ê°€ ì‹ ì²­ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
    "    \"ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ì™€ ë°°í¬ ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”\",\n",
    "    \"íšŒì‚¬ ì •ì±…ì— ëŒ€í•´ ì „ë°˜ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”\"\n",
    "]\n",
    "\n",
    "if rag_workflow:\n",
    "    workflow_test_results = test_integrated_workflow(rag_workflow, workflow_test_questions)\n",
    "    print(\"\\nâœ… í†µí•© ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(\"âŒ RAG ì›Œí¬í”Œë¡œìš°ê°€ ìƒì„±ë˜ì§€ ì•Šì•„ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "### âœ… ì™„ë£Œëœ ì‘ì—…\n",
    "1. **ì§ˆë¬¸ ë¶„ì„ ì‹œìŠ¤í…œ**: AI ê¸°ë°˜ ë„ë©”ì¸ ë¶„ë¥˜ ë° ì—ì´ì „íŠ¸ ì„ íƒ\n",
    "2. **ë©€í‹° ì—ì´ì „íŠ¸ ë¼ìš°íŒ…**: ìµœì ì˜ ì „ë¬¸ê°€ ì¡°í•© ìë™ ì„ íƒ\n",
    "3. **ì‘ë‹µ í†µí•© ì‹œìŠ¤í…œ**: ë‹¨ì¼/ë³µí•© ë‹µë³€ ì§€ëŠ¥í˜• í†µí•©\n",
    "4. **LangGraph ì›Œí¬í”Œë¡œìš°**: ì „ì²´ íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜\n",
    "5. **í†µí•© í…ŒìŠ¤íŠ¸**: ì—”ë“œíˆ¬ì—”ë“œ ì‹œìŠ¤í…œ ê²€ì¦\n",
    "\n",
    "### ğŸ”§ í•µì‹¬ ê¸°ëŠ¥\n",
    "- **Intelligent Routing**: ì§ˆë¬¸ ë‚´ìš© ê¸°ë°˜ ìµœì  ì—ì´ì „íŠ¸ ìë™ ì„ íƒ\n",
    "- **Multi-Agent Orchestration**: 1-3ê°œ ë„ë©”ì¸ ì „ë¬¸ê°€ ë™ì  ì¡°í•©\n",
    "- **Response Integration**: ë‹¨ì¼ ì„ íƒ, ë³µí•© í†µí•©, ìˆœìœ„ ê¸°ë°˜ í†µí•©\n",
    "- **Workflow Management**: LangGraph ê¸°ë°˜ ìƒíƒœ ê´€ë¦¬ íŒŒì´í”„ë¼ì¸\n",
    "- **Error Handling**: ê° ë‹¨ê³„ë³„ ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë³µêµ¬\n",
    "\n",
    "### ğŸ“Š ì‹œìŠ¤í…œ íŠ¹ì§•\n",
    "- **í™•ì¥ ê°€ëŠ¥**: ìƒˆë¡œìš´ ë„ë©”ì¸/ì—ì´ì „íŠ¸ ì‰½ê²Œ ì¶”ê°€\n",
    "- **ìœ ì—°í•œ í†µí•©**: ì§ˆë¬¸ ë³µì¡ë„ì— ë”°ë¥¸ ì ì‘í˜• ì‘ë‹µ ìƒì„±\n",
    "- **ìƒíƒœ ì¶”ì **: ì „ì²´ ì²˜ë¦¬ ê³¼ì • ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥\n",
    "- **ì‹ ë¢°ë„ ê¸°ë°˜**: ì—ì´ì „íŠ¸ë³„ ì‹ ë¢°ë„ ê³„ì‚° ë° ê°€ì¤‘ í‰ê· \n",
    "\n",
    "### ğŸš€ ë‹¤ìŒ ë‹¨ê³„\n",
    "**05_hitl_evaluation.ipynb**: Human-in-the-Loop í‰ê°€ ì‹œìŠ¤í…œ\n",
    "- ReAct í‰ê°€ ì—ì´ì „íŠ¸ êµ¬í˜„\n",
    "- 6ì°¨ì› í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ\n",
    "- ì¸í„°ëŸ½íŠ¸ ê¸°ë°˜ ì¸ê°„ ê²€ì¦\n",
    "- í’ˆì§ˆ ê¸°ë°˜ í”¼ë“œë°± ë£¨í”„"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}