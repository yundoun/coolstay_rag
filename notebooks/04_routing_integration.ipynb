{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧭 꿀스테이 RAG - 라우팅 및 통합\n",
    "\n",
    "이 노트북에서는 질문 분석, 에이전트 라우팅, 멀티 에이전트 답변 통합을 구현합니다.\n",
    "\n",
    "## 목표\n",
    "1. 질문 분석 및 도메인 분류 시스템\n",
    "2. 적절한 에이전트 선택 로직\n",
    "3. 멀티 에이전트 답변 조합\n",
    "4. 마스터 오케스트레이션 구현\n",
    "5. LangGraph 워크플로우 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport sys\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Optional, Tuple, Union\nimport logging\nfrom dotenv import load_dotenv\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nimport json\nfrom datetime import datetime\n\n# LangChain 관련\nfrom langchain_openai import ChatOpenAI\nfrom langchain_chroma import Chroma\nfrom langchain_ollama import OllamaEmbeddings\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser, JsonOutputParser\nfrom langchain_core.documents import Document\nfrom langchain_core.runnables import RunnablePassthrough\n\n# LangGraph 관련\nfrom langgraph.graph import StateGraph, END\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom typing_extensions import TypedDict\n\n# 웹 검색\nfrom langchain_community.tools import TavilySearchResults\n\n# 환경변수 로드 (절대 경로 지정)\nproject_root = Path(\"/Users/yundoun/Desktop/Project/legal_rag/coolstay_rag\")\nenv_file = project_root / \".env\"\nload_result = load_dotenv(env_file)\nprint(f\"📝 .env 파일 로드: {load_result} (경로: {env_file})\")\n\n# API 키 확인\nopenai_key = os.getenv(\"OPENAI_API_KEY\", \"NOT_FOUND\")\ntavily_key = os.getenv(\"TAVILY_API_KEY\", \"NOT_FOUND\")\nprint(f\"🔑 OpenAI API Key: {'설정됨' if openai_key != 'NOT_FOUND' and openai_key.startswith('sk-') else 'NOT_FOUND'}\")\nprint(f\"🔑 Tavily API Key: {'설정됨' if tavily_key != 'NOT_FOUND' and tavily_key.startswith('tvly-') else 'NOT_FOUND'}\")\n\n# 로깅 설정\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nprint(\"✅ 라이브러리 import 완료\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 기본 설정 및 에이전트 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로젝트 경로 설정\n",
    "PROJECT_ROOT = Path(\"/Users/yundoun/Desktop/Project/legal_rag/coolstay_rag\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "CHROMA_DB_DIR = PROJECT_ROOT / \"chroma_db\"\n",
    "\n",
    "# 도메인 설정\n",
    "DOMAIN_CONFIG = {\n",
    "    \"hr_policy\": {\n",
    "        \"file\": \"HR_Policy_Guide.md\",\n",
    "        \"description\": \"인사정책, 근무시간, 휴가, 급여, 복리후생\",\n",
    "        \"collection_name\": \"hr_policy_db\",\n",
    "        \"agent_name\": \"HR 정책 전문가\",\n",
    "        \"keywords\": [\"인사\", \"HR\", \"근무\", \"휴가\", \"연차\", \"급여\", \"보험\", \"복리후생\", \"채용\", \"퇴사\", \"승진\"]\n",
    "    },\n",
    "    \"tech_policy\": {\n",
    "        \"file\": \"Tech_Policy_Guide.md\",\n",
    "        \"description\": \"기술정책, 개발환경, 코딩표준, 보안정책\",\n",
    "        \"collection_name\": \"tech_policy_db\",\n",
    "        \"agent_name\": \"기술 정책 전문가\",\n",
    "        \"keywords\": [\"기술\", \"개발\", \"코딩\", \"코드\", \"프로그래밍\", \"보안\", \"개발환경\", \"IDE\", \"도구\", \"라이브러리\"]\n",
    "    },\n",
    "    \"architecture\": {\n",
    "        \"file\": \"Architecture_Guide.md\",\n",
    "        \"description\": \"CMS 아키텍처, 시스템설계, 레이어구조\",\n",
    "        \"collection_name\": \"architecture_db\",\n",
    "        \"agent_name\": \"아키텍처 전문가\",\n",
    "        \"keywords\": [\"아키텍처\", \"시스템\", \"설계\", \"구조\", \"레이어\", \"모듈\", \"서비스\", \"API\", \"데이터베이스\", \"인프라\"]\n",
    "    },\n",
    "    \"component\": {\n",
    "        \"file\": \"Component_Guide.md\",\n",
    "        \"description\": \"컴포넌트 가이드라인, UI/UX 표준\",\n",
    "        \"collection_name\": \"component_db\",\n",
    "        \"agent_name\": \"컴포넌트 개발 전문가\",\n",
    "        \"keywords\": [\"컴포넌트\", \"UI\", \"UX\", \"인터페이스\", \"디자인\", \"프론트엔드\", \"사용자\", \"화면\", \"페이지\"]\n",
    "    },\n",
    "    \"deployment\": {\n",
    "        \"file\": \"Deployment_Guide.md\",\n",
    "        \"description\": \"배포프로세스, CI/CD, 환경관리\",\n",
    "        \"collection_name\": \"deployment_db\",\n",
    "        \"agent_name\": \"배포 전문가\",\n",
    "        \"keywords\": [\"배포\", \"CI/CD\", \"환경\", \"서버\", \"클라우드\", \"도커\", \"쿠버네티스\", \"파이프라인\", \"자동화\"]\n",
    "    },\n",
    "    \"development\": {\n",
    "        \"file\": \"Development_Process_Guide.md\",\n",
    "        \"description\": \"개발프로세스, 워크플로우, 협업규칙\",\n",
    "        \"collection_name\": \"development_db\",\n",
    "        \"agent_name\": \"개발 프로세스 전문가\",\n",
    "        \"keywords\": [\"개발프로세스\", \"워크플로우\", \"협업\", \"프로세스\", \"방법론\", \"스크럼\", \"애자일\", \"리뷰\", \"테스트\"]\n",
    "    },\n",
    "    \"business_policy\": {\n",
    "        \"file\": \"Business_Policy_Guide.md\",\n",
    "        \"description\": \"비즈니스정책, 운영규칙, 의사결정\",\n",
    "        \"collection_name\": \"business_policy_db\",\n",
    "        \"agent_name\": \"비즈니스 정책 전문가\",\n",
    "        \"keywords\": [\"비즈니스\", \"정책\", \"운영\", \"의사결정\", \"전략\", \"계획\", \"목표\", \"성과\", \"관리\", \"조직\"]\n",
    "    },\n",
    "    \"web_search\": {\n",
    "        \"description\": \"실시간 웹 검색을 통한 최신 정보 제공\",\n",
    "        \"agent_name\": \"웹 검색 전문가\",\n",
    "        \"keywords\": [\"최신\", \"트렌드\", \"뉴스\", \"동향\", \"현재\", \"실시간\", \"업데이트\", \"신기술\", \"외부정보\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"✅ 설정 완료: {len(DOMAIN_CONFIG)}개 도메인 (웹검색 포함)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 노트북에서 구현한 클래스들 임포트 (간소화된 버전)\n",
    "# 실제로는 03_agents_development.ipynb의 코드를 재사용하거나 모듈로 분리\n",
    "\n",
    "# 간소화된 RAGResponse 클래스\n",
    "@dataclass\n",
    "class RAGResponse:\n",
    "    answer: str\n",
    "    source_documents: List[Document]\n",
    "    domain: str\n",
    "    quality_assessment: Optional[Any] = None\n",
    "    corrective_iterations: int = 0\n",
    "    confidence_score: float = 0.7  # 기본 신뢰도\n",
    "\n",
    "# 간소화된 기본 에이전트\n",
    "class MockRAGAgent:\n",
    "    \"\"\"테스트용 Mock RAG Agent\"\"\"\n",
    "    \n",
    "    def __init__(self, domain: str, llm: ChatOpenAI):\n",
    "        self.domain = domain\n",
    "        self.llm = llm\n",
    "        self.config = DOMAIN_CONFIG.get(domain, {})\n",
    "        self.agent_name = self.config.get(\"agent_name\", f\"{domain} 전문가\")\n",
    "        self.description = self.config.get(\"description\", \"도메인 전문가\")\n",
    "    \n",
    "    def query(self, question: str, enable_corrective: bool = True) -> RAGResponse:\n",
    "        \"\"\"Mock 질문 처리 (실제 구현에서는 03번 노트북의 BaseRAGAgent 사용)\"\"\"\n",
    "        try:\n",
    "            # 간단한 답변 생성 (실제로는 벡터 검색 + LLM 체인 사용)\n",
    "            prompt = f\"당신은 꿀스테이의 {self.agent_name}입니다. 다음 질문에 {self.description} 관점에서 답변해주세요: {question}\"\n",
    "            \n",
    "            answer = self.llm.invoke(prompt).content\n",
    "            \n",
    "            # Mock 소스 문서\n",
    "            source_docs = [\n",
    "                Document(\n",
    "                    page_content=f\"{self.domain} 도메인 관련 정보\",\n",
    "                    metadata={\"domain\": self.domain, \"source\": \"mock_data\"}\n",
    "                )\n",
    "            ]\n",
    "            \n",
    "            return RAGResponse(\n",
    "                answer=answer,\n",
    "                source_documents=source_docs,\n",
    "                domain=self.domain,\n",
    "                confidence_score=0.8\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Mock 에이전트 질문 처리 실패 ({self.domain}): {e}\")\n",
    "            return RAGResponse(\n",
    "                answer=f\"죄송합니다. {self.domain} 관련 질문 처리 중 오류가 발생했습니다.\",\n",
    "                source_documents=[],\n",
    "                domain=self.domain,\n",
    "                confidence_score=0.1\n",
    "            )\n",
    "\n",
    "print(\"✅ Mock 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 초기화\n",
    "def initialize_llm():\n",
    "    try:\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.1,\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        \n",
    "        # 테스트 호출\n",
    "        test_response = llm.invoke(\"Hello\")\n",
    "        print(f\"✅ LLM 초기화 성공: {llm.model_name}\")\n",
    "        return llm\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ LLM 초기화 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "# Mock 에이전트들 생성 (실제 구현에서는 03번 노트북의 실제 에이전트 사용)\n",
    "def create_mock_agents(llm: ChatOpenAI) -> Dict[str, MockRAGAgent]:\n",
    "    \"\"\"Mock 에이전트 생성\"\"\"\n",
    "    agents = {}\n",
    "    \n",
    "    for domain in DOMAIN_CONFIG.keys():\n",
    "        if domain != \"web_search\":  # 웹검색은 별도 처리\n",
    "            agents[domain] = MockRAGAgent(domain, llm)\n",
    "    \n",
    "    print(f\"✅ Mock 에이전트 생성 완료: {len(agents)}개\")\n",
    "    return agents\n",
    "\n",
    "# 초기화\n",
    "llm = initialize_llm()\n",
    "if llm:\n",
    "    mock_agents = create_mock_agents(llm)\n",
    "else:\n",
    "    mock_agents = {}\n",
    "    print(\"❌ LLM이 초기화되지 않아 Mock 에이전트를 생성할 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 질문 분석 및 도메인 분류 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class QuestionAnalysis:\n",
    "    \"\"\"질문 분석 결과\"\"\"\n",
    "    original_question: str\n",
    "    question_type: str  # \"specific\", \"general\", \"comparison\", \"multi_domain\"\n",
    "    relevant_domains: List[str]  # 관련 도메인 목록\n",
    "    confidence_scores: Dict[str, float]  # 도메인별 신뢰도\n",
    "    keywords_found: List[str]  # 발견된 키워드\n",
    "    needs_web_search: bool  # 웹 검색 필요 여부\n",
    "    priority_domains: List[str]  # 우선순위 도메인\n",
    "    reasoning: str  # 분석 근거\n",
    "\n",
    "class QuestionAnalyzer:\n",
    "    \"\"\"질문 분석 및 도메인 분류기\"\"\"\n",
    "    \n",
    "    def __init__(self, llm: ChatOpenAI, domain_config: Dict[str, Dict]):\n",
    "        self.llm = llm\n",
    "        self.domain_config = domain_config\n",
    "        \n",
    "        # 도메인 분석 프롬프트\n",
    "        self.analysis_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        당신은 꿀스테이 회사의 질문을 분석하고 적절한 전문가 도메인을 선택하는 전문가입니다.\n",
    "        \n",
    "        **사용 가능한 도메인:**\n",
    "        {domain_descriptions}\n",
    "        \n",
    "        **질문:** {question}\n",
    "        \n",
    "        **분석 요청:**\n",
    "        1. 질문 유형 분류 (specific/general/comparison/multi_domain)\n",
    "        2. 관련 도메인 식별 (1-3개 추천)\n",
    "        3. 도메인별 관련도 점수 (0.0-1.0)\n",
    "        4. 웹 검색 필요성 판단\n",
    "        5. 우선순위 도메인 선정\n",
    "        \n",
    "        **분석 기준:**\n",
    "        - 키워드 매칭을 통한 도메인 식별\n",
    "        - 질문의 맥락과 의도 파악\n",
    "        - 최신 정보가 필요한 경우 웹 검색 추천\n",
    "        - 복합적인 질문의 경우 여러 도메인 선택\n",
    "        \n",
    "        다음 JSON 형식으로 응답하세요:\n",
    "        {{\n",
    "            \"question_type\": \"specific|general|comparison|multi_domain\",\n",
    "            \"relevant_domains\": [\"domain1\", \"domain2\", ...],\n",
    "            \"confidence_scores\": {{\"domain1\": 0.9, \"domain2\": 0.7, ...}},\n",
    "            \"keywords_found\": [\"keyword1\", \"keyword2\", ...],\n",
    "            \"needs_web_search\": true|false,\n",
    "            \"priority_domains\": [\"domain1\", \"domain2\"],\n",
    "            \"reasoning\": \"분석 근거 설명\"\n",
    "        }}\n",
    "        \"\"\")\n",
    "        \n",
    "        # 분석 체인 구성\n",
    "        self.analysis_chain = (\n",
    "            self.analysis_prompt\n",
    "            | self.llm\n",
    "            | JsonOutputParser()\n",
    "        )\n",
    "    \n",
    "    def _build_domain_descriptions(self) -> str:\n",
    "        \"\"\"도메인 설명 문자열 생성\"\"\"\n",
    "        descriptions = []\n",
    "        \n",
    "        for domain, config in self.domain_config.items():\n",
    "            agent_name = config.get(\"agent_name\", domain)\n",
    "            description = config.get(\"description\", \"\")\n",
    "            keywords = config.get(\"keywords\", [])\n",
    "            \n",
    "            desc_text = f\"- {domain}: {agent_name} ({description})\"\n",
    "            if keywords:\n",
    "                desc_text += f\" [키워드: {', '.join(keywords[:5])}]\"\n",
    "            \n",
    "            descriptions.append(desc_text)\n",
    "        \n",
    "        return \"\\n\".join(descriptions)\n",
    "    \n",
    "    def analyze_question(self, question: str) -> QuestionAnalysis:\n",
    "        \"\"\"질문 분석 수행\"\"\"\n",
    "        try:\n",
    "            domain_descriptions = self._build_domain_descriptions()\n",
    "            \n",
    "            result = self.analysis_chain.invoke({\n",
    "                \"question\": question,\n",
    "                \"domain_descriptions\": domain_descriptions\n",
    "            })\n",
    "            \n",
    "            return QuestionAnalysis(\n",
    "                original_question=question,\n",
    "                question_type=result.get(\"question_type\", \"general\"),\n",
    "                relevant_domains=result.get(\"relevant_domains\", []),\n",
    "                confidence_scores=result.get(\"confidence_scores\", {}),\n",
    "                keywords_found=result.get(\"keywords_found\", []),\n",
    "                needs_web_search=result.get(\"needs_web_search\", False),\n",
    "                priority_domains=result.get(\"priority_domains\", []),\n",
    "                reasoning=result.get(\"reasoning\", \"분석 완료\")\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"질문 분석 실패: {e}\")\n",
    "            # 기본값 반환\n",
    "            return QuestionAnalysis(\n",
    "                original_question=question,\n",
    "                question_type=\"general\",\n",
    "                relevant_domains=[\"hr_policy\"],  # 기본 도메인\n",
    "                confidence_scores={\"hr_policy\": 0.5},\n",
    "                keywords_found=[],\n",
    "                needs_web_search=False,\n",
    "                priority_domains=[\"hr_policy\"],\n",
    "                reasoning=\"분석 과정에서 오류 발생, 기본값 사용\"\n",
    "            )\n",
    "\n",
    "# 질문 분석기 초기화\n",
    "if llm:\n",
    "    question_analyzer = QuestionAnalyzer(llm, DOMAIN_CONFIG)\n",
    "    print(\"✅ 질문 분석기 초기화 완료\")\n",
    "else:\n",
    "    question_analyzer = None\n",
    "    print(\"❌ LLM이 초기화되지 않아 질문 분석기를 생성할 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 질문 분석 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 질문들\n",
    "test_questions = [\n",
    "    \"연차 휴가는 어떻게 신청하나요?\",  # hr_policy\n",
    "    \"코딩 스타일 가이드는 무엇인가요?\",  # tech_policy\n",
    "    \"시스템 아키텍처와 배포 프로세스를 설명해주세요\",  # multi_domain: architecture + deployment\n",
    "    \"2024년 AI 기술 트렌드는 무엇인가요?\",  # web_search\n",
    "    \"회사의 개발 프로세스와 UI 컴포넌트 가이드라인을 알려주세요\"  # multi_domain: development + component\n",
    "]\n",
    "\n",
    "def test_question_analysis(analyzer: QuestionAnalyzer, questions: List[str]):\n",
    "    \"\"\"질문 분석 테스트\"\"\"\n",
    "    \n",
    "    print(\"🔍 질문 분석 테스트 시작\\n\")\n",
    "    \n",
    "    for i, question in enumerate(questions, 1):\n",
    "        print(f\"📋 테스트 {i}: {question}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        try:\n",
    "            # 질문 분석 수행\n",
    "            analysis = analyzer.analyze_question(question)\n",
    "            \n",
    "            # 결과 출력\n",
    "            print(f\"🏷️  질문 유형: {analysis.question_type}\")\n",
    "            print(f\"🎯 관련 도메인: {', '.join(analysis.relevant_domains)}\")\n",
    "            print(f\"⭐ 우선순위: {', '.join(analysis.priority_domains)}\")\n",
    "            print(f\"🌐 웹 검색 필요: {'예' if analysis.needs_web_search else '아니오'}\")\n",
    "            \n",
    "            # 신뢰도 점수\n",
    "            if analysis.confidence_scores:\n",
    "                print(f\"📊 신뢰도 점수:\")\n",
    "                for domain, score in analysis.confidence_scores.items():\n",
    "                    print(f\"   - {domain}: {score:.2f}\")\n",
    "            \n",
    "            # 발견된 키워드\n",
    "            if analysis.keywords_found:\n",
    "                print(f\"🔤 키워드: {', '.join(analysis.keywords_found)}\")\n",
    "            \n",
    "            print(f\"💭 분석 근거: {analysis.reasoning}\")\n",
    "            print(f\"✅ 분석 완료\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 분석 실패: {e}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# 질문 분석 테스트 실행\n",
    "if question_analyzer:\n",
    "    test_question_analysis(question_analyzer, test_questions[:3])  # 처음 3개만 테스트\n",
    "else:\n",
    "    print(\"❌ 질문 분석기가 초기화되지 않아 테스트를 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 멀티 에이전트 답변 통합 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class IntegratedResponse:\n",
    "    \"\"\"통합된 최종 응답\"\"\"\n",
    "    final_answer: str\n",
    "    contributing_domains: List[str]\n",
    "    individual_responses: Dict[str, RAGResponse]\n",
    "    integration_method: str  # \"single\", \"combined\", \"ranked\"\n",
    "    overall_confidence: float\n",
    "    source_summary: List[str]\n",
    "    processing_time: float\n",
    "\n",
    "class ResponseIntegrator:\n",
    "    \"\"\"멀티 에이전트 응답 통합기\"\"\"\n",
    "    \n",
    "    def __init__(self, llm: ChatOpenAI):\n",
    "        self.llm = llm\n",
    "        \n",
    "        # 단일 응답 선택 프롬프트\n",
    "        self.single_selection_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        여러 전문가의 답변 중에서 질문에 가장 적합한 답변을 선택해주세요.\n",
    "        \n",
    "        **질문:** {question}\n",
    "        \n",
    "        **전문가 답변들:**\n",
    "        {responses}\n",
    "        \n",
    "        **선택 기준:**\n",
    "        1. 질문과의 직접적 관련성\n",
    "        2. 답변의 구체성과 완성도\n",
    "        3. 전문가의 신뢰도\n",
    "        \n",
    "        가장 적합한 답변을 선택하고, 필요시 약간의 수정을 가해 최종 답변을 제공하세요.\n",
    "        \"\"\")\n",
    "        \n",
    "        # 복합 통합 프롬프트\n",
    "        self.integration_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        여러 전문가의 답변을 통합하여 포괄적인 최종 답변을 만들어주세요.\n",
    "        \n",
    "        **질문:** {question}\n",
    "        \n",
    "        **전문가 답변들:**\n",
    "        {responses}\n",
    "        \n",
    "        **통합 지침:**\n",
    "        1. 각 전문가의 고유한 관점을 존중하여 통합\n",
    "        2. 중복되는 내용은 정리하고 보완적인 내용은 조합\n",
    "        3. 전문 분야별로 구분하여 체계적으로 구성\n",
    "        4. 일관성 있고 자연스러운 흐름으로 작성\n",
    "        5. 각 정보의 출처(전문가)를 명시\n",
    "        \n",
    "        통합된 최종 답변을 제공하세요.\n",
    "        \"\"\")\n",
    "        \n",
    "        # 체인 구성\n",
    "        self.single_chain = self.single_selection_prompt | self.llm | StrOutputParser()\n",
    "        self.integration_chain = self.integration_prompt | self.llm | StrOutputParser()\n",
    "    \n",
    "    def _format_responses(self, responses: Dict[str, RAGResponse]) -> str:\n",
    "        \"\"\"응답들을 포맷팅\"\"\"\n",
    "        formatted = []\n",
    "        \n",
    "        for domain, response in responses.items():\n",
    "            domain_config = DOMAIN_CONFIG.get(domain, {})\n",
    "            agent_name = domain_config.get(\"agent_name\", f\"{domain} 전문가\")\n",
    "            \n",
    "            formatted.append(\n",
    "                f\"**{agent_name} ({domain})**\\n\"\n",
    "                f\"신뢰도: {response.confidence_score:.2f}\\n\"\n",
    "                f\"답변: {response.answer}\\n\"\n",
    "                f\"출처: {len(response.source_documents)}개 문서\"\n",
    "            )\n",
    "        \n",
    "        return \"\\n\\n\".join(formatted)\n",
    "    \n",
    "    def integrate_responses(self, \n",
    "                          question: str,\n",
    "                          responses: Dict[str, RAGResponse],\n",
    "                          integration_method: str = \"auto\") -> IntegratedResponse:\n",
    "        \"\"\"응답 통합 수행\"\"\"\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        if not responses:\n",
    "            return IntegratedResponse(\n",
    "                final_answer=\"죄송합니다. 답변을 생성할 수 없습니다.\",\n",
    "                contributing_domains=[],\n",
    "                individual_responses={},\n",
    "                integration_method=\"none\",\n",
    "                overall_confidence=0.0,\n",
    "                source_summary=[],\n",
    "                processing_time=0.0\n",
    "            )\n",
    "        \n",
    "        # 통합 방식 결정\n",
    "        if integration_method == \"auto\":\n",
    "            if len(responses) == 1:\n",
    "                integration_method = \"single\"\n",
    "            elif len(responses) <= 2:\n",
    "                integration_method = \"combined\"\n",
    "            else:\n",
    "                integration_method = \"ranked\"\n",
    "        \n",
    "        try:\n",
    "            formatted_responses = self._format_responses(responses)\n",
    "            \n",
    "            if integration_method == \"single\":\n",
    "                # 단일 응답 선택\n",
    "                if len(responses) == 1:\n",
    "                    final_answer = list(responses.values())[0].answer\n",
    "                else:\n",
    "                    final_answer = self.single_chain.invoke({\n",
    "                        \"question\": question,\n",
    "                        \"responses\": formatted_responses\n",
    "                    })\n",
    "            \n",
    "            else:\n",
    "                # 복합 통합\n",
    "                final_answer = self.integration_chain.invoke({\n",
    "                    \"question\": question,\n",
    "                    \"responses\": formatted_responses\n",
    "                })\n",
    "            \n",
    "            # 전체 신뢰도 계산\n",
    "            confidence_scores = [r.confidence_score for r in responses.values()]\n",
    "            overall_confidence = sum(confidence_scores) / len(confidence_scores)\n",
    "            \n",
    "            # 출처 요약\n",
    "            source_summary = []\n",
    "            for domain, response in responses.items():\n",
    "                source_count = len(response.source_documents)\n",
    "                if source_count > 0:\n",
    "                    agent_name = DOMAIN_CONFIG.get(domain, {}).get(\"agent_name\", domain)\n",
    "                    source_summary.append(f\"{agent_name}: {source_count}개 문서\")\n",
    "            \n",
    "            processing_time = (datetime.now() - start_time).total_seconds()\n",
    "            \n",
    "            return IntegratedResponse(\n",
    "                final_answer=final_answer,\n",
    "                contributing_domains=list(responses.keys()),\n",
    "                individual_responses=responses,\n",
    "                integration_method=integration_method,\n",
    "                overall_confidence=overall_confidence,\n",
    "                source_summary=source_summary,\n",
    "                processing_time=processing_time\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"응답 통합 실패: {e}\")\n",
    "            # 첫 번째 응답을 기본값으로 사용\n",
    "            first_response = list(responses.values())[0]\n",
    "            \n",
    "            return IntegratedResponse(\n",
    "                final_answer=first_response.answer,\n",
    "                contributing_domains=list(responses.keys()),\n",
    "                individual_responses=responses,\n",
    "                integration_method=\"fallback\",\n",
    "                overall_confidence=first_response.confidence_score,\n",
    "                source_summary=[f\"단일 응답: {len(first_response.source_documents)}개 문서\"],\n",
    "                processing_time=(datetime.now() - start_time).total_seconds()\n",
    "            )\n",
    "\n",
    "# 응답 통합기 초기화\n",
    "if llm:\n",
    "    response_integrator = ResponseIntegrator(llm)\n",
    "    print(\"✅ 응답 통합기 초기화 완료\")\n",
    "else:\n",
    "    response_integrator = None\n",
    "    print(\"❌ LLM이 초기화되지 않아 응답 통합기를 생성할 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LangGraph 워크플로우 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# LangGraph 상태 정의\nclass RAGWorkflowState(TypedDict):\n    \"\"\"RAG 워크플로우 상태\"\"\"\n    question: str\n    question_analysis: Optional[QuestionAnalysis]\n    selected_agents: List[str]\n    agent_responses: Dict[str, RAGResponse]\n    integrated_response: Optional[IntegratedResponse]\n    error_message: Optional[str]\n    processing_start_time: Optional[datetime]\n\nclass CoolStayRAGWorkflow:\n    \"\"\"꿀스테이 RAG 워크플로우 관리자\"\"\"\n    \n    def __init__(self, \n                 question_analyzer: QuestionAnalyzer,\n                 agents: Dict[str, MockRAGAgent],\n                 response_integrator: ResponseIntegrator):\n        \n        self.question_analyzer = question_analyzer\n        self.agents = agents\n        self.response_integrator = response_integrator\n        \n        # 워크플로우 그래프 구성\n        self._build_workflow()\n    \n    def _build_workflow(self):\n        \"\"\"워크플로우 그래프 구성\"\"\"\n        \n        # StateGraph 생성\n        workflow = StateGraph(RAGWorkflowState)\n        \n        # 노드 추가\n        workflow.add_node(\"analyze_question\", self._analyze_question)\n        workflow.add_node(\"select_agents\", self._select_agents)\n        workflow.add_node(\"execute_agents\", self._execute_agents)\n        workflow.add_node(\"integrate_responses\", self._integrate_responses)\n        \n        # 엣지 추가\n        workflow.set_entry_point(\"analyze_question\")\n        workflow.add_edge(\"analyze_question\", \"select_agents\")\n        workflow.add_edge(\"select_agents\", \"execute_agents\")\n        workflow.add_edge(\"execute_agents\", \"integrate_responses\")\n        workflow.add_edge(\"integrate_responses\", END)\n        \n        # 메모리 설정 (선택사항) - checkpointer 없이 컴파일\n        # memory = MemorySaver()\n        \n        # 워크플로우 컴파일 (checkpointer 제거)\n        self.workflow = workflow.compile()\n    \n    def _analyze_question(self, state: RAGWorkflowState) -> RAGWorkflowState:\n        \"\"\"질문 분석 단계\"\"\"\n        try:\n            logger.info(\"질문 분석 시작\")\n            \n            analysis = self.question_analyzer.analyze_question(state[\"question\"])\n            \n            state[\"question_analysis\"] = analysis\n            state[\"processing_start_time\"] = datetime.now()\n            \n            logger.info(f\"질문 분석 완료: {len(analysis.relevant_domains)}개 도메인 식별\")\n            \n        except Exception as e:\n            logger.error(f\"질문 분석 실패: {e}\")\n            state[\"error_message\"] = f\"질문 분석 실패: {e}\"\n        \n        return state\n    \n    def _select_agents(self, state: RAGWorkflowState) -> RAGWorkflowState:\n        \"\"\"에이전트 선택 단계\"\"\"\n        try:\n            logger.info(\"에이전트 선택 시작\")\n            \n            analysis = state.get(\"question_analysis\")\n            if not analysis:\n                # 기본 에이전트 선택\n                selected_agents = [\"hr_policy\"]\n            else:\n                # 우선순위 도메인을 기반으로 선택\n                selected_agents = analysis.priority_domains[:3]  # 최대 3개 에이전트\n                \n                # 웹 검색이 필요한 경우 추가\n                if analysis.needs_web_search:\n                    selected_agents.append(\"web_search\")\n            \n            # 사용 가능한 에이전트만 필터링\n            available_agents = []\n            for agent in selected_agents:\n                if agent in self.agents or agent == \"web_search\":\n                    available_agents.append(agent)\n            \n            state[\"selected_agents\"] = available_agents\n            \n            logger.info(f\"에이전트 선택 완료: {available_agents}\")\n            \n        except Exception as e:\n            logger.error(f\"에이전트 선택 실패: {e}\")\n            state[\"selected_agents\"] = [\"hr_policy\"]  # 기본 에이전트\n        \n        return state\n    \n    def _execute_agents(self, state: RAGWorkflowState) -> RAGWorkflowState:\n        \"\"\"에이전트 실행 단계\"\"\"\n        try:\n            logger.info(\"에이전트 실행 시작\")\n            \n            question = state[\"question\"]\n            selected_agents = state.get(\"selected_agents\", [])\n            responses = {}\n            \n            for agent_name in selected_agents:\n                if agent_name == \"web_search\":\n                    # 웹 검색 에이전트 처리 (Mock)\n                    responses[agent_name] = RAGResponse(\n                        answer=f\"웹 검색 결과: {question}에 대한 최신 정보를 검색했습니다.\",\n                        source_documents=[],\n                        domain=agent_name,\n                        confidence_score=0.7\n                    )\n                elif agent_name in self.agents:\n                    # 일반 RAG 에이전트 실행\n                    agent = self.agents[agent_name]\n                    response = agent.query(question, enable_corrective=True)\n                    responses[agent_name] = response\n                    \n                logger.info(f\"{agent_name} 에이전트 실행 완료\")\n            \n            state[\"agent_responses\"] = responses\n            \n            logger.info(f\"모든 에이전트 실행 완료: {len(responses)}개 응답\")\n            \n        except Exception as e:\n            logger.error(f\"에이전트 실행 실패: {e}\")\n            state[\"error_message\"] = f\"에이전트 실행 실패: {e}\"\n        \n        return state\n    \n    def _integrate_responses(self, state: RAGWorkflowState) -> RAGWorkflowState:\n        \"\"\"응답 통합 단계\"\"\"\n        try:\n            logger.info(\"응답 통합 시작\")\n            \n            question = state[\"question\"]\n            agent_responses = state.get(\"agent_responses\", {})\n            \n            if not agent_responses:\n                state[\"error_message\"] = \"통합할 응답이 없습니다.\"\n                return state\n            \n            # 응답 통합 수행\n            integrated_response = self.response_integrator.integrate_responses(\n                question=question,\n                responses=agent_responses,\n                integration_method=\"auto\"\n            )\n            \n            state[\"integrated_response\"] = integrated_response\n            \n            logger.info(\"응답 통합 완료\")\n            \n        except Exception as e:\n            logger.error(f\"응답 통합 실패: {e}\")\n            state[\"error_message\"] = f\"응답 통합 실패: {e}\"\n        \n        return state\n    \n    def process_question(self, question: str) -> IntegratedResponse:\n        \"\"\"질문 처리 (전체 워크플로우 실행)\"\"\"\n        \n        # 초기 상태 설정\n        initial_state = {\n            \"question\": question,\n            \"question_analysis\": None,\n            \"selected_agents\": [],\n            \"agent_responses\": {},\n            \"integrated_response\": None,\n            \"error_message\": None,\n            \"processing_start_time\": None\n        }\n        \n        try:\n            # 워크플로우 실행 (checkpointer가 없으므로 config 불필요)\n            result = self.workflow.invoke(initial_state)\n            \n            # 결과 반환\n            if result.get(\"integrated_response\"):\n                return result[\"integrated_response\"]\n            else:\n                # 오류 발생 시 기본 응답\n                error_msg = result.get(\"error_message\", \"알 수 없는 오류\")\n                return IntegratedResponse(\n                    final_answer=f\"죄송합니다. 질문 처리 중 오류가 발생했습니다: {error_msg}\",\n                    contributing_domains=[],\n                    individual_responses={},\n                    integration_method=\"error\",\n                    overall_confidence=0.0,\n                    source_summary=[],\n                    processing_time=0.0\n                )\n                \n        except Exception as e:\n            logger.error(f\"워크플로우 실행 실패: {e}\")\n            return IntegratedResponse(\n                final_answer=f\"죄송합니다. 시스템 오류가 발생했습니다: {e}\",\n                contributing_domains=[],\n                individual_responses={},\n                integration_method=\"system_error\",\n                overall_confidence=0.0,\n                source_summary=[],\n                processing_time=0.0\n            )\n\n# 워크플로우 생성\nif all([question_analyzer, mock_agents, response_integrator]):\n    rag_workflow = CoolStayRAGWorkflow(\n        question_analyzer=question_analyzer,\n        agents=mock_agents,\n        response_integrator=response_integrator\n    )\n    print(\"✅ RAG 워크플로우 생성 완료\")\nelse:\n    rag_workflow = None\n    missing = []\n    if not question_analyzer: missing.append(\"질문 분석기\")\n    if not mock_agents: missing.append(\"에이전트\")\n    if not response_integrator: missing.append(\"응답 통합기\")\n    print(f\"❌ RAG 워크플로우를 생성할 수 없습니다. 누락: {', '.join(missing)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 통합 워크플로우 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_integrated_workflow(workflow: CoolStayRAGWorkflow, test_questions: List[str]):\n",
    "    \"\"\"통합 워크플로우 테스트\"\"\"\n",
    "    \n",
    "    print(\"🚀 통합 RAG 워크플로우 테스트 시작\\n\")\n",
    "    \n",
    "    test_results = []\n",
    "    \n",
    "    for i, question in enumerate(test_questions, 1):\n",
    "        print(f\"📋 테스트 {i}: {question}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        try:\n",
    "            start_time = datetime.now()\n",
    "            \n",
    "            # 통합 워크플로우 실행\n",
    "            result = workflow.process_question(question)\n",
    "            \n",
    "            end_time = datetime.now()\n",
    "            total_time = (end_time - start_time).total_seconds()\n",
    "            \n",
    "            # 결과 출력\n",
    "            print(f\"\\n💬 최종 답변:\")\n",
    "            print(result.final_answer[:400] + \"...\" if len(result.final_answer) > 400 else result.final_answer)\n",
    "            \n",
    "            print(f\"\\n📊 처리 정보:\")\n",
    "            print(f\"   - 참여 도메인: {', '.join(result.contributing_domains)}\")\n",
    "            print(f\"   - 통합 방식: {result.integration_method}\")\n",
    "            print(f\"   - 전체 신뢰도: {result.overall_confidence:.2f}\")\n",
    "            print(f\"   - 처리 시간: {total_time:.2f}초\")\n",
    "            \n",
    "            if result.source_summary:\n",
    "                print(f\"   - 출처 요약: {', '.join(result.source_summary)}\")\n",
    "            \n",
    "            # 개별 응답 요약\n",
    "            if result.individual_responses:\n",
    "                print(f\"\\n🤖 개별 에이전트 응답:\")\n",
    "                for domain, response in result.individual_responses.items():\n",
    "                    agent_name = DOMAIN_CONFIG.get(domain, {}).get(\"agent_name\", domain)\n",
    "                    print(f\"   - {agent_name}: 신뢰도 {response.confidence_score:.2f}\")\n",
    "            \n",
    "            # 테스트 결과 저장\n",
    "            test_result = {\n",
    "                \"question\": question,\n",
    "                \"domains_used\": len(result.contributing_domains),\n",
    "                \"integration_method\": result.integration_method,\n",
    "                \"confidence\": result.overall_confidence,\n",
    "                \"processing_time\": total_time,\n",
    "                \"success\": True\n",
    "            }\n",
    "            test_results.append(test_result)\n",
    "            \n",
    "            print(f\"\\n✅ 테스트 완료\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 테스트 실패: {e}\")\n",
    "            logger.error(f\"워크플로우 테스트 실패 ({question}): {e}\")\n",
    "            \n",
    "            test_results.append({\n",
    "                \"question\": question,\n",
    "                \"domains_used\": 0,\n",
    "                \"integration_method\": \"error\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"processing_time\": 0.0,\n",
    "                \"success\": False\n",
    "            })\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # 전체 테스트 결과 요약\n",
    "    print(f\"📈 전체 테스트 결과 요약\")\n",
    "    print(f\"   - 총 테스트: {len(test_results)}개\")\n",
    "    successful_tests = [r for r in test_results if r['success']]\n",
    "    print(f\"   - 성공한 테스트: {len(successful_tests)}개\")\n",
    "    print(f\"   - 성공률: {len(successful_tests)/len(test_results)*100:.1f}%\")\n",
    "    \n",
    "    if successful_tests:\n",
    "        avg_confidence = sum(r['confidence'] for r in successful_tests) / len(successful_tests)\n",
    "        avg_processing_time = sum(r['processing_time'] for r in successful_tests) / len(successful_tests)\n",
    "        avg_domains = sum(r['domains_used'] for r in successful_tests) / len(successful_tests)\n",
    "        \n",
    "        print(f\"\\n📊 평균 성능 지표:\")\n",
    "        print(f\"   - 평균 신뢰도: {avg_confidence:.2f}\")\n",
    "        print(f\"   - 평균 처리 시간: {avg_processing_time:.2f}초\")\n",
    "        print(f\"   - 평균 사용 도메인: {avg_domains:.1f}개\")\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# 통합 워크플로우 테스트 실행\n",
    "workflow_test_questions = [\n",
    "    \"연차 휴가 신청 방법을 알려주세요\",\n",
    "    \"시스템 아키텍처와 배포 방법을 설명해주세요\",\n",
    "    \"회사 정책에 대해 전반적으로 설명해주세요\"\n",
    "]\n",
    "\n",
    "if rag_workflow:\n",
    "    workflow_test_results = test_integrated_workflow(rag_workflow, workflow_test_questions)\n",
    "    print(\"\\n✅ 통합 워크플로우 테스트 완료!\")\n",
    "else:\n",
    "    print(\"❌ RAG 워크플로우가 생성되지 않아 테스트를 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 요약 및 다음 단계\n",
    "\n",
    "### ✅ 완료된 작업\n",
    "1. **질문 분석 시스템**: AI 기반 도메인 분류 및 에이전트 선택\n",
    "2. **멀티 에이전트 라우팅**: 최적의 전문가 조합 자동 선택\n",
    "3. **응답 통합 시스템**: 단일/복합 답변 지능형 통합\n",
    "4. **LangGraph 워크플로우**: 전체 파이프라인 오케스트레이션\n",
    "5. **통합 테스트**: 엔드투엔드 시스템 검증\n",
    "\n",
    "### 🔧 핵심 기능\n",
    "- **Intelligent Routing**: 질문 내용 기반 최적 에이전트 자동 선택\n",
    "- **Multi-Agent Orchestration**: 1-3개 도메인 전문가 동적 조합\n",
    "- **Response Integration**: 단일 선택, 복합 통합, 순위 기반 통합\n",
    "- **Workflow Management**: LangGraph 기반 상태 관리 파이프라인\n",
    "- **Error Handling**: 각 단계별 오류 처리 및 복구\n",
    "\n",
    "### 📊 시스템 특징\n",
    "- **확장 가능**: 새로운 도메인/에이전트 쉽게 추가\n",
    "- **유연한 통합**: 질문 복잡도에 따른 적응형 응답 생성\n",
    "- **상태 추적**: 전체 처리 과정 모니터링 가능\n",
    "- **신뢰도 기반**: 에이전트별 신뢰도 계산 및 가중 평균\n",
    "\n",
    "### 🚀 다음 단계\n",
    "**05_hitl_evaluation.ipynb**: Human-in-the-Loop 평가 시스템\n",
    "- ReAct 평가 에이전트 구현\n",
    "- 6차원 품질 평가 시스템\n",
    "- 인터럽트 기반 인간 검증\n",
    "- 품질 기반 피드백 루프"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}