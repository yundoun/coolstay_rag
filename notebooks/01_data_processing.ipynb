{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "001",
   "metadata": {},
   "source": [
    "# ğŸ“š 01. ë°ì´í„° ì²˜ë¦¬ ë° ì „ì²˜ë¦¬\n",
    "\n",
    "## ëª©í‘œ\n",
    "- ê¿€ìŠ¤í…Œì´ 7ê°œ ë„ë©”ì¸ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë¡œë”©\n",
    "- ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ë° íŒŒì‹±\n",
    "- ì²­í‚¹ ì „ëµ ì‹¤í—˜\n",
    "- ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004",
   "metadata": {},
   "source": [
    "## 2. ë„ë©”ì¸ ì„¤ì • ë° íŒŒì¼ ê²½ë¡œ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ë°ì´í„° ë””ë ‰í† ë¦¬: /Users/yundoun/Desktop/project/legal_rag/coolstay_rag/notebooks/../data\n",
      "ğŸ“Š ì´ 7ê°œ ë„ë©”ì¸ ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë„ë©”ì¸ë³„ ì„¤ì •\n",
    "DOMAIN_CONFIG = {\n",
    "    \"hr_policy\": {\n",
    "        \"file\": \"HR_Policy_Guide.md\",\n",
    "        \"description\": \"ì¸ì‚¬ì •ì±…, ê·¼ë¬´ì‹œê°„, íœ´ê°€, ê¸‰ì—¬, ë³µë¦¬í›„ìƒ\",\n",
    "        \"keywords\": [\"ê·¼ë¬´ì‹œê°„\", \"íœ´ê°€\", \"ê¸‰ì—¬\", \"ë³µë¦¬í›„ìƒ\", \"ì¸ì‚¬\", \"ì±„ìš©\", \"í‰ê°€\"]\n",
    "    },\n",
    "    \"tech_policy\": {\n",
    "        \"file\": \"Tech_Policy_Guide.md\",\n",
    "        \"description\": \"ê¸°ìˆ ì •ì±…, ê°œë°œí™˜ê²½, ì½”ë”©í‘œì¤€, ë³´ì•ˆì •ì±…\",\n",
    "        \"keywords\": [\"ê°œë°œ\", \"ê¸°ìˆ \", \"ì½”ë”©\", \"ë³´ì•ˆ\", \"í…ŒìŠ¤íŠ¸\", \"ë°°í¬\", \"ì¸í”„ë¼\"]\n",
    "    },\n",
    "    \"architecture\": {\n",
    "        \"file\": \"Architecture_Guide.md\",\n",
    "        \"description\": \"CMS ì•„í‚¤í…ì²˜, ì‹œìŠ¤í…œì„¤ê³„, ë ˆì´ì–´êµ¬ì¡°\",\n",
    "        \"keywords\": [\"ì•„í‚¤í…ì²˜\", \"ì‹œìŠ¤í…œ\", \"ì„¤ê³„\", \"êµ¬ì¡°\", \"ë ˆì´ì–´\", \"ëª¨ë“ˆ\"]\n",
    "    },\n",
    "    \"component\": {\n",
    "        \"file\": \"Component_Guide.md\",\n",
    "        \"description\": \"ì»´í¬ë„ŒíŠ¸ ê°€ì´ë“œë¼ì¸, UI/UX í‘œì¤€\",\n",
    "        \"keywords\": [\"ì»´í¬ë„ŒíŠ¸\", \"UI\", \"UX\", \"ë””ìì¸\", \"ì¸í„°í˜ì´ìŠ¤\", \"ì‚¬ìš©ì\"]\n",
    "    },\n",
    "    \"deployment\": {\n",
    "        \"file\": \"Deployment_Guide.md\",\n",
    "        \"description\": \"ë°°í¬í”„ë¡œì„¸ìŠ¤, CI/CD, í™˜ê²½ê´€ë¦¬\",\n",
    "        \"keywords\": [\"ë°°í¬\", \"CI/CD\", \"í™˜ê²½\", \"ë¹Œë“œ\", \"ë¦´ë¦¬ìŠ¤\", \"ìš´ì˜\"]\n",
    "    },\n",
    "    \"development\": {\n",
    "        \"file\": \"Development_Process_Guide.md\",\n",
    "        \"description\": \"ê°œë°œí”„ë¡œì„¸ìŠ¤, ì›Œí¬í”Œë¡œìš°, í˜‘ì—…ê·œì¹™\",\n",
    "        \"keywords\": [\"í”„ë¡œì„¸ìŠ¤\", \"ì›Œí¬í”Œë¡œìš°\", \"í˜‘ì—…\", \"ìŠ¤í”„ë¦°íŠ¸\", \"ì• ìì¼\"]\n",
    "    },\n",
    "    \"business_policy\": {\n",
    "        \"file\": \"Business_Policy_Guide.md\",\n",
    "        \"description\": \"ë¹„ì¦ˆë‹ˆìŠ¤ì •ì±…, ìš´ì˜ê·œì¹™, ì˜ì‚¬ê²°ì •\",\n",
    "        \"keywords\": [\"ë¹„ì¦ˆë‹ˆìŠ¤\", \"ì •ì±…\", \"ìš´ì˜\", \"ì˜ì‚¬ê²°ì •\", \"ì „ëµ\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ ì„¤ì •\n",
    "DATA_DIR = Path(\"../data\")\n",
    "print(f\"ğŸ“ ë°ì´í„° ë””ë ‰í† ë¦¬: {DATA_DIR.absolute()}\")\n",
    "print(f\"ğŸ“Š ì´ {len(DOMAIN_CONFIG)}ê°œ ë„ë©”ì¸ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006",
   "metadata": {},
   "source": [
    "## 3. ë¬¸ì„œ ë¡œë”© ë° ê¸°ë³¸ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… hr_policy: 1,782ì, 93ì¤„\n",
      "âœ… tech_policy: 3,889ì, 172ì¤„\n",
      "âœ… architecture: 12,779ì, 542ì¤„\n",
      "âœ… component: 7,689ì, 423ì¤„\n",
      "âœ… deployment: 5,436ì, 306ì¤„\n",
      "âœ… development: 3,562ì, 181ì¤„\n",
      "âœ… business_policy: 2,243ì, 110ì¤„\n",
      "\n",
      "ğŸ“š ì´ 7ê°œ ë¬¸ì„œ ë¡œë”© ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def load_markdown_files() -> Dict[str, str]:\n",
    "    \"\"\"ëª¨ë“  ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ ë¡œë”©í•©ë‹ˆë‹¤.\"\"\"\n",
    "    documents = {}\n",
    "    \n",
    "    for domain, config in DOMAIN_CONFIG.items():\n",
    "        file_path = DATA_DIR / config[\"file\"]\n",
    "        \n",
    "        if file_path.exists():\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "                documents[domain] = content\n",
    "                print(f\"âœ… {domain}: {len(content):,}ì, {len(content.splitlines())}ì¤„\")\n",
    "        else:\n",
    "            print(f\"âŒ {domain}: íŒŒì¼ ì—†ìŒ - {file_path}\")\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# ë¬¸ì„œ ë¡œë”©\n",
    "raw_documents = load_markdown_files()\n",
    "print(f\"\\nğŸ“š ì´ {len(raw_documents)}ê°œ ë¬¸ì„œ ë¡œë”© ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008",
   "metadata": {},
   "source": [
    "## 4. ë§ˆí¬ë‹¤ìš´ êµ¬ì¡° ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ HR_POLICY êµ¬ì¡° ë¶„ì„:\n",
      "  - ì´ ë¼ì¸: 93ì¤„\n",
      "  - ì´ ë¬¸ì: 1,782ì\n",
      "  - H1 í—¤ë”: 1ê°œ\n",
      "  - H2 í—¤ë”: 7ê°œ\n",
      "  - H3 í—¤ë”: 13ê°œ\n",
      "  - ì½”ë“œ ë¸”ë¡: 0ê°œ\n",
      "  - ë¶ˆë¦¿ í¬ì¸íŠ¸: 47ê°œ\n",
      "\n",
      "ğŸ“‹ TECH_POLICY êµ¬ì¡° ë¶„ì„:\n",
      "  - ì´ ë¼ì¸: 172ì¤„\n",
      "  - ì´ ë¬¸ì: 3,889ì\n",
      "  - H1 í—¤ë”: 1ê°œ\n",
      "  - H2 í—¤ë”: 9ê°œ\n",
      "  - H3 í—¤ë”: 22ê°œ\n",
      "  - ì½”ë“œ ë¸”ë¡: 3ê°œ\n",
      "  - ë¶ˆë¦¿ í¬ì¸íŠ¸: 76ê°œ\n",
      "\n",
      "ğŸ“‹ ARCHITECTURE êµ¬ì¡° ë¶„ì„:\n",
      "  - ì´ ë¼ì¸: 542ì¤„\n",
      "  - ì´ ë¬¸ì: 12,779ì\n",
      "  - H1 í—¤ë”: 1ê°œ\n",
      "  - H2 í—¤ë”: 11ê°œ\n",
      "  - H3 í—¤ë”: 22ê°œ\n",
      "  - ì½”ë“œ ë¸”ë¡: 22ê°œ\n",
      "  - ë¶ˆë¦¿ í¬ì¸íŠ¸: 0ê°œ\n",
      "\n",
      "ğŸ“‹ COMPONENT êµ¬ì¡° ë¶„ì„:\n",
      "  - ì´ ë¼ì¸: 423ì¤„\n",
      "  - ì´ ë¬¸ì: 7,689ì\n",
      "  - H1 í—¤ë”: 1ê°œ\n",
      "  - H2 í—¤ë”: 11ê°œ\n",
      "  - H3 í—¤ë”: 25ê°œ\n",
      "  - ì½”ë“œ ë¸”ë¡: 22ê°œ\n",
      "  - ë¶ˆë¦¿ í¬ì¸íŠ¸: 17ê°œ\n",
      "\n",
      "ğŸ“‹ DEPLOYMENT êµ¬ì¡° ë¶„ì„:\n",
      "  - ì´ ë¼ì¸: 306ì¤„\n",
      "  - ì´ ë¬¸ì: 5,436ì\n",
      "  - H1 í—¤ë”: 19ê°œ\n",
      "  - H2 í—¤ë”: 10ê°œ\n",
      "  - H3 í—¤ë”: 23ê°œ\n",
      "  - ì½”ë“œ ë¸”ë¡: 11ê°œ\n",
      "  - ë¶ˆë¦¿ í¬ì¸íŠ¸: 47ê°œ\n",
      "\n",
      "ğŸ“‹ DEVELOPMENT êµ¬ì¡° ë¶„ì„:\n",
      "  - ì´ ë¼ì¸: 181ì¤„\n",
      "  - ì´ ë¬¸ì: 3,562ì\n",
      "  - H1 í—¤ë”: 1ê°œ\n",
      "  - H2 í—¤ë”: 8ê°œ\n",
      "  - H3 í—¤ë”: 19ê°œ\n",
      "  - ì½”ë“œ ë¸”ë¡: 1ê°œ\n",
      "  - ë¶ˆë¦¿ í¬ì¸íŠ¸: 74ê°œ\n",
      "\n",
      "ğŸ“‹ BUSINESS_POLICY êµ¬ì¡° ë¶„ì„:\n",
      "  - ì´ ë¼ì¸: 110ì¤„\n",
      "  - ì´ ë¬¸ì: 2,243ì\n",
      "  - H1 í—¤ë”: 1ê°œ\n",
      "  - H2 í—¤ë”: 7ê°œ\n",
      "  - H3 í—¤ë”: 15ê°œ\n",
      "  - ì½”ë“œ ë¸”ë¡: 0ê°œ\n",
      "  - ë¶ˆë¦¿ í¬ì¸íŠ¸: 60ê°œ\n"
     ]
    }
   ],
   "source": [
    "def analyze_markdown_structure(content: str, domain: str) -> Dict[str, Any]:\n",
    "    \"\"\"ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œì˜ êµ¬ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.\"\"\"\n",
    "    lines = content.split('\\n')\n",
    "    \n",
    "    # í—¤ë” êµ¬ì¡° ë¶„ì„\n",
    "    headers = {\n",
    "        'h1': [],\n",
    "        'h2': [],\n",
    "        'h3': [],\n",
    "        'h4': []\n",
    "    }\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if line.startswith('# '):\n",
    "            headers['h1'].append((i, line.strip('# ').strip()))\n",
    "        elif line.startswith('## '):\n",
    "            headers['h2'].append((i, line.strip('# ').strip()))\n",
    "        elif line.startswith('### '):\n",
    "            headers['h3'].append((i, line.strip('# ').strip()))\n",
    "        elif line.startswith('#### '):\n",
    "            headers['h4'].append((i, line.strip('# ').strip()))\n",
    "    \n",
    "    # ì½”ë“œ ë¸”ë¡ ë° íŠ¹ìˆ˜ êµ¬ì¡° ë¶„ì„\n",
    "    code_blocks = len(re.findall(r'```[\\s\\S]*?```', content))\n",
    "    bullet_points = len(re.findall(r'^[-*+]\\s', content, re.MULTILINE))\n",
    "    numbered_lists = len(re.findall(r'^\\d+\\.\\s', content, re.MULTILINE))\n",
    "    \n",
    "    return {\n",
    "        'domain': domain,\n",
    "        'total_lines': len(lines),\n",
    "        'total_chars': len(content),\n",
    "        'headers': headers,\n",
    "        'code_blocks': code_blocks,\n",
    "        'bullet_points': bullet_points,\n",
    "        'numbered_lists': numbered_lists\n",
    "    }\n",
    "\n",
    "# ê° ë¬¸ì„œ êµ¬ì¡° ë¶„ì„\n",
    "document_structures = {}\n",
    "for domain, content in raw_documents.items():\n",
    "    structure = analyze_markdown_structure(content, domain)\n",
    "    document_structures[domain] = structure\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ {domain.upper()} êµ¬ì¡° ë¶„ì„:\")\n",
    "    print(f\"  - ì´ ë¼ì¸: {structure['total_lines']:,}ì¤„\")\n",
    "    print(f\"  - ì´ ë¬¸ì: {structure['total_chars']:,}ì\")\n",
    "    print(f\"  - H1 í—¤ë”: {len(structure['headers']['h1'])}ê°œ\")\n",
    "    print(f\"  - H2 í—¤ë”: {len(structure['headers']['h2'])}ê°œ\")\n",
    "    print(f\"  - H3 í—¤ë”: {len(structure['headers']['h3'])}ê°œ\")\n",
    "    print(f\"  - ì½”ë“œ ë¸”ë¡: {structure['code_blocks']}ê°œ\")\n",
    "    print(f\"  - ë¶ˆë¦¿ í¬ì¸íŠ¸: {structure['bullet_points']}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010",
   "metadata": {},
   "source": [
    "## 5. ì²­í‚¹ ì „ëµ ì‹¤í—˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ hr_policy ì²­í‚¹ ì‹¤í—˜ ì¤‘...\n",
      "  âœ… í—¤ë” ê¸°ë°˜: 14ê°œ ì²­í¬\n",
      "  âœ… í¬ê¸° 1000: 3ê°œ ì²­í¬\n",
      "  âœ… í¬ê¸° 1500: 2ê°œ ì²­í¬\n",
      "\n",
      "ğŸ”„ tech_policy ì²­í‚¹ ì‹¤í—˜ ì¤‘...\n",
      "  âœ… í—¤ë” ê¸°ë°˜: 23ê°œ ì²­í¬\n",
      "  âœ… í¬ê¸° 1000: 5ê°œ ì²­í¬\n",
      "  âœ… í¬ê¸° 1500: 3ê°œ ì²­í¬\n",
      "\n",
      "ğŸ”„ architecture ì²­í‚¹ ì‹¤í—˜ ì¤‘...\n",
      "  âœ… í—¤ë” ê¸°ë°˜: 23ê°œ ì²­í¬\n",
      "  âœ… í¬ê¸° 1000: 17ê°œ ì²­í¬\n",
      "  âœ… í¬ê¸° 1500: 11ê°œ ì²­í¬\n",
      "\n",
      "ğŸ”„ component ì²­í‚¹ ì‹¤í—˜ ì¤‘...\n",
      "  âœ… í—¤ë” ê¸°ë°˜: 26ê°œ ì²­í¬\n",
      "  âœ… í¬ê¸° 1000: 11ê°œ ì²­í¬\n",
      "  âœ… í¬ê¸° 1500: 6ê°œ ì²­í¬\n",
      "\n",
      "ğŸ”„ deployment ì²­í‚¹ ì‹¤í—˜ ì¤‘...\n",
      "  âœ… í—¤ë” ê¸°ë°˜: 24ê°œ ì²­í¬\n",
      "  âœ… í¬ê¸° 1000: 7ê°œ ì²­í¬\n",
      "  âœ… í¬ê¸° 1500: 5ê°œ ì²­í¬\n",
      "\n",
      "ğŸ”„ development ì²­í‚¹ ì‹¤í—˜ ì¤‘...\n",
      "  âœ… í—¤ë” ê¸°ë°˜: 20ê°œ ì²­í¬\n",
      "  âœ… í¬ê¸° 1000: 5ê°œ ì²­í¬\n",
      "  âœ… í¬ê¸° 1500: 3ê°œ ì²­í¬\n",
      "\n",
      "ğŸ”„ business_policy ì²­í‚¹ ì‹¤í—˜ ì¤‘...\n",
      "  âœ… í—¤ë” ê¸°ë°˜: 16ê°œ ì²­í¬\n",
      "  âœ… í¬ê¸° 1000: 3ê°œ ì²­í¬\n",
      "  âœ… í¬ê¸° 1500: 2ê°œ ì²­í¬\n",
      "\n",
      "ğŸ¯ ì²­í‚¹ ì‹¤í—˜ ì™„ë£Œ - ì´ 7ê°œ ë„ë©”ì¸\n"
     ]
    }
   ],
   "source": [
    "def create_chunks_by_headers(content: str, domain: str) -> List[Document]:\n",
    "    \"\"\"í—¤ë” ê¸°ë°˜ìœ¼ë¡œ ì²­í‚¹í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    # í—¤ë” ê¸°ë°˜ ë¶„í• \n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "    ]\n",
    "    \n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=headers_to_split_on\n",
    "    )\n",
    "    \n",
    "    md_header_splits = markdown_splitter.split_text(content)\n",
    "    \n",
    "    # ë©”íƒ€ë°ì´í„° ê°•í™”\n",
    "    enhanced_docs = []\n",
    "    for doc in md_header_splits:\n",
    "        # ê¸°ë³¸ ë©”íƒ€ë°ì´í„°ì— ë„ë©”ì¸ ì •ë³´ ì¶”ê°€\n",
    "        doc.metadata.update({\n",
    "            \"domain\": domain,\n",
    "            \"description\": DOMAIN_CONFIG[domain][\"description\"],\n",
    "            \"keywords\": DOMAIN_CONFIG[domain][\"keywords\"],\n",
    "            \"chunk_type\": \"header_based\"\n",
    "        })\n",
    "        enhanced_docs.append(doc)\n",
    "    \n",
    "    return enhanced_docs\n",
    "\n",
    "def create_chunks_by_size(content: str, domain: str, chunk_size: int = 1000) -> List[Document]:\n",
    "    \"\"\"ê³ ì • í¬ê¸° ê¸°ë°˜ìœ¼ë¡œ ì²­í‚¹í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_text(content)\n",
    "    \n",
    "    # Document ê°ì²´ë¡œ ë³€í™˜í•˜ë©° ë©”íƒ€ë°ì´í„° ì¶”ê°€\n",
    "    documents = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        doc = Document(\n",
    "            page_content=chunk,\n",
    "            metadata={\n",
    "                \"domain\": domain,\n",
    "                \"description\": DOMAIN_CONFIG[domain][\"description\"],\n",
    "                \"keywords\": DOMAIN_CONFIG[domain][\"keywords\"],\n",
    "                \"chunk_type\": \"size_based\",\n",
    "                \"chunk_index\": i,\n",
    "                \"chunk_size\": len(chunk)\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# ì²­í‚¹ ì‹¤í—˜\n",
    "chunking_results = {}\n",
    "\n",
    "for domain, content in raw_documents.items():\n",
    "    print(f\"\\nğŸ”„ {domain} ì²­í‚¹ ì‹¤í—˜ ì¤‘...\")\n",
    "    \n",
    "    # í—¤ë” ê¸°ë°˜ ì²­í‚¹\n",
    "    header_chunks = create_chunks_by_headers(content, domain)\n",
    "    \n",
    "    # í¬ê¸° ê¸°ë°˜ ì²­í‚¹ (ì—¬ëŸ¬ í¬ê¸° ì‹¤í—˜)\n",
    "    size_chunks_1000 = create_chunks_by_size(content, domain, 1000)\n",
    "    size_chunks_1500 = create_chunks_by_size(content, domain, 1500)\n",
    "    \n",
    "    chunking_results[domain] = {\n",
    "        \"header_based\": header_chunks,\n",
    "        \"size_1000\": size_chunks_1000,\n",
    "        \"size_1500\": size_chunks_1500\n",
    "    }\n",
    "    \n",
    "    print(f\"  âœ… í—¤ë” ê¸°ë°˜: {len(header_chunks)}ê°œ ì²­í¬\")\n",
    "    print(f\"  âœ… í¬ê¸° 1000: {len(size_chunks_1000)}ê°œ ì²­í¬\")\n",
    "    print(f\"  âœ… í¬ê¸° 1500: {len(size_chunks_1500)}ê°œ ì²­í¬\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ì²­í‚¹ ì‹¤í—˜ ì™„ë£Œ - ì´ {len(chunking_results)}ê°œ ë„ë©”ì¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012",
   "metadata": {},
   "source": [
    "## 6. ì²­í‚¹ í’ˆì§ˆ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ì²­í‚¹ ì „ëµë³„ í’ˆì§ˆ ë¶„ì„\n",
      "\n",
      "ë„ë©”ì¸             ì „ëµ           ì²­í¬ìˆ˜      í‰ê· í¬ê¸°       ìµœì†Œí¬ê¸°       ìµœëŒ€í¬ê¸°      \n",
      "--------------------------------------------------------------------------------\n",
      "hr_policy       header_based 14       108        33         167       \n",
      "hr_policy       size_1000    3        698        242        941       \n",
      "hr_policy       size_1500    2        956        472        1440      \n",
      "tech_policy     header_based 23       148        34         321       \n",
      "tech_policy     size_1000    5        903        774        967       \n",
      "tech_policy     size_1500    3        1421       1335       1493      \n",
      "architecture    header_based 23       475        36         1245      \n",
      "architecture    size_1000    17       838        482        992       \n",
      "architecture    size_1500    11       1224       867        1495      \n",
      "component       header_based 26       245        37         429       \n",
      "component       size_1000    11       824        314        995       \n",
      "component       size_1500    6        1359       919        1498      \n",
      "deployment      header_based 24       196        32         777       \n",
      "deployment      size_1000    7        896        693        972       \n",
      "deployment      size_1500    5        1184       332        1445      \n",
      "development     header_based 20       156        42         510       \n",
      "development     size_1000    5        838        435        993       \n",
      "development     size_1500    3        1231       711        1500      \n",
      "business_policy header_based 16       121        31         181       \n",
      "business_policy size_1000    3        838        572        976       \n",
      "business_policy size_1500    2        1202       1000       1405      \n"
     ]
    }
   ],
   "source": [
    "def analyze_chunk_quality(chunks: List[Document], strategy_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"ì²­í¬ í’ˆì§ˆì„ ë¶„ì„í•©ë‹ˆë‹¤.\"\"\"\n",
    "    if not chunks:\n",
    "        return {}\n",
    "    \n",
    "    chunk_sizes = [len(doc.page_content) for doc in chunks]\n",
    "    \n",
    "    return {\n",
    "        \"strategy\": strategy_name,\n",
    "        \"total_chunks\": len(chunks),\n",
    "        \"avg_chunk_size\": sum(chunk_sizes) / len(chunk_sizes),\n",
    "        \"min_chunk_size\": min(chunk_sizes),\n",
    "        \"max_chunk_size\": max(chunk_sizes),\n",
    "        \"total_content_size\": sum(chunk_sizes)\n",
    "    }\n",
    "\n",
    "# ì²­í‚¹ í’ˆì§ˆ ë¶„ì„\n",
    "print(\"ğŸ“Š ì²­í‚¹ ì „ëµë³„ í’ˆì§ˆ ë¶„ì„\\n\")\n",
    "print(f\"{'ë„ë©”ì¸':<15} {'ì „ëµ':<12} {'ì²­í¬ìˆ˜':<8} {'í‰ê· í¬ê¸°':<10} {'ìµœì†Œí¬ê¸°':<10} {'ìµœëŒ€í¬ê¸°':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "quality_analysis = {}\n",
    "for domain, strategies in chunking_results.items():\n",
    "    quality_analysis[domain] = {}\n",
    "    \n",
    "    for strategy_name, chunks in strategies.items():\n",
    "        quality = analyze_chunk_quality(chunks, strategy_name)\n",
    "        quality_analysis[domain][strategy_name] = quality\n",
    "        \n",
    "        if quality:  # ë¹ˆ ê²°ê³¼ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶œë ¥\n",
    "            print(f\"{domain:<15} {strategy_name:<12} {quality['total_chunks']:<8} \"\n",
    "                  f\"{quality['avg_chunk_size']:<10.0f} {quality['min_chunk_size']:<10} {quality['max_chunk_size']:<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014",
   "metadata": {},
   "source": [
    "## 7. ìµœì  ì²­í‚¹ ì „ëµ ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ hr_policy: size_1500 (ì ìˆ˜: 4.97)\n",
      "ğŸ¯ tech_policy: size_1000 (ì ìˆ˜: 2.69)\n",
      "ğŸ¯ architecture: size_1500 (ì ìˆ˜: 1.37)\n",
      "ğŸ¯ component: size_1000 (ì ìˆ˜: 1.18)\n",
      "ğŸ¯ deployment: size_1000 (ì ìˆ˜: 1.78)\n",
      "ğŸ¯ development: size_1000 (ì ìˆ˜: 3.06)\n",
      "ğŸ¯ business_policy: size_1000 (ì ìˆ˜: 3.90)\n",
      "âœ… hr_policy: 2ê°œ ì²­í¬ ì¤€ë¹„ ì™„ë£Œ\n",
      "âœ… tech_policy: 5ê°œ ì²­í¬ ì¤€ë¹„ ì™„ë£Œ\n",
      "âœ… architecture: 11ê°œ ì²­í¬ ì¤€ë¹„ ì™„ë£Œ\n",
      "âœ… component: 11ê°œ ì²­í¬ ì¤€ë¹„ ì™„ë£Œ\n",
      "âœ… deployment: 7ê°œ ì²­í¬ ì¤€ë¹„ ì™„ë£Œ\n",
      "âœ… development: 5ê°œ ì²­í¬ ì¤€ë¹„ ì™„ë£Œ\n",
      "âœ… business_policy: 3ê°œ ì²­í¬ ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def select_best_chunking_strategy(quality_analysis: Dict) -> Dict[str, str]:\n",
    "    \"\"\"ë„ë©”ì¸ë³„ ìµœì  ì²­í‚¹ ì „ëµì„ ì„ íƒí•©ë‹ˆë‹¤.\"\"\"\n",
    "    best_strategies = {}\n",
    "    \n",
    "    for domain, strategies in quality_analysis.items():\n",
    "        # í‰ê°€ ê¸°ì¤€: ì ì ˆí•œ ì²­í¬ ìˆ˜ + ê· í˜•ì¡íŒ í¬ê¸°\n",
    "        # ë„ˆë¬´ ë§ì€ ì²­í¬ëŠ” ê²€ìƒ‰ ì„±ëŠ¥ ì €í•˜, ë„ˆë¬´ ì ìœ¼ë©´ ì •ë³´ ì†ì‹¤\n",
    "        \n",
    "        best_score = float('inf')\n",
    "        best_strategy = \"header_based\"  # ê¸°ë³¸ê°’\n",
    "        \n",
    "        for strategy_name, quality in strategies.items():\n",
    "            if not quality:\n",
    "                continue\n",
    "                \n",
    "            # ì ìˆ˜ ê³„ì‚° (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
    "            # ì²­í¬ ìˆ˜ê°€ ë„ˆë¬´ ë§ê±°ë‚˜ ì ìœ¼ë©´ íŒ¨ë„í‹°\n",
    "            chunk_count_penalty = abs(quality['total_chunks'] - 10) * 0.5\n",
    "            \n",
    "            # í‰ê·  í¬ê¸°ê°€ 800-1200 ë²”ìœ„ì—ì„œ ë²—ì–´ë‚˜ë©´ íŒ¨ë„í‹°\n",
    "            avg_size = quality['avg_chunk_size']\n",
    "            size_penalty = max(0, abs(avg_size - 1000) - 200) * 0.01\n",
    "            \n",
    "            # í¬ê¸° í¸ì°¨ê°€ í´ìˆ˜ë¡ íŒ¨ë„í‹°\n",
    "            size_variance = quality['max_chunk_size'] - quality['min_chunk_size']\n",
    "            variance_penalty = size_variance * 0.001\n",
    "            \n",
    "            total_score = chunk_count_penalty + size_penalty + variance_penalty\n",
    "            \n",
    "            if total_score < best_score:\n",
    "                best_score = total_score\n",
    "                best_strategy = strategy_name\n",
    "        \n",
    "        best_strategies[domain] = best_strategy\n",
    "        print(f\"ğŸ¯ {domain}: {best_strategy} (ì ìˆ˜: {best_score:.2f})\")\n",
    "    \n",
    "    return best_strategies\n",
    "\n",
    "# ìµœì  ì „ëµ ì„ íƒ\n",
    "best_chunking_strategies = select_best_chunking_strategy(quality_analysis)\n",
    "\n",
    "# ì„ íƒëœ ì „ëµìœ¼ë¡œ ìµœì¢… ë¬¸ì„œ ì¤€ë¹„\n",
    "final_documents = {}\n",
    "for domain, strategy in best_chunking_strategies.items():\n",
    "    final_documents[domain] = chunking_results[domain][strategy]\n",
    "    print(f\"âœ… {domain}: {len(final_documents[domain])}ê°œ ì²­í¬ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016",
   "metadata": {},
   "source": [
    "## 8. ê²°ê³¼ ìš”ì•½ ë° ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ“‹ ë°ì´í„° ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½\n",
      "============================================================\n",
      "hr_policy      :   2ê°œ ì²­í¬, í‰ê·   956ì\n",
      "tech_policy    :   5ê°œ ì²­í¬, í‰ê·   903ì\n",
      "architecture   :  11ê°œ ì²­í¬, í‰ê·  1224ì\n",
      "component      :  11ê°œ ì²­í¬, í‰ê·   824ì\n",
      "deployment     :   7ê°œ ì²­í¬, í‰ê·   896ì\n",
      "development    :   5ê°œ ì²­í¬, í‰ê·   838ì\n",
      "business_policy:   3ê°œ ì²­í¬, í‰ê·   838ì\n",
      "------------------------------------------------------------\n",
      "ì´ê³„             :  44ê°œ ì²­í¬, ì´  41,929ì\n",
      "í‰ê·              :     953ì/ì²­í¬\n",
      "\n",
      "ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: 02_vector_stores.ipynbì—ì„œ ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶•\n",
      "ğŸ“Š ì¤€ë¹„ëœ ë°ì´í„°: 7ê°œ ë„ë©”ì¸, 44ê°œ ì²­í¬\n"
     ]
    }
   ],
   "source": [
    "# ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“‹ ë°ì´í„° ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_chunks = 0\n",
    "total_content_size = 0\n",
    "\n",
    "for domain, chunks in final_documents.items():\n",
    "    chunk_count = len(chunks)\n",
    "    content_size = sum(len(doc.page_content) for doc in chunks)\n",
    "    avg_size = content_size / chunk_count if chunk_count > 0 else 0\n",
    "    \n",
    "    total_chunks += chunk_count\n",
    "    total_content_size += content_size\n",
    "    \n",
    "    print(f\"{domain:<15}: {chunk_count:>3}ê°œ ì²­í¬, í‰ê·  {avg_size:>4.0f}ì\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'ì´ê³„':<15}: {total_chunks:>3}ê°œ ì²­í¬, ì´ {total_content_size:>7,}ì\")\n",
    "print(f\"{'í‰ê· ':<15}: {total_content_size/total_chunks:>7.0f}ì/ì²­í¬\")\n",
    "\n",
    "# ë‹¤ìŒ ë…¸íŠ¸ë¶ì„ ìœ„í•œ ë°ì´í„° ì €ì¥ ì¤€ë¹„\n",
    "print(f\"\\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„: 02_vector_stores.ipynbì—ì„œ ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶•\")\n",
    "print(f\"ğŸ“Š ì¤€ë¹„ëœ ë°ì´í„°: {len(final_documents)}ê°œ ë„ë©”ì¸, {total_chunks}ê°œ ì²­í¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018",
   "metadata": {},
   "source": [
    "## 9. ìƒ˜í”Œ ì²­í¬ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ ë„ë©”ì¸ë³„ ì²­í¬ ìƒ˜í”Œ (ì²« 300ì)\n",
      "\n",
      "ğŸ·ï¸  HR_POLICY\n",
      "ğŸ“„ ë©”íƒ€ë°ì´í„°: {'domain': 'hr_policy', 'description': 'ì¸ì‚¬ì •ì±…, ê·¼ë¬´ì‹œê°„, íœ´ê°€, ê¸‰ì—¬, ë³µë¦¬í›„ìƒ', 'keywords': ['ê·¼ë¬´ì‹œê°„', 'íœ´ê°€', 'ê¸‰ì—¬', 'ë³µë¦¬í›„ìƒ', 'ì¸ì‚¬', 'ì±„ìš©', 'í‰ê°€'], 'chunk_type': 'size_based', 'chunk_index': 0, 'chunk_size': 1440}\n",
      "ğŸ“ ë‚´ìš© ìƒ˜í”Œ: # ê¿€ìŠ¤í…Œì´ ì¸ì‚¬ì •ì±… ê°€ì´ë“œ\n",
      "\n",
      "## ğŸ“‹ ê°œìš”\n",
      "ê¿€ìŠ¤í…Œì´ ì§ì›ë“¤ì„ ìœ„í•œ ì¸ì‚¬ì •ì±… ë° ê·¼ë¬´ ê·œì •ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.\n",
      "\n",
      "## ğŸ• ê·¼ë¬´ì‹œê°„ ë° íœ´ê°€\n",
      "\n",
      "### ì •ê·œ ê·¼ë¬´ì‹œê°„\n",
      "- **í‰ì¼**: ì˜¤ì „ 9:00 ~ ì˜¤í›„ 6:00 (ì ì‹¬ì‹œê°„ 12:00~13:00 ì œì™¸)\n",
      "- **ì£¼ 40ì‹œê°„** ê·¼ë¬´ì œ ìš´ì˜\n",
      "- **ì½”ì–´íƒ€ì„**: ì˜¤ì „ 10:00 ~ ì˜¤í›„ 4:00 (í•„ìˆ˜ ê·¼ë¬´ì‹œê°„)\n",
      "\n",
      "### ìœ ì—°ê·¼ë¬´ì œ\n",
      "- **ì‹œì°¨ì¶œí‡´ê·¼**: ì˜¤ì „ 8:00~10:00 ì¶œê·¼, ì˜¤í›„ 5:00~7:00 í‡´ê·¼ ê°€ëŠ¥\n",
      "- **ì¬íƒê·¼ë¬´**: ì£¼ 2ì¼ê¹Œì§€ ê°€ëŠ¥ (ì‚¬ì „ ìŠ¹ì¸ í•„ìš”)\n",
      "- **í•˜ì´ë¸Œ...\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ·ï¸  TECH_POLICY\n",
      "ğŸ“„ ë©”íƒ€ë°ì´í„°: {'domain': 'tech_policy', 'description': 'ê¸°ìˆ ì •ì±…, ê°œë°œí™˜ê²½, ì½”ë”©í‘œì¤€, ë³´ì•ˆì •ì±…', 'keywords': ['ê°œë°œ', 'ê¸°ìˆ ', 'ì½”ë”©', 'ë³´ì•ˆ', 'í…ŒìŠ¤íŠ¸', 'ë°°í¬', 'ì¸í”„ë¼'], 'chunk_type': 'size_based', 'chunk_index': 0, 'chunk_size': 774}\n",
      "ğŸ“ ë‚´ìš© ìƒ˜í”Œ: # ê¿€ìŠ¤í…Œì´ ê¸°ìˆ ì •ì±… ê°€ì´ë“œ\n",
      "\n",
      "## ğŸ“‹ ê°œìš”\n",
      "ê¿€ìŠ¤í…Œì´ ê°œë°œíŒ€ì˜ ê¸°ìˆ  ì •ì±… ë° ê°œë°œ ê°€ì´ë“œë¼ì¸ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.\n",
      "\n",
      "## ğŸ—ï¸ ê°œë°œ í™˜ê²½ ë° ì¸í”„ë¼\n",
      "\n",
      "### ê°œë°œ í™˜ê²½ êµ¬ì„±\n",
      "- **ë¡œì»¬ ê°œë°œ**: Node.js 18+, React 18, Material-UI v5\n",
      "- **íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €**: npm (yarn ê¸ˆì§€)\n",
      "- **IDE**: VS Code ê¶Œì¥, ê³µí†µ Extension Pack ì‚¬ìš©\n",
      "- **ë¸Œë¼ìš°ì €**: Chrome ìµœì‹ ë²„ì „ ê¸°ì¤€ ê°œë°œ\n",
      "\n",
      "### í™˜ê²½ ë¶„ë¦¬\n",
      "- **Local**: ê°œë°œì ë¡œì»¬ í™˜ê²½\n",
      "- **Development**: ...\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ·ï¸  ARCHITECTURE\n",
      "ğŸ“„ ë©”íƒ€ë°ì´í„°: {'domain': 'architecture', 'description': 'CMS ì•„í‚¤í…ì²˜, ì‹œìŠ¤í…œì„¤ê³„, ë ˆì´ì–´êµ¬ì¡°', 'keywords': ['ì•„í‚¤í…ì²˜', 'ì‹œìŠ¤í…œ', 'ì„¤ê³„', 'êµ¬ì¡°', 'ë ˆì´ì–´', 'ëª¨ë“ˆ'], 'chunk_type': 'size_based', 'chunk_index': 0, 'chunk_size': 882}\n",
      "ğŸ“ ë‚´ìš© ìƒ˜í”Œ: # ê¿€ìŠ¤í…Œì´ CMS ì•„í‚¤í…ì²˜ ê°€ì´ë“œ\n",
      "\n",
      "## ğŸ“‹ ê°œìš”\n",
      "ê¿€ìŠ¤í…Œì´ CMSì˜ ì „ì²´ ì•„í‚¤í…ì²˜ êµ¬ì¡° ë° ì„¤ê³„ ì›ì¹™ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.\n",
      "\n",
      "## ğŸ—ï¸ ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜\n",
      "\n",
      "### í´ë¼ì´ì–¸íŠ¸-ì„œë²„ êµ¬ì¡°\n",
      "```\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚\n",
      "â”‚   React CMS     â”‚â—„â”€â”€â–ºâ”‚   Backend API   â”‚â—„â”€â”€â–ºâ”‚   Database    ...\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ·ï¸  COMPONENT\n",
      "ğŸ“„ ë©”íƒ€ë°ì´í„°: {'domain': 'component', 'description': 'ì»´í¬ë„ŒíŠ¸ ê°€ì´ë“œë¼ì¸, UI/UX í‘œì¤€', 'keywords': ['ì»´í¬ë„ŒíŠ¸', 'UI', 'UX', 'ë””ìì¸', 'ì¸í„°í˜ì´ìŠ¤', 'ì‚¬ìš©ì'], 'chunk_type': 'size_based', 'chunk_index': 0, 'chunk_size': 995}\n",
      "ğŸ“ ë‚´ìš© ìƒ˜í”Œ: # ê¿€ìŠ¤í…Œì´ ì»´í¬ë„ŒíŠ¸ ê°€ì´ë“œ\n",
      "\n",
      "## ğŸ“‹ ê°œìš”\n",
      "ê¿€ìŠ¤í…Œì´ CMSì˜ ê³µí†µ ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©ë²• ë° UI íŒ¨í„´ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.\n",
      "\n",
      "## ğŸ” DefaultSearchForm ì»´í¬ë„ŒíŠ¸\n",
      "\n",
      "### ê¸°ë³¸ ì‚¬ìš©ë²•\n",
      "CMSì˜ ëª¨ë“  ê²€ìƒ‰ í¼ì—ì„œ ì‚¬ìš©í•˜ëŠ” í‘œì¤€ ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤.\n",
      "\n",
      "```jsx\n",
      "import DefaultSearchForm from 'components/common/DefaultSearchForm';\n",
      "\n",
      "<DefaultSearchForm\n",
      "  data={searchFormData}\n",
      "  onSearch={handleSearch}\n",
      "  onReset={handle...\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ·ï¸  DEPLOYMENT\n",
      "ğŸ“„ ë©”íƒ€ë°ì´í„°: {'domain': 'deployment', 'description': 'ë°°í¬í”„ë¡œì„¸ìŠ¤, CI/CD, í™˜ê²½ê´€ë¦¬', 'keywords': ['ë°°í¬', 'CI/CD', 'í™˜ê²½', 'ë¹Œë“œ', 'ë¦´ë¦¬ìŠ¤', 'ìš´ì˜'], 'chunk_type': 'size_based', 'chunk_index': 0, 'chunk_size': 851}\n",
      "ğŸ“ ë‚´ìš© ìƒ˜í”Œ: # ê¿€ìŠ¤í…Œì´ ë°°í¬ ê°€ì´ë“œ\n",
      "\n",
      "## ğŸ“‹ ê°œìš”\n",
      "ê¿€ìŠ¤í…Œì´ CMS ë°°í¬ í”„ë¡œì„¸ìŠ¤ ë° í™˜ê²½ ê´€ë¦¬ ê°€ì´ë“œì…ë‹ˆë‹¤.\n",
      "\n",
      "## ğŸŒ í™˜ê²½ êµ¬ì„±\n",
      "\n",
      "### í™˜ê²½ë³„ íŠ¹ì„±\n",
      "| í™˜ê²½ | ë¸Œëœì¹˜ | ë„ë©”ì¸ | ìš©ë„ |\n",
      "|------|--------|---------|------|\n",
      "| **Local** | feature/* | localhost:3000 | ê°œë°œì ë¡œì»¬ ê°œë°œ |\n",
      "| **Development** | dev | dev-cms.coolstay.co.kr | í†µí•© ê°œë°œ í…ŒìŠ¤íŠ¸ |\n",
      "| **Staging** | release/* | stage-cms.cools...\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ·ï¸  DEVELOPMENT\n",
      "ğŸ“„ ë©”íƒ€ë°ì´í„°: {'domain': 'development', 'description': 'ê°œë°œí”„ë¡œì„¸ìŠ¤, ì›Œí¬í”Œë¡œìš°, í˜‘ì—…ê·œì¹™', 'keywords': ['í”„ë¡œì„¸ìŠ¤', 'ì›Œí¬í”Œë¡œìš°', 'í˜‘ì—…', 'ìŠ¤í”„ë¦°íŠ¸', 'ì• ìì¼'], 'chunk_type': 'size_based', 'chunk_index': 0, 'chunk_size': 920}\n",
      "ğŸ“ ë‚´ìš© ìƒ˜í”Œ: # ê¿€ìŠ¤í…Œì´ ê°œë°œ í”„ë¡œì„¸ìŠ¤ ê°€ì´ë“œ\n",
      "\n",
      "## ğŸ“‹ ê°œìš”\n",
      "ê¿€ìŠ¤í…Œì´ ê°œë°œíŒ€ì˜ ìŠ¤í”„ë¦°íŠ¸ ê¸°ë°˜ ê°œë°œ í”„ë¡œì„¸ìŠ¤ ë° í˜‘ì—… ë°©ë²•ë¡ ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.\n",
      "\n",
      "## ğŸ”„ ìŠ¤í”„ë¦°íŠ¸ ìš´ì˜\n",
      "\n",
      "### ìŠ¤í”„ë¦°íŠ¸ êµ¬ì„±\n",
      "- **ê¸°ê°„**: 2ì£¼ ë‹¨ìœ„ ìŠ¤í”„ë¦°íŠ¸\n",
      "- **íŒ€ êµ¬ì„±**: Finn(Frontend Lead), Dana(Backend Lead), Lynn(Full-stack)\n",
      "- **ìŠ¤í¬ëŸ¼ ë§ˆìŠ¤í„°**: ë¡œí…Œì´ì…˜ ë°©ì‹ (ì›”ë³„ êµì²´)\n",
      "- **ì œí’ˆ ì±…ì„ì**: CTO\n",
      "\n",
      "### ìŠ¤í”„ë¦°íŠ¸ ì´ë²¤íŠ¸\n",
      "\n",
      "#### ìŠ¤í”„ë¦°íŠ¸ í”Œë˜ë‹ (ì›”ìš”ì¼ ì˜¤ì „ 10ì‹œ)\n",
      "- **ì†Œìš”ì‹œê°„**: 2ì‹œê°„\n",
      "- **...\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ·ï¸  BUSINESS_POLICY\n",
      "ğŸ“„ ë©”íƒ€ë°ì´í„°: {'domain': 'business_policy', 'description': 'ë¹„ì¦ˆë‹ˆìŠ¤ì •ì±…, ìš´ì˜ê·œì¹™, ì˜ì‚¬ê²°ì •', 'keywords': ['ë¹„ì¦ˆë‹ˆìŠ¤', 'ì •ì±…', 'ìš´ì˜', 'ì˜ì‚¬ê²°ì •', 'ì „ëµ'], 'chunk_type': 'size_based', 'chunk_index': 0, 'chunk_size': 976}\n",
      "ğŸ“ ë‚´ìš© ìƒ˜í”Œ: # ê¿€ìŠ¤í…Œì´ ì‚¬ì—…ì •ì±… ê°€ì´ë“œ\n",
      "\n",
      "## ğŸ“‹ ê°œìš”\n",
      "ê¿€ìŠ¤í…Œì´ì˜ ì‚¬ì—… ìš´ì˜ ì •ì±… ë° ì„œë¹„ìŠ¤ ê·œì •ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.\n",
      "\n",
      "## ğŸ¨ ìˆ™ì†Œ ìš´ì˜ ì •ì±…\n",
      "\n",
      "### ìˆ™ì†Œ ë“±ë¡ ê¸°ì¤€\n",
      "- **ê¸°ë³¸ìš”ê±´**: ì‚¬ì—…ìë“±ë¡ì¦, ê´€ê´‘ì‚¬ì—…ì ì‹ ê³ ì¦ í•„ìˆ˜\n",
      "- **ì‹œì„¤ê¸°ì¤€**: ìµœì†Œ ê°ì‹¤ ë©´ì  16.5ã¡ ì´ìƒ\n",
      "- **ì•ˆì „ê¸°ì¤€**: í™”ì¬ë³´í—˜ ê°€ì…, ì†Œë°©ì‹œì„¤ ì ê²€ì¦ëª…ì„œ\n",
      "- **ìœ„ìƒê¸°ì¤€**: ì •ê¸° ë°©ì—­ ì¦ëª…ì„œ, ì²­ì†Œìš©í’ˆ êµ¬ë¹„\n",
      "\n",
      "### ê°ì‹¤ ê´€ë¦¬ ê·œì •\n",
      "- **ì²´í¬ì¸**: ì˜¤í›„ 3ì‹œ (ìµœëŒ€ ì˜¤í›„ 6ì‹œê¹Œì§€ ì—°ì¥ ê°€ëŠ¥)\n",
      "- **ì²´í¬ì•„ì›ƒ**: ì˜¤ì „ 11ì‹œ (1ì‹œê°„ ì—°ì¥ ì‹œ ì¶”ê°€ìš”ê¸ˆ)\n",
      "- *...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âœ… 01_data_processing.ipynb ì™„ë£Œ!\n",
      "ğŸš€ ë‹¤ìŒ: 02_vector_stores.ipynb ì‹¤í–‰\n"
     ]
    }
   ],
   "source": [
    "# ê° ë„ë©”ì¸ë³„ ì²« ë²ˆì§¸ ì²­í¬ ìƒ˜í”Œ ì¶œë ¥\n",
    "print(\"\\nğŸ“‹ ë„ë©”ì¸ë³„ ì²­í¬ ìƒ˜í”Œ (ì²« 300ì)\\n\")\n",
    "\n",
    "for domain, chunks in final_documents.items():\n",
    "    if chunks:\n",
    "        first_chunk = chunks[0]\n",
    "        sample_content = first_chunk.page_content[:300] + \"...\" if len(first_chunk.page_content) > 300 else first_chunk.page_content\n",
    "        \n",
    "        print(f\"ğŸ·ï¸  {domain.upper()}\")\n",
    "        print(f\"ğŸ“„ ë©”íƒ€ë°ì´í„°: {first_chunk.metadata}\")\n",
    "        print(f\"ğŸ“ ë‚´ìš© ìƒ˜í”Œ: {sample_content}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nâœ… 01_data_processing.ipynb ì™„ë£Œ!\")\n",
    "print(\"ğŸš€ ë‹¤ìŒ: 02_vector_stores.ipynb ì‹¤í–‰\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
