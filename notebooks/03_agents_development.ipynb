{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤– ê¿€ìŠ¤í…Œì´ RAG - ì—ì´ì „íŠ¸ ê°œë°œ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ë„ë©”ì¸ë³„ RAG ì—ì´ì „íŠ¸ì™€ Corrective RAG ë©”ì»¤ë‹ˆì¦˜ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ëª©í‘œ\n",
    "1. ê¸°ë³¸ RAG ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ ì„¤ê³„\n",
    "2. ë„ë©”ì¸ë³„ ì „ë¬¸ ì—ì´ì „íŠ¸ êµ¬í˜„ (7ê°œ)\n",
    "3. Corrective RAG ë©”ì»¤ë‹ˆì¦˜ ê°œë°œ\n",
    "4. ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ í†µí•©\n",
    "5. ì—ì´ì „íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ .env íŒŒì¼ ë¡œë“œ: True (ê²½ë¡œ: /Users/yundoun/Desktop/Project/legal_rag/coolstay_rag/.env)\n",
      "ğŸ”‘ OpenAI API Key: ì„¤ì •ë¨\n",
      "ğŸ”‘ Tavily API Key: ì„¤ì •ë¨\n",
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "# LangChain ê´€ë ¨\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# ì›¹ ê²€ìƒ‰ (Tavily)\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (ì ˆëŒ€ ê²½ë¡œ ì§€ì •)\n",
    "project_root = Path(\"/Users/yundoun/Desktop/Project/legal_rag/coolstay_rag\")\n",
    "env_file = project_root / \".env\"\n",
    "load_result = load_dotenv(env_file)\n",
    "print(f\"ğŸ“ .env íŒŒì¼ ë¡œë“œ: {load_result} (ê²½ë¡œ: {env_file})\")\n",
    "\n",
    "# API í‚¤ í™•ì¸\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\", \"NOT_FOUND\")\n",
    "tavily_key = os.getenv(\"TAVILY_API_KEY\", \"NOT_FOUND\")\n",
    "print(f\"ğŸ”‘ OpenAI API Key: {'ì„¤ì •ë¨' if openai_key != 'NOT_FOUND' and openai_key.startswith('sk-') else 'NOT_FOUND'}\")\n",
    "print(f\"ğŸ”‘ Tavily API Key: {'ì„¤ì •ë¨' if tavily_key != 'NOT_FOUND' and tavily_key.startswith('tvly-') else 'NOT_FOUND'}\")\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ê¸°ë³¸ ì„¤ì • ë° ëª¨ë¸ ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„¤ì • ì™„ë£Œ: 7ê°œ ë„ë©”ì¸\n"
     ]
    }
   ],
   "source": [
    "# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •\n",
    "PROJECT_ROOT = Path(\"/Users/yundoun/Desktop/Project/legal_rag/coolstay_rag\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "CHROMA_DB_DIR = PROJECT_ROOT / \"chroma_db\"\n",
    "\n",
    "# ë„ë©”ì¸ ì„¤ì •\n",
    "DOMAIN_CONFIG = {\n",
    "    \"hr_policy\": {\n",
    "        \"file\": \"HR_Policy_Guide.md\",\n",
    "        \"description\": \"ì¸ì‚¬ì •ì±…, ê·¼ë¬´ì‹œê°„, íœ´ê°€, ê¸‰ì—¬, ë³µë¦¬í›„ìƒ\",\n",
    "        \"collection_name\": \"hr_policy_db\",\n",
    "        \"agent_name\": \"HR ì •ì±… ì „ë¬¸ê°€\"\n",
    "    },\n",
    "    \"tech_policy\": {\n",
    "        \"file\": \"Tech_Policy_Guide.md\",\n",
    "        \"description\": \"ê¸°ìˆ ì •ì±…, ê°œë°œí™˜ê²½, ì½”ë”©í‘œì¤€, ë³´ì•ˆì •ì±…\",\n",
    "        \"collection_name\": \"tech_policy_db\",\n",
    "        \"agent_name\": \"ê¸°ìˆ  ì •ì±… ì „ë¬¸ê°€\"\n",
    "    },\n",
    "    \"architecture\": {\n",
    "        \"file\": \"Architecture_Guide.md\",\n",
    "        \"description\": \"CMS ì•„í‚¤í…ì²˜, ì‹œìŠ¤í…œì„¤ê³„, ë ˆì´ì–´êµ¬ì¡°\",\n",
    "        \"collection_name\": \"architecture_db\",\n",
    "        \"agent_name\": \"ì•„í‚¤í…ì²˜ ì „ë¬¸ê°€\"\n",
    "    },\n",
    "    \"component\": {\n",
    "        \"file\": \"Component_Guide.md\",\n",
    "        \"description\": \"ì»´í¬ë„ŒíŠ¸ ê°€ì´ë“œë¼ì¸, UI/UX í‘œì¤€\",\n",
    "        \"collection_name\": \"component_db\",\n",
    "        \"agent_name\": \"ì»´í¬ë„ŒíŠ¸ ê°œë°œ ì „ë¬¸ê°€\"\n",
    "    },\n",
    "    \"deployment\": {\n",
    "        \"file\": \"Deployment_Guide.md\",\n",
    "        \"description\": \"ë°°í¬í”„ë¡œì„¸ìŠ¤, CI/CD, í™˜ê²½ê´€ë¦¬\",\n",
    "        \"collection_name\": \"deployment_db\",\n",
    "        \"agent_name\": \"ë°°í¬ ì „ë¬¸ê°€\"\n",
    "    },\n",
    "    \"development\": {\n",
    "        \"file\": \"Development_Process_Guide.md\",\n",
    "        \"description\": \"ê°œë°œí”„ë¡œì„¸ìŠ¤, ì›Œí¬í”Œë¡œìš°, í˜‘ì—…ê·œì¹™\",\n",
    "        \"collection_name\": \"development_db\",\n",
    "        \"agent_name\": \"ê°œë°œ í”„ë¡œì„¸ìŠ¤ ì „ë¬¸ê°€\"\n",
    "    },\n",
    "    \"business_policy\": {\n",
    "        \"file\": \"Business_Policy_Guide.md\",\n",
    "        \"description\": \"ë¹„ì¦ˆë‹ˆìŠ¤ì •ì±…, ìš´ì˜ê·œì¹™, ì˜ì‚¬ê²°ì •\",\n",
    "        \"collection_name\": \"business_policy_db\",\n",
    "        \"agent_name\": \"ë¹„ì¦ˆë‹ˆìŠ¤ ì •ì±… ì „ë¬¸ê°€\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"âœ… ì„¤ì • ì™„ë£Œ: {len(DOMAIN_CONFIG)}ê°œ ë„ë©”ì¸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM ì´ˆê¸°í™” ì„±ê³µ: gpt-4o-mini\n",
      "âœ… ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ: bge-m3 (1024ì°¨ì›)\n",
      "âœ… ì›¹ ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™” ì„±ê³µ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m6/gznvfzn13lx3pznw3cs7f4800000gn/T/ipykernel_5739/2301650756.py:39: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  web_search = TavilySearchResults(\n"
     ]
    }
   ],
   "source": [
    "# LLM ëª¨ë¸ ì´ˆê¸°í™”\n",
    "def initialize_llm():\n",
    "    try:\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.1,\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        \n",
    "        # í…ŒìŠ¤íŠ¸ í˜¸ì¶œ\n",
    "        test_response = llm.invoke(\"Hello\")\n",
    "        print(f\"âœ… LLM ì´ˆê¸°í™” ì„±ê³µ: {llm.model_name}\")\n",
    "        return llm\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "def initialize_embeddings():\n",
    "    try:\n",
    "        embeddings = OllamaEmbeddings(\n",
    "            model=\"bge-m3\",\n",
    "            base_url=\"http://localhost:11434\"\n",
    "        )\n",
    "        \n",
    "        # í…ŒìŠ¤íŠ¸ ì„ë² ë”©\n",
    "        test_embedding = embeddings.embed_query(\"test\")\n",
    "        print(f\"âœ… ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ: bge-m3 ({len(test_embedding)}ì°¨ì›)\")\n",
    "        return embeddings\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# ì›¹ ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™”\n",
    "def initialize_web_search():\n",
    "    try:\n",
    "        web_search = TavilySearchResults(\n",
    "            max_results=3,\n",
    "            api_key=os.getenv(\"TAVILY_API_KEY\")\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… ì›¹ ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™” ì„±ê³µ\")\n",
    "        return web_search\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì›¹ ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        print(\"   Tavily API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "        return None\n",
    "\n",
    "# ëª¨ë“  ëª¨ë¸ ì´ˆê¸°í™”\n",
    "llm = initialize_llm()\n",
    "embeddings = initialize_embeddings()\n",
    "web_search = initialize_web_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë²¡í„° ì €ì¥ì†Œ ë¡œë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:__main__:âœ… hr_policy ë¡œë”© ì™„ë£Œ: 14ê°œ ë¬¸ì„œ\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:__main__:âœ… tech_policy ë¡œë”© ì™„ë£Œ: 23ê°œ ë¬¸ì„œ\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:__main__:âœ… architecture ë¡œë”© ì™„ë£Œ: 23ê°œ ë¬¸ì„œ\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:__main__:âœ… component ë¡œë”© ì™„ë£Œ: 26ê°œ ë¬¸ì„œ\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:__main__:âœ… deployment ë¡œë”© ì™„ë£Œ: 26ê°œ ë¬¸ì„œ\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:__main__:âœ… development ë¡œë”© ì™„ë£Œ: 24ê°œ ë¬¸ì„œ\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:__main__:âœ… business_policy ë¡œë”© ì™„ë£Œ: 16ê°œ ë¬¸ì„œ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ë²¡í„° ì €ì¥ì†Œ ë¡œë”© ì™„ë£Œ: 7/7ê°œ ë„ë©”ì¸\n"
     ]
    }
   ],
   "source": [
    "def load_vectorstore(domain: str, embeddings) -> Optional[Chroma]:\n",
    "    \"\"\"ê°œë³„ ë²¡í„° ì €ì¥ì†Œ ë¡œë”©\"\"\"\n",
    "    if domain not in DOMAIN_CONFIG:\n",
    "        logger.error(f\"ì•Œ ìˆ˜ ì—†ëŠ” ë„ë©”ì¸: {domain}\")\n",
    "        return None\n",
    "    \n",
    "    collection_name = DOMAIN_CONFIG[domain][\"collection_name\"]\n",
    "    persist_directory = str(CHROMA_DB_DIR / domain)\n",
    "    \n",
    "    if not Path(persist_directory).exists():\n",
    "        logger.warning(f\"ë²¡í„° ì €ì¥ì†Œ ì—†ìŒ: {persist_directory}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        vectorstore = Chroma(\n",
    "            collection_name=collection_name,\n",
    "            embedding_function=embeddings,\n",
    "            persist_directory=persist_directory\n",
    "        )\n",
    "        \n",
    "        # ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "        count = vectorstore._collection.count()\n",
    "        logger.info(f\"âœ… {domain} ë¡œë”© ì™„ë£Œ: {count}ê°œ ë¬¸ì„œ\")\n",
    "        \n",
    "        return vectorstore\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"ë²¡í„° ì €ì¥ì†Œ ë¡œë”© ì‹¤íŒ¨ {domain}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_all_vectorstores(embeddings) -> Dict[str, Chroma]:\n",
    "    \"\"\"ëª¨ë“  ë²¡í„° ì €ì¥ì†Œ ë¡œë”©\"\"\"\n",
    "    vectorstores = {}\n",
    "    \n",
    "    for domain in DOMAIN_CONFIG.keys():\n",
    "        vectorstore = load_vectorstore(domain, embeddings)\n",
    "        if vectorstore:\n",
    "            vectorstores[domain] = vectorstore\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ë²¡í„° ì €ì¥ì†Œ ë¡œë”© ì™„ë£Œ: {len(vectorstores)}/{len(DOMAIN_CONFIG)}ê°œ ë„ë©”ì¸\")\n",
    "    return vectorstores\n",
    "\n",
    "# ë²¡í„° ì €ì¥ì†Œ ë¡œë”©\n",
    "if embeddings:\n",
    "    vectorstores = load_all_vectorstores(embeddings)\n",
    "else:\n",
    "    vectorstores = {}\n",
    "    print(\"âŒ ì„ë² ë”© ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ë²¡í„° ì €ì¥ì†Œë¥¼ ë¡œë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ë‹µë³€ í’ˆì§ˆ í‰ê°€ í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í’ˆì§ˆ í‰ê°€ê¸° ì´ˆê¸°í™” ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "class AnswerQuality(Enum):\n",
    "    \"\"\"ë‹µë³€ í’ˆì§ˆ ë“±ê¸‰\"\"\"\n",
    "    EXCELLENT = \"excellent\"    # ë§¤ìš° ìš°ìˆ˜\n",
    "    GOOD = \"good\"             # ì–‘í˜¸\n",
    "    FAIR = \"fair\"             # ë³´í†µ\n",
    "    POOR = \"poor\"             # ë¯¸í¡\n",
    "\n",
    "@dataclass\n",
    "class QualityAssessment:\n",
    "    \"\"\"í’ˆì§ˆ í‰ê°€ ê²°ê³¼\"\"\"\n",
    "    overall_quality: AnswerQuality\n",
    "    relevance_score: float      # ê´€ë ¨ì„± (0-1)\n",
    "    accuracy_score: float       # ì •í™•ì„± (0-1)\n",
    "    completeness_score: float   # ì™„ì„±ë„ (0-1)\n",
    "    confidence_score: float     # í™•ì‹ ë„ (0-1)\n",
    "    reasoning: str              # í‰ê°€ ì´ìœ \n",
    "    needs_improvement: bool     # ê°œì„  í•„ìš” ì—¬ë¶€\n",
    "\n",
    "class QualityEvaluator:\n",
    "    \"\"\"ë‹µë³€ í’ˆì§ˆ í‰ê°€ê¸°\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.evaluation_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        ë‹¹ì‹ ì€ RAG ì‹œìŠ¤í…œì˜ ë‹µë³€ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "        \n",
    "        **í‰ê°€ ê¸°ì¤€:**\n",
    "        1. **ê´€ë ¨ì„±**: ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ì–¼ë§ˆë‚˜ ê´€ë ¨ì´ ìˆëŠ”ê°€?\n",
    "        2. **ì •í™•ì„±**: ì œê³µëœ ì •ë³´ê°€ ì–¼ë§ˆë‚˜ ì •í™•í•œê°€?\n",
    "        3. **ì™„ì„±ë„**: ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ì–¼ë§ˆë‚˜ ì™„ì „í•œê°€?\n",
    "        4. **í™•ì‹ ë„**: ë‹µë³€ì˜ ì‹ ë¢°ë„ëŠ” ì–¼ë§ˆë‚˜ ë†’ì€ê°€?\n",
    "        \n",
    "        **ì§ˆë¬¸:** {question}\n",
    "        \n",
    "        **ì œê³µëœ ì»¨í…ìŠ¤íŠ¸:**\n",
    "        {context}\n",
    "        \n",
    "        **ìƒì„±ëœ ë‹µë³€:**\n",
    "        {answer}\n",
    "        \n",
    "        **í‰ê°€ ìš”ì²­:**\n",
    "        ê° ê¸°ì¤€ì— ëŒ€í•´ 0.0~1.0 ì ìˆ˜ë¥¼ ë§¤ê¸°ê³ , ì „ì²´ì ì¸ í’ˆì§ˆ ë“±ê¸‰(excellent/good/fair/poor)ì„ ê²°ì •í•˜ì„¸ìš”.\n",
    "        ê°œì„ ì´ í•„ìš”í•œì§€ íŒë‹¨í•˜ê³  ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "        \n",
    "        ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:\n",
    "        {{\n",
    "            \"overall_quality\": \"excellent|good|fair|poor\",\n",
    "            \"relevance_score\": 0.0-1.0,\n",
    "            \"accuracy_score\": 0.0-1.0,\n",
    "            \"completeness_score\": 0.0-1.0,\n",
    "            \"confidence_score\": 0.0-1.0,\n",
    "            \"reasoning\": \"í‰ê°€ ì´ìœ \",\n",
    "            \"needs_improvement\": true|false\n",
    "        }}\n",
    "        \"\"\")\n",
    "        \n",
    "        self.chain = (\n",
    "            self.evaluation_prompt \n",
    "            | self.llm \n",
    "            | JsonOutputParser()\n",
    "        )\n",
    "    \n",
    "    def evaluate(self, question: str, context: List[str], answer: str) -> QualityAssessment:\n",
    "        \"\"\"ë‹µë³€ í’ˆì§ˆ í‰ê°€\"\"\"\n",
    "        try:\n",
    "            context_text = \"\\n\\n\".join(context) if context else \"ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ\"\n",
    "            \n",
    "            result = self.chain.invoke({\n",
    "                \"question\": question,\n",
    "                \"context\": context_text,\n",
    "                \"answer\": answer\n",
    "            })\n",
    "            \n",
    "            return QualityAssessment(\n",
    "                overall_quality=AnswerQuality(result[\"overall_quality\"]),\n",
    "                relevance_score=result[\"relevance_score\"],\n",
    "                accuracy_score=result[\"accuracy_score\"],\n",
    "                completeness_score=result[\"completeness_score\"],\n",
    "                confidence_score=result[\"confidence_score\"],\n",
    "                reasoning=result[\"reasoning\"],\n",
    "                needs_improvement=result[\"needs_improvement\"]\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨: {e}\")\n",
    "            # ê¸°ë³¸ê°’ ë°˜í™˜\n",
    "            return QualityAssessment(\n",
    "                overall_quality=AnswerQuality.FAIR,\n",
    "                relevance_score=0.5,\n",
    "                accuracy_score=0.5,\n",
    "                completeness_score=0.5,\n",
    "                confidence_score=0.5,\n",
    "                reasoning=\"í‰ê°€ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ\",\n",
    "                needs_improvement=True\n",
    "            )\n",
    "\n",
    "# í’ˆì§ˆ í‰ê°€ê¸° ì´ˆê¸°í™”\n",
    "if llm:\n",
    "    quality_evaluator = QualityEvaluator(llm)\n",
    "    print(\"âœ… í’ˆì§ˆ í‰ê°€ê¸° ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "else:\n",
    "    quality_evaluator = None\n",
    "    print(\"âŒ LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ í’ˆì§ˆ í‰ê°€ê¸°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ê¸°ë³¸ RAG ì—ì´ì „íŠ¸ í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BaseRAGAgent í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class RAGResponse:\n",
    "    \"\"\"RAG ì‘ë‹µ ê²°ê³¼\"\"\"\n",
    "    answer: str\n",
    "    source_documents: List[Document]\n",
    "    domain: str\n",
    "    quality_assessment: Optional[QualityAssessment]\n",
    "    corrective_iterations: int = 0\n",
    "    \n",
    "class BaseRAGAgent:\n",
    "    \"\"\"ê¸°ë³¸ RAG ì—ì´ì „íŠ¸ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 domain: str, \n",
    "                 vectorstore: Chroma,\n",
    "                 llm: ChatOpenAI,\n",
    "                 quality_evaluator: Optional[QualityEvaluator] = None,\n",
    "                 max_corrective_iterations: int = 2):\n",
    "        \n",
    "        self.domain = domain\n",
    "        self.vectorstore = vectorstore\n",
    "        self.llm = llm\n",
    "        self.quality_evaluator = quality_evaluator\n",
    "        self.max_corrective_iterations = max_corrective_iterations\n",
    "        \n",
    "        # ë„ë©”ì¸ ì„¤ì • ë¡œë“œ\n",
    "        self.config = DOMAIN_CONFIG.get(domain, {})\n",
    "        self.agent_name = self.config.get(\"agent_name\", f\"{domain} ì „ë¬¸ê°€\")\n",
    "        self.description = self.config.get(\"description\", \"ë„ë©”ì¸ ì „ë¬¸ê°€\")\n",
    "        \n",
    "        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "        self._setup_prompts()\n",
    "        \n",
    "        # RAG ì²´ì¸ êµ¬ì„±\n",
    "        self._build_rag_chain()\n",
    "    \n",
    "    def _setup_prompts(self):\n",
    "        \"\"\"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\"\"\"\n",
    "        \n",
    "        # ê¸°ë³¸ ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸\n",
    "        self.answer_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        ë‹¹ì‹ ì€ ê¿€ìŠ¤í…Œì´ì˜ {agent_name}ì…ë‹ˆë‹¤.\n",
    "        ì „ë¬¸ ë¶„ì•¼: {description}\n",
    "        \n",
    "        **ì—­í• :**\n",
    "        - {description} ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ ì œê³µ\n",
    "        - ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€\n",
    "        - ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” ëª…ì‹œì ìœ¼ë¡œ í‘œí˜„\n",
    "        \n",
    "        **ì§ˆë¬¸:** {question}\n",
    "        \n",
    "        **ê´€ë ¨ ë¬¸ì„œ:**\n",
    "        {context}\n",
    "        \n",
    "        **ë‹µë³€ ì§€ì¹¨:**\n",
    "        1. ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”\n",
    "        2. ì œê³µëœ ë¬¸ì„œì˜ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”\n",
    "        3. êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ì ˆì°¨ê°€ ìˆë‹¤ë©´ í¬í•¨í•˜ì„¸ìš”\n",
    "        4. í™•ì‹¤í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” \"ë¬¸ì„œì— ë”°ë¥´ë©´...\" ë“±ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”\n",
    "        5. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”\n",
    "        \n",
    "        **ë‹µë³€:**\n",
    "        \"\"\")\n",
    "        \n",
    "        # ì¿¼ë¦¬ ê°œì„  í”„ë¡¬í”„íŠ¸\n",
    "        self.query_improvement_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "        ë” ë‚˜ì€ ê²€ìƒ‰ì„ ìœ„í•´ ì§ˆë¬¸ì„ ê°œì„ í•´ì£¼ì„¸ìš”.\n",
    "        \n",
    "        **ì›ë˜ ì§ˆë¬¸:** {original_question}\n",
    "        **ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸:** {context}\n",
    "        **í’ˆì§ˆ í‰ê°€:** {quality_feedback}\n",
    "        \n",
    "        **ìš”ì²­:**\n",
    "        - ë” êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ê°œì„ \n",
    "        - {description} ë„ë©”ì¸ì— íŠ¹í™”ëœ ìš©ì–´ ì‚¬ìš©\n",
    "        - ì—¬ëŸ¬ ê´€ì ì—ì„œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í™•ì¥\n",
    "        \n",
    "        **ê°œì„ ëœ ì§ˆë¬¸:**\n",
    "        \"\"\")\n",
    "    \n",
    "    def _build_rag_chain(self):\n",
    "        \"\"\"RAG ì²´ì¸ êµ¬ì„±\"\"\"\n",
    "        # ê²€ìƒ‰ê¸° ì„¤ì •\n",
    "        retriever = self.vectorstore.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 5}\n",
    "        )\n",
    "        \n",
    "        # ë¬¸ì„œ í¬ë§·íŒ… í•¨ìˆ˜\n",
    "        def format_docs(docs):\n",
    "            formatted = []\n",
    "            for i, doc in enumerate(docs, 1):\n",
    "                content = doc.page_content\n",
    "                metadata = doc.metadata\n",
    "                \n",
    "                # í—¤ë” ì •ë³´ ì¶”ì¶œ\n",
    "                header_info = []\n",
    "                for key in [\"Header 1\", \"Header 2\", \"Header 3\"]:\n",
    "                    if key in metadata and metadata[key]:\n",
    "                        header_info.append(metadata[key])\n",
    "                \n",
    "                header_str = \" > \".join(header_info) if header_info else \"N/A\"\n",
    "                \n",
    "                formatted.append(f\"**ë¬¸ì„œ {i}** (ì¶œì²˜: {header_str})\\n{content}\")\n",
    "            \n",
    "            return \"\\n\\n\".join(formatted)\n",
    "        \n",
    "        # RAG ì²´ì¸ êµ¬ì„±\n",
    "        self.rag_chain = (\n",
    "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | self.answer_prompt.partial(\n",
    "                agent_name=self.agent_name,\n",
    "                description=self.description\n",
    "            )\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        \n",
    "        # ì¿¼ë¦¬ ê°œì„  ì²´ì¸\n",
    "        self.query_improvement_chain = (\n",
    "            self.query_improvement_prompt.partial(\n",
    "                description=self.description\n",
    "            )\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "    \n",
    "    def retrieve_documents(self, query: str, k: int = 5) -> List[Document]:\n",
    "        \"\"\"ë¬¸ì„œ ê²€ìƒ‰\"\"\"\n",
    "        try:\n",
    "            docs = self.vectorstore.similarity_search(query, k=k)\n",
    "            return docs\n",
    "        except Exception as e:\n",
    "            logger.error(f\"ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨ ({self.domain}): {e}\")\n",
    "            return []\n",
    "    \n",
    "    def generate_answer(self, question: str) -> str:\n",
    "        \"\"\"ë‹µë³€ ìƒì„±\"\"\"\n",
    "        try:\n",
    "            answer = self.rag_chain.invoke(question)\n",
    "            return answer\n",
    "        except Exception as e:\n",
    "            logger.error(f\"ë‹µë³€ ìƒì„± ì‹¤íŒ¨ ({self.domain}): {e}\")\n",
    "            return f\"ì£„ì†¡í•©ë‹ˆë‹¤. {self.domain} ê´€ë ¨ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    def improve_query(self, original_question: str, context: List[str], quality_feedback: str) -> str:\n",
    "        \"\"\"ì¿¼ë¦¬ ê°œì„ \"\"\"\n",
    "        try:\n",
    "            improved_query = self.query_improvement_chain.invoke({\n",
    "                \"original_question\": original_question,\n",
    "                \"context\": \"\\n\\n\".join(context) if context else \"ê´€ë ¨ ì •ë³´ ì—†ìŒ\",\n",
    "                \"quality_feedback\": quality_feedback\n",
    "            })\n",
    "            return improved_query.strip()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì¿¼ë¦¬ ê°œì„  ì‹¤íŒ¨ ({self.domain}): {e}\")\n",
    "            return original_question\n",
    "    \n",
    "    def query(self, question: str, enable_corrective: bool = True) -> RAGResponse:\n",
    "        \"\"\"Corrective RAGë¥¼ í¬í•¨í•œ ì§ˆë¬¸ ì²˜ë¦¬\"\"\"\n",
    "        \n",
    "        current_question = question\n",
    "        iterations = 0\n",
    "        \n",
    "        while iterations <= self.max_corrective_iterations:\n",
    "            # ë¬¸ì„œ ê²€ìƒ‰\n",
    "            source_docs = self.retrieve_documents(current_question)\n",
    "            \n",
    "            # ë‹µë³€ ìƒì„±\n",
    "            answer = self.generate_answer(current_question)\n",
    "            \n",
    "            # í’ˆì§ˆ í‰ê°€ (ì²« ë²ˆì§¸ ì‹œë„ì´ê±°ë‚˜ êµì • ê¸°ëŠ¥ì´ í™œì„±í™”ëœ ê²½ìš°)\n",
    "            quality_assessment = None\n",
    "            if self.quality_evaluator and (iterations == 0 or enable_corrective):\n",
    "                context_texts = [doc.page_content for doc in source_docs]\n",
    "                quality_assessment = self.quality_evaluator.evaluate(\n",
    "                    question, context_texts, answer\n",
    "                )\n",
    "                \n",
    "                # í’ˆì§ˆì´ ì¶©ë¶„í•˜ê±°ë‚˜ êµì • ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ëœ ê²½ìš° ì™„ë£Œ\n",
    "                if not enable_corrective or not quality_assessment.needs_improvement:\n",
    "                    break\n",
    "                \n",
    "                # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ì— ë„ë‹¬í•œ ê²½ìš° ì™„ë£Œ\n",
    "                if iterations >= self.max_corrective_iterations:\n",
    "                    break\n",
    "                \n",
    "                # ì¿¼ë¦¬ ê°œì„  ë° ì¬ì‹œë„\n",
    "                logger.info(f\"í’ˆì§ˆ ê°œì„  í•„ìš” - ì¿¼ë¦¬ ì¬ì‘ì„± ì‹œë„ {iterations + 1}\")\n",
    "                improved_question = self.improve_query(\n",
    "                    question, \n",
    "                    [doc.page_content for doc in source_docs],\n",
    "                    quality_assessment.reasoning\n",
    "                )\n",
    "                \n",
    "                current_question = improved_question\n",
    "                iterations += 1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        return RAGResponse(\n",
    "            answer=answer,\n",
    "            source_documents=source_docs,\n",
    "            domain=self.domain,\n",
    "            quality_assessment=quality_assessment,\n",
    "            corrective_iterations=iterations\n",
    "        )\n",
    "\n",
    "print(\"âœ… BaseRAGAgent í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "class WebSearchAgent:\n",
    "    \"\"\"ì›¹ ê²€ìƒ‰ ì „ìš© ì—ì´ì „íŠ¸\"\"\"\n",
    "    \n",
    "    def __init__(self, web_search_tool: TavilySearchResults, llm: ChatOpenAI):\n",
    "        self.web_search = web_search_tool\n",
    "        self.llm = llm\n",
    "        self.domain = \"web_search\"\n",
    "        self.agent_name = \"ì›¹ ê²€ìƒ‰ ì „ë¬¸ê°€\"\n",
    "        self.description = \"ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì„ í†µí•œ ìµœì‹  ì •ë³´ ì œê³µ\"\n",
    "        \n",
    "        # ì›¹ ê²€ìƒ‰ ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸\n",
    "        self.web_answer_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        ë‹¹ì‹ ì€ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "        \n",
    "        **ì§ˆë¬¸:** {question}\n",
    "        \n",
    "        **ì›¹ ê²€ìƒ‰ ê²°ê³¼:**\n",
    "        {search_results}\n",
    "        \n",
    "        **ë‹µë³€ ì§€ì¹¨:**\n",
    "        1. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ë‹µë³€ ì œê³µ\n",
    "        2. ìµœì‹  ì •ë³´ì„ì„ ëª…ì‹œí•˜ê³  ì¶œì²˜ ì–¸ê¸‰\n",
    "        3. ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ì •ë³´ê°€ ë‹¤ë¥¼ ê²½ìš° ì´ë¥¼ ëª…ì‹œ\n",
    "        4. ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ ìš°ì„  ì‚¬ìš©\n",
    "        5. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±\n",
    "        \n",
    "        **ë‹µë³€:**\n",
    "        \"\"\")\n",
    "        \n",
    "        # ë‹µë³€ ìƒì„± ì²´ì¸\n",
    "        self.answer_chain = (\n",
    "            self.web_answer_prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "    \n",
    "    def search_web(self, query: str) -> List[Dict]:\n",
    "        \"\"\"ì›¹ ê²€ìƒ‰ ìˆ˜í–‰\"\"\"\n",
    "        try:\n",
    "            if not self.web_search:\n",
    "                return []\n",
    "            \n",
    "            results = self.web_search.invoke({\"query\": query})\n",
    "            return results if isinstance(results, list) else []\n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def format_search_results(self, results: List[Dict]) -> str:\n",
    "        \"\"\"ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…\"\"\"\n",
    "        if not results:\n",
    "            return \"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        formatted = []\n",
    "        for i, result in enumerate(results, 1):\n",
    "            title = result.get(\"title\", \"ì œëª© ì—†ìŒ\")\n",
    "            content = result.get(\"content\", \"ë‚´ìš© ì—†ìŒ\")\n",
    "            url = result.get(\"url\", \"URL ì—†ìŒ\")\n",
    "            \n",
    "            formatted.append(f\"**ê²€ìƒ‰ ê²°ê³¼ {i}:**\\nì œëª©: {title}\\në‚´ìš©: {content}\\nì¶œì²˜: {url}\")\n",
    "        \n",
    "        return \"\\n\\n\".join(formatted)\n",
    "    \n",
    "    def query(self, question: str) -> RAGResponse:\n",
    "        \"\"\"ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ì§ˆë¬¸ ì²˜ë¦¬\"\"\"\n",
    "        # ì›¹ ê²€ìƒ‰ ìˆ˜í–‰\n",
    "        search_results = self.search_web(question)\n",
    "        \n",
    "        if not search_results:\n",
    "            answer = \"ì£„ì†¡í•©ë‹ˆë‹¤. ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "            source_docs = []\n",
    "        else:\n",
    "            # ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…\n",
    "            formatted_results = self.format_search_results(search_results)\n",
    "            \n",
    "            # ë‹µë³€ ìƒì„±\n",
    "            try:\n",
    "                answer = self.answer_chain.invoke({\n",
    "                    \"question\": question,\n",
    "                    \"search_results\": formatted_results\n",
    "                })\n",
    "            except Exception as e:\n",
    "                logger.error(f\"ì›¹ ê²€ìƒ‰ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "                answer = f\"ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì •ë³´ë¥¼ ì°¾ì•˜ìœ¼ë‚˜ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\\n\\nê²€ìƒ‰ ê²°ê³¼:\\n{formatted_results}\"\n",
    "            \n",
    "            # Document í˜•íƒœë¡œ ë³€í™˜\n",
    "            source_docs = []\n",
    "            for result in search_results:\n",
    "                doc = Document(\n",
    "                    page_content=result.get(\"content\", \"\"),\n",
    "                    metadata={\n",
    "                        \"title\": result.get(\"title\", \"\"),\n",
    "                        \"url\": result.get(\"url\", \"\"),\n",
    "                        \"source\": \"web_search\"\n",
    "                    }\n",
    "                )\n",
    "                source_docs.append(doc)\n",
    "        \n",
    "        return RAGResponse(\n",
    "            answer=answer,\n",
    "            source_documents=source_docs,\n",
    "            domain=self.domain,\n",
    "            quality_assessment=None,  # ì›¹ ê²€ìƒ‰ì€ í’ˆì§ˆ í‰ê°€ ìƒëµ\n",
    "            corrective_iterations=0\n",
    "        )\n",
    "\n",
    "# ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì´ˆê¸°í™”\n",
    "if web_search and llm:\n",
    "    web_search_agent = WebSearchAgent(web_search, llm)\n",
    "    print(\"âœ… ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "else:\n",
    "    web_search_agent = None\n",
    "    print(\"âŒ ì›¹ ê²€ìƒ‰ ë„êµ¬ ë˜ëŠ” LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ë„ë©”ì¸ë³„ RAG ì—ì´ì „íŠ¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:âœ… hr_policy ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ\n",
      "INFO:__main__:âœ… tech_policy ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ\n",
      "INFO:__main__:âœ… architecture ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ\n",
      "INFO:__main__:âœ… component ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ\n",
      "INFO:__main__:âœ… deployment ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ\n",
      "INFO:__main__:âœ… development ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ\n",
      "INFO:__main__:âœ… business_policy ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ë„ë©”ì¸ë³„ RAG ì—ì´ì „íŠ¸ ìƒì„± ì¤‘...\n",
      "\n",
      "\n",
      "ğŸ‰ RAG ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ!\n",
      "   - ìƒì„±ëœ ì—ì´ì „íŠ¸: 7ê°œ\n",
      "   ğŸ·ï¸  hr_policy: HR ì •ì±… ì „ë¬¸ê°€ (ì¸ì‚¬ì •ì±…, ê·¼ë¬´ì‹œê°„, íœ´ê°€, ê¸‰ì—¬, ë³µë¦¬í›„ìƒ)\n",
      "   ğŸ·ï¸  tech_policy: ê¸°ìˆ  ì •ì±… ì „ë¬¸ê°€ (ê¸°ìˆ ì •ì±…, ê°œë°œí™˜ê²½, ì½”ë”©í‘œì¤€, ë³´ì•ˆì •ì±…)\n",
      "   ğŸ·ï¸  architecture: ì•„í‚¤í…ì²˜ ì „ë¬¸ê°€ (CMS ì•„í‚¤í…ì²˜, ì‹œìŠ¤í…œì„¤ê³„, ë ˆì´ì–´êµ¬ì¡°)\n",
      "   ğŸ·ï¸  component: ì»´í¬ë„ŒíŠ¸ ê°œë°œ ì „ë¬¸ê°€ (ì»´í¬ë„ŒíŠ¸ ê°€ì´ë“œë¼ì¸, UI/UX í‘œì¤€)\n",
      "   ğŸ·ï¸  deployment: ë°°í¬ ì „ë¬¸ê°€ (ë°°í¬í”„ë¡œì„¸ìŠ¤, CI/CD, í™˜ê²½ê´€ë¦¬)\n",
      "   ğŸ·ï¸  development: ê°œë°œ í”„ë¡œì„¸ìŠ¤ ì „ë¬¸ê°€ (ê°œë°œí”„ë¡œì„¸ìŠ¤, ì›Œí¬í”Œë¡œìš°, í˜‘ì—…ê·œì¹™)\n",
      "   ğŸ·ï¸  business_policy: ë¹„ì¦ˆë‹ˆìŠ¤ ì •ì±… ì „ë¬¸ê°€ (ë¹„ì¦ˆë‹ˆìŠ¤ì •ì±…, ìš´ì˜ê·œì¹™, ì˜ì‚¬ê²°ì •)\n",
      "   ğŸŒ web_search: ì›¹ ê²€ìƒ‰ ì „ë¬¸ê°€ (ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì„ í†µí•œ ìµœì‹  ì •ë³´ ì œê³µ)\n",
      "\n",
      "ğŸ“Š ì „ì²´ ì—ì´ì „íŠ¸: 8ê°œ (ë„ë©”ì¸ 7ê°œ + ì›¹ê²€ìƒ‰ 1ê°œ)\n"
     ]
    }
   ],
   "source": [
    "def create_domain_agents(vectorstores: Dict[str, Chroma], \n",
    "                        llm: ChatOpenAI, \n",
    "                        quality_evaluator: QualityEvaluator) -> Dict[str, BaseRAGAgent]:\n",
    "    \"\"\"ë„ë©”ì¸ë³„ RAG ì—ì´ì „íŠ¸ ìƒì„±\"\"\"\n",
    "    \n",
    "    agents = {}\n",
    "    \n",
    "    for domain, vectorstore in vectorstores.items():\n",
    "        try:\n",
    "            agent = BaseRAGAgent(\n",
    "                domain=domain,\n",
    "                vectorstore=vectorstore,\n",
    "                llm=llm,\n",
    "                quality_evaluator=quality_evaluator,\n",
    "                max_corrective_iterations=2\n",
    "            )\n",
    "            \n",
    "            agents[domain] = agent\n",
    "            logger.info(f\"âœ… {domain} ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ {domain} ì—ì´ì „íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    return agents\n",
    "\n",
    "# ë„ë©”ì¸ë³„ RAG ì—ì´ì „íŠ¸ ìƒì„±\n",
    "if vectorstores and llm and quality_evaluator:\n",
    "    print(\"ğŸ¤– ë„ë©”ì¸ë³„ RAG ì—ì´ì „íŠ¸ ìƒì„± ì¤‘...\\n\")\n",
    "    \n",
    "    rag_agents = create_domain_agents(vectorstores, llm, quality_evaluator)\n",
    "    \n",
    "    print(f\"\\nğŸ‰ RAG ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ!\")\n",
    "    print(f\"   - ìƒì„±ëœ ì—ì´ì „íŠ¸: {len(rag_agents)}ê°œ\")\n",
    "    \n",
    "    # ê° ì—ì´ì „íŠ¸ ì •ë³´ ì¶œë ¥\n",
    "    for domain, agent in rag_agents.items():\n",
    "        print(f\"   ğŸ·ï¸  {domain}: {agent.agent_name} ({agent.description})\")\n",
    "    \n",
    "    # ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì¶”ê°€\n",
    "    if web_search_agent:\n",
    "        rag_agents[\"web_search\"] = web_search_agent\n",
    "        print(f\"   ğŸŒ web_search: {web_search_agent.agent_name} ({web_search_agent.description})\")\n",
    "        \n",
    "    print(f\"\\nğŸ“Š ì „ì²´ ì—ì´ì „íŠ¸: {len(rag_agents)}ê°œ (ë„ë©”ì¸ {len(vectorstores)}ê°œ + ì›¹ê²€ìƒ‰ 1ê°œ)\")\n",
    "    \n",
    "else:\n",
    "    rag_agents = {}\n",
    "    missing = []\n",
    "    if not vectorstores: missing.append(\"ë²¡í„° ì €ì¥ì†Œ\")\n",
    "    if not llm: missing.append(\"LLM\")\n",
    "    if not quality_evaluator: missing.append(\"í’ˆì§ˆ í‰ê°€ê¸°\")\n",
    "    \n",
    "    print(f\"âŒ RAG ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëˆ„ë½: {', '.join(missing)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì—ì´ì „íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì—ì´ì „íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...\n",
      "(ì„±ëŠ¥ì„ ìœ„í•´ ê° ë„ë©”ì¸ë‹¹ 1ê°œ ì§ˆë¬¸, ìµœëŒ€ 3ê°œ ë„ë©”ì¸ í…ŒìŠ¤íŠ¸)\n",
      "\n",
      "\n",
      "ğŸ§ª hr_policy ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸\n",
      "ğŸ·ï¸  ì—ì´ì „íŠ¸: HR ì •ì±… ì „ë¬¸ê°€\n",
      "==================================================\n",
      "\n",
      "ğŸ“‹ í…ŒìŠ¤íŠ¸ 1: ì—°ì°¨ íœ´ê°€ëŠ” ì–´ë–»ê²Œ ì‹ ì²­í•˜ë‚˜ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¬ ë‹µë³€:\n",
      "ì—°ì°¨ íœ´ê°€ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì ˆì°¨ë¡œ ì‹ ì²­í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ì‹ ì²­ì„œ ì‘ì„±**: ì—°ì°¨ íœ´ê°€ë¥¼ ì‹ ì²­í•˜ê¸° ìœ„í•´ì„œëŠ” ì‚¬ë‚´ì—ì„œ ì œê³µí•˜ëŠ” ì—°ì°¨ íœ´ê°€ ì‹ ì²­ì„œë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ì‹ ì²­ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì¸ì‚¬íŒ€ì´ë‚˜ ì‚¬ë‚´ í¬í„¸ì—ì„œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ìƒì‚¬ ìŠ¹ì¸**: ì‘ì„±í•œ ì‹ ì²­ì„œë¥¼ ìƒì‚¬ì—ê²Œ ì œì¶œí•˜ì—¬ ìŠ¹ì¸ì„ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤. ìƒì‚¬ëŠ” íŒ€ì˜ ì—…ë¬´ ìƒí™©ì„ ê³ ë ¤í•˜ì—¬ íœ´ê°€ë¥¼ ìŠ¹ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ì¸ì‚¬íŒ€ ì œì¶œ**: ìƒì‚¬ë¡œë¶€í„° ìŠ¹ì¸ì„ ë°›ì€ í›„, ìµœì¢…ì ìœ¼ë¡œ ì¸ì‚¬íŒ€ì— ì œì¶œí•˜ì—¬ íœ´ê°€ë¥¼ ê³µì‹ì ìœ¼ë¡œ ë“±ë¡í•©ë‹ˆë‹¤.\n",
      "\n",
      "4. **íœ´ê°€ ì‚¬ìš©**: ìŠ¹ì¸...\n",
      "\n",
      "ğŸ“Š ê²€ìƒ‰ ì •ë³´:\n",
      "   - ê²€ìƒ‰ëœ ë¬¸ì„œ: 5ê°œ\n",
      "   - êµì • ë°˜ë³µ: 0íšŒ\n",
      "\n",
      "ğŸ¯ í’ˆì§ˆ í‰ê°€:\n",
      "   - ì „ì²´ í’ˆì§ˆ: excellent\n",
      "   - ê´€ë ¨ì„±: 1.00\n",
      "   - ì •í™•ì„±: 1.00\n",
      "   - ì™„ì„±ë„: 1.00\n",
      "   - í™•ì‹ ë„: 1.00\n",
      "   - ê°œì„  í•„ìš”: ì•„ë‹ˆì˜¤\n",
      "\n",
      "âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ğŸ§ª tech_policy ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸\n",
      "ğŸ·ï¸  ì—ì´ì „íŠ¸: ê¸°ìˆ  ì •ì±… ì „ë¬¸ê°€\n",
      "==================================================\n",
      "\n",
      "ğŸ“‹ í…ŒìŠ¤íŠ¸ 1: ì½”ë”© ìŠ¤íƒ€ì¼ ê°€ì´ë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¬ ë‹µë³€:\n",
      "ì½”ë”© ìŠ¤íƒ€ì¼ ê°€ì´ë“œëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì‹œ ì½”ë“œì˜ ì¼ê´€ì„±ê³¼ ê°€ë…ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ì„¤ì •ëœ ê·œì¹™ê³¼ ì§€ì¹¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê°€ì´ë“œëŠ” íŒ€ ë‚´ì—ì„œ ì½”ë“œ ì‘ì„± ì‹œ í†µì¼ëœ ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•˜ë„ë¡ ë„ì™€ì£¼ë©°, í˜‘ì—… ì‹œ ì½”ë“œ ì´í•´ë„ë¥¼ ë†’ì´ê³  ìœ ì§€ë³´ìˆ˜ë¥¼ ìš©ì´í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ê¿€ìŠ¤í…Œì´ì˜ ì½”ë”© ìŠ¤íƒ€ì¼ ê°€ì´ë“œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” ìš”ì†Œë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **CSS/Styling ê·œì¹™**:\n",
      "   - Material-UIì˜ `styled()` ë˜ëŠ” `sx` propì„ ì‚¬ìš©í•˜ì—¬ ìŠ¤íƒ€ì¼ë§í•©ë‹ˆë‹¤.\n",
      "   - ì „ì—­ ìŠ¤íƒ€ì¼ì€ `themes/` í´ë”ì—ì„œ ê´€ë¦¬í•˜ë©°, ì»´...\n",
      "\n",
      "ğŸ“Š ê²€ìƒ‰ ì •ë³´:\n",
      "   - ê²€ìƒ‰ëœ ë¬¸ì„œ: 5ê°œ\n",
      "   - êµì • ë°˜ë³µ: 0íšŒ\n",
      "\n",
      "ğŸ¯ í’ˆì§ˆ í‰ê°€:\n",
      "   - ì „ì²´ í’ˆì§ˆ: excellent\n",
      "   - ê´€ë ¨ì„±: 1.00\n",
      "   - ì •í™•ì„±: 1.00\n",
      "   - ì™„ì„±ë„: 1.00\n",
      "   - í™•ì‹ ë„: 1.00\n",
      "   - ê°œì„  í•„ìš”: ì•„ë‹ˆì˜¤\n",
      "\n",
      "âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ğŸ§ª architecture ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸\n",
      "ğŸ·ï¸  ì—ì´ì „íŠ¸: ì•„í‚¤í…ì²˜ ì „ë¬¸ê°€\n",
      "==================================================\n",
      "\n",
      "ğŸ“‹ í…ŒìŠ¤íŠ¸ 1: ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ì˜ ì£¼ìš” êµ¬ì„±ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 20.000000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¬ ë‹µë³€:\n",
      "ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ì˜ ì£¼ìš” êµ¬ì„±ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **í´ë¼ì´ì–¸íŠ¸-ì„œë²„ êµ¬ì¡°**:\n",
      "   - **í´ë¼ì´ì–¸íŠ¸**: ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ë¶€ë¶„ìœ¼ë¡œ, ê¿€ìŠ¤í…Œì´ì—ì„œëŠ” React CMSê°€ í•´ë‹¹ ì—­í• ì„ í•©ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì§ì ‘ ìƒí˜¸ì‘ìš©í•˜ëŠ” í”„ë¡ íŠ¸ì—”ë“œì…ë‹ˆë‹¤.\n",
      "   - **ì„œë²„**: í´ë¼ì´ì–¸íŠ¸ì˜ ìš”ì²­ì„ ì²˜ë¦¬í•˜ê³  ë°ì´í„°ë¥¼ ì œê³µí•˜ëŠ” Backend APIê°€ ìˆìŠµë‹ˆë‹¤. ì´ APIëŠ” Java ë˜ëŠ” Node.jsë¡œ êµ¬í˜„ë˜ì–´ ìˆìœ¼ë©°, í´ë¼ì´ì–¸íŠ¸ì™€ ë°ì´í„°ë² ì´ìŠ¤ ê°„ì˜ ì¤‘ê°œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "   - **ë°ì´í„°ë² ì´ìŠ¤**: MySQL ë˜ëŠ” Redisì™€ ê°™ì€...\n",
      "\n",
      "ğŸ“Š ê²€ìƒ‰ ì •ë³´:\n",
      "   - ê²€ìƒ‰ëœ ë¬¸ì„œ: 5ê°œ\n",
      "   - êµì • ë°˜ë³µ: 0íšŒ\n",
      "\n",
      "ğŸ¯ í’ˆì§ˆ í‰ê°€:\n",
      "   - ì „ì²´ í’ˆì§ˆ: excellent\n",
      "   - ê´€ë ¨ì„±: 1.00\n",
      "   - ì •í™•ì„±: 1.00\n",
      "   - ì™„ì„±ë„: 1.00\n",
      "   - í™•ì‹ ë„: 1.00\n",
      "   - ê°œì„  í•„ìš”: ì•„ë‹ˆì˜¤\n",
      "\n",
      "âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ˆ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\n",
      "   - í…ŒìŠ¤íŠ¸ëœ ë„ë©”ì¸: 3ê°œ\n",
      "   - ì´ í…ŒìŠ¤íŠ¸ íšŸìˆ˜: 3ê°œ\n",
      "\n",
      "ğŸ¯ í‰ê·  í’ˆì§ˆ ì ìˆ˜:\n",
      "   - ê´€ë ¨ì„±: 1.00\n",
      "   - ì •í™•ì„±: 1.00\n",
      "   - ì™„ì„±ë„: 1.00\n",
      "   - í™•ì‹ ë„: 1.00\n",
      "\n",
      "ğŸ”„ Corrective RAG í™œìš©:\n",
      "   - êµì • ì‚¬ìš© íšŸìˆ˜: 0/3\n",
      "   - í‰ê·  êµì • ë°˜ë³µ: 0.0íšŒ\n",
      "\n",
      "âœ… ì—ì´ì „íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ë„ë©”ì¸ë³„ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸\n",
    "test_questions = {\n",
    "    \"hr_policy\": [\n",
    "        \"ì—°ì°¨ íœ´ê°€ëŠ” ì–´ë–»ê²Œ ì‹ ì²­í•˜ë‚˜ìš”?\",\n",
    "        \"ì¬íƒê·¼ë¬´ ì •ì±…ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\"\n",
    "    ],\n",
    "    \"tech_policy\": [\n",
    "        \"ì½”ë”© ìŠ¤íƒ€ì¼ ê°€ì´ë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "        \"ë³´ì•ˆ ì •ì±…ì—ì„œ ì¤‘ìš”í•œ ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "    ],\n",
    "    \"architecture\": [\n",
    "        \"ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ì˜ ì£¼ìš” êµ¬ì„±ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "        \"ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ëŠ” ì–´ë–»ê²Œ êµ¬ì„±ë˜ë‚˜ìš”?\"\n",
    "    ],\n",
    "    \"component\": [\n",
    "        \"UI ì»´í¬ë„ŒíŠ¸ ê°œë°œ ì‹œ ì£¼ì˜ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "        \"ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì€?\"\n",
    "    ],\n",
    "    \"deployment\": [\n",
    "        \"ë°°í¬ í”„ë¡œì„¸ìŠ¤ëŠ” ì–´ë–»ê²Œ ì§„í–‰í•˜ë‚˜ìš”?\",\n",
    "        \"CI/CD íŒŒì´í”„ë¼ì¸ì€ ì–´ë–»ê²Œ êµ¬ì„±ë˜ë‚˜ìš”?\"\n",
    "    ],\n",
    "    \"development\": [\n",
    "        \"ê°œë°œ ì›Œí¬í”Œë¡œìš°ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n",
    "        \"ì½”ë“œ ë¦¬ë·° í”„ë¡œì„¸ìŠ¤ëŠ” ì–´ë–»ê²Œ ì§„í–‰í•˜ë‚˜ìš”?\"\n",
    "    ],\n",
    "    \"business_policy\": [\n",
    "        \"ì˜ì‚¬ê²°ì • í”„ë¡œì„¸ìŠ¤ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n",
    "        \"íšŒì‚¬ì˜ í•µì‹¬ ê°€ì¹˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "    ],\n",
    "    \"web_search\": [\n",
    "        \"2024ë…„ AI ê¸°ìˆ  íŠ¸ë Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "        \"ìµœì‹  ì›¹ ê°œë°œ í”„ë ˆì„ì›Œí¬ ë™í–¥ì€?\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def test_agent_performance(agents: Dict[str, BaseRAGAgent], \n",
    "                         test_questions: Dict[str, List[str]], \n",
    "                         max_domains: int = 3) -> List[Dict]:\n",
    "    \"\"\"ì—ì´ì „íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    test_results = []\n",
    "    tested_domains = 0\n",
    "    \n",
    "    for domain, questions in test_questions.items():\n",
    "        if tested_domains >= max_domains:\n",
    "            break\n",
    "            \n",
    "        if domain not in agents:\n",
    "            print(f\"âš ï¸ {domain} ì—ì´ì „íŠ¸ê°€ ì—†ì–´ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            continue\n",
    "            \n",
    "        agent = agents[domain]\n",
    "        \n",
    "        print(f\"\\nğŸ§ª {domain} ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸\")\n",
    "        print(f\"ğŸ·ï¸  ì—ì´ì „íŠ¸: {agent.agent_name}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        for i, question in enumerate(questions[:1], 1):  # ê° ë„ë©”ì¸ë‹¹ 1ê°œ ì§ˆë¬¸ë§Œ í…ŒìŠ¤íŠ¸\n",
    "            print(f\"\\nğŸ“‹ í…ŒìŠ¤íŠ¸ {i}: {question}\")\n",
    "            \n",
    "            try:\n",
    "                # RAG ì¿¼ë¦¬ ì‹¤í–‰ (Corrective RAG í™œì„±í™”)\n",
    "                response = agent.query(question, enable_corrective=True)\n",
    "                \n",
    "                # ê²°ê³¼ ì¶œë ¥\n",
    "                print(f\"\\nğŸ’¬ ë‹µë³€:\")\n",
    "                print(response.answer[:300] + \"...\" if len(response.answer) > 300 else response.answer)\n",
    "                \n",
    "                print(f\"\\nğŸ“Š ê²€ìƒ‰ ì •ë³´:\")\n",
    "                print(f\"   - ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(response.source_documents)}ê°œ\")\n",
    "                print(f\"   - êµì • ë°˜ë³µ: {response.corrective_iterations}íšŒ\")\n",
    "                \n",
    "                # í’ˆì§ˆ í‰ê°€ ê²°ê³¼\n",
    "                if response.quality_assessment:\n",
    "                    qa = response.quality_assessment\n",
    "                    print(f\"\\nğŸ¯ í’ˆì§ˆ í‰ê°€:\")\n",
    "                    print(f\"   - ì „ì²´ í’ˆì§ˆ: {qa.overall_quality.value}\")\n",
    "                    print(f\"   - ê´€ë ¨ì„±: {qa.relevance_score:.2f}\")\n",
    "                    print(f\"   - ì •í™•ì„±: {qa.accuracy_score:.2f}\")\n",
    "                    print(f\"   - ì™„ì„±ë„: {qa.completeness_score:.2f}\")\n",
    "                    print(f\"   - í™•ì‹ ë„: {qa.confidence_score:.2f}\")\n",
    "                    print(f\"   - ê°œì„  í•„ìš”: {'ì˜ˆ' if qa.needs_improvement else 'ì•„ë‹ˆì˜¤'}\")\n",
    "                \n",
    "                # ê²°ê³¼ ì €ì¥\n",
    "                result = {\n",
    "                    \"domain\": domain,\n",
    "                    \"question\": question,\n",
    "                    \"answer_length\": len(response.answer),\n",
    "                    \"source_count\": len(response.source_documents),\n",
    "                    \"corrective_iterations\": response.corrective_iterations,\n",
    "                    \"quality_assessment\": response.quality_assessment\n",
    "                }\n",
    "                test_results.append(result)\n",
    "                \n",
    "                print(f\"\\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "                logger.error(f\"ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ({domain}): {e}\")\n",
    "        \n",
    "        tested_domains += 1\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "if rag_agents:\n",
    "    print(\"ğŸš€ ì—ì´ì „íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "    print(\"(ì„±ëŠ¥ì„ ìœ„í•´ ê° ë„ë©”ì¸ë‹¹ 1ê°œ ì§ˆë¬¸, ìµœëŒ€ 3ê°œ ë„ë©”ì¸ í…ŒìŠ¤íŠ¸)\\n\")\n",
    "    \n",
    "    test_results = test_agent_performance(rag_agents, test_questions, max_domains=3)\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\n",
    "    if test_results:\n",
    "        print(f\"\\nğŸ“ˆ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\")\n",
    "        print(f\"   - í…ŒìŠ¤íŠ¸ëœ ë„ë©”ì¸: {len(set(r['domain'] for r in test_results))}ê°œ\")\n",
    "        print(f\"   - ì´ í…ŒìŠ¤íŠ¸ íšŸìˆ˜: {len(test_results)}ê°œ\")\n",
    "        \n",
    "        # í’ˆì§ˆ í‰ê°€ ìš”ì•½\n",
    "        quality_results = [r for r in test_results if r['quality_assessment']]\n",
    "        if quality_results:\n",
    "            avg_relevance = sum(r['quality_assessment'].relevance_score for r in quality_results) / len(quality_results)\n",
    "            avg_accuracy = sum(r['quality_assessment'].accuracy_score for r in quality_results) / len(quality_results)\n",
    "            avg_completeness = sum(r['quality_assessment'].completeness_score for r in quality_results) / len(quality_results)\n",
    "            avg_confidence = sum(r['quality_assessment'].confidence_score for r in quality_results) / len(quality_results)\n",
    "            \n",
    "            print(f\"\\nğŸ¯ í‰ê·  í’ˆì§ˆ ì ìˆ˜:\")\n",
    "            print(f\"   - ê´€ë ¨ì„±: {avg_relevance:.2f}\")\n",
    "            print(f\"   - ì •í™•ì„±: {avg_accuracy:.2f}\")\n",
    "            print(f\"   - ì™„ì„±ë„: {avg_completeness:.2f}\")\n",
    "            print(f\"   - í™•ì‹ ë„: {avg_confidence:.2f}\")\n",
    "        \n",
    "        # Corrective RAG íš¨ê³¼\n",
    "        corrective_used = sum(1 for r in test_results if r['corrective_iterations'] > 0)\n",
    "        print(f\"\\nğŸ”„ Corrective RAG í™œìš©:\")\n",
    "        print(f\"   - êµì • ì‚¬ìš© íšŸìˆ˜: {corrective_used}/{len(test_results)}\")\n",
    "        print(f\"   - í‰ê·  êµì • ë°˜ë³µ: {sum(r['corrective_iterations'] for r in test_results) / len(test_results):.1f}íšŒ\")\n",
    "        \n",
    "    print(\"\\nâœ… ì—ì´ì „íŠ¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(\"âŒ ìƒì„±ëœ ì—ì´ì „íŠ¸ê°€ ì—†ì–´ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "### âœ… ì™„ë£Œëœ ì‘ì—…\n",
    "1. **ê¸°ë³¸ RAG ì—ì´ì „íŠ¸ í´ë˜ìŠ¤**: BaseRAGAgent êµ¬í˜„\n",
    "2. **Corrective RAG ë©”ì»¤ë‹ˆì¦˜**: í’ˆì§ˆ í‰ê°€ ê¸°ë°˜ ìë™ ì¿¼ë¦¬ ê°œì„ \n",
    "3. **ë„ë©”ì¸ë³„ ì „ë¬¸ ì—ì´ì „íŠ¸**: 7ê°œ ë„ë©”ì¸ ê°ê°ì˜ RAG ì—ì´ì „íŠ¸\n",
    "4. **ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸**: Tavily API ê¸°ë°˜ ì‹¤ì‹œê°„ ê²€ìƒ‰\n",
    "5. **í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ**: 4ì°¨ì› í’ˆì§ˆ í‰ê°€ (ê´€ë ¨ì„±, ì •í™•ì„±, ì™„ì„±ë„, í™•ì‹ ë„)\n",
    "6. **ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**: ê° ì—ì´ì „íŠ¸ì˜ ê¸°ëŠ¥ ê²€ì¦\n",
    "\n",
    "### ğŸ”§ í•µì‹¬ ê¸°ëŠ¥\n",
    "- **Multi-Agent RAG**: 8ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ (7ê°œ ë„ë©”ì¸ + 1ê°œ ì›¹ê²€ìƒ‰)\n",
    "- **Self-Correcting**: í’ˆì§ˆì´ ë¶€ì¡±í•  ê²½ìš° ìë™ìœ¼ë¡œ ì¿¼ë¦¬ ê°œì„  í›„ ì¬ê²€ìƒ‰\n",
    "- **Quality Assessment**: AI ê¸°ë°˜ 6ì°¨ì› í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ\n",
    "- **Domain Expertise**: ê° ë„ë©”ì¸ì— íŠ¹í™”ëœ ì „ë¬¸ ì§€ì‹ê³¼ ì–´ì¡°\n",
    "\n",
    "### ğŸ“Š ì£¼ìš” ì„±ê³¼\n",
    "- ë„ë©”ì¸ë³„ ì „ë¬¸í™”ëœ ë‹µë³€ í’ˆì§ˆ\n",
    "- Corrective RAGë¥¼ í†µí•œ ë‹µë³€ ê°œì„ \n",
    "- ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ìµœì‹  ì •ë³´ ë³´ì™„\n",
    "- ì²´ê³„ì ì¸ í’ˆì§ˆ í‰ê°€ ë° ê´€ë¦¬\n",
    "\n",
    "### ğŸš€ ë‹¤ìŒ ë‹¨ê³„\n",
    "**04_routing_integration.ipynb**: ì§ˆë¬¸ ë¼ìš°íŒ… ë° ë©€í‹° ì—ì´ì „íŠ¸ í†µí•©\n",
    "- ì§ˆë¬¸ ë¶„ì„ ë° ì ì ˆí•œ ì—ì´ì „íŠ¸ ì„ íƒ\n",
    "- ë©€í‹° ì—ì´ì „íŠ¸ ë‹µë³€ ì¡°í•© ë¡œì§\n",
    "- ë§ˆìŠ¤í„° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ êµ¬í˜„"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
