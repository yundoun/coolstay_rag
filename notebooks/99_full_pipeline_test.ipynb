{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 꿀스테이 RAG - 전체 파이프라인 통합 테스트\n",
    "\n",
    "이 노트북에서는 1-5번 노트북의 모든 컴포넌트를 통합하여 완전한 RAG 시스템을 테스트합니다.\n",
    "\n",
    "## 목표\n",
    "1. 전체 RAG 파이프라인 통합\n",
    "2. 엔드투엔드 성능 테스트\n",
    "3. 실제 사용 시나리오 검증\n",
    "4. 시스템 벤치마크 및 성능 분석\n",
    "5. 최종 배포 준비 상태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport sys\nimport time\nimport json\nimport uuid\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Optional, Tuple, Union\nimport logging\nfrom datetime import datetime, timedelta\nfrom dataclasses import dataclass, field\nfrom enum import Enum\n\n# 환경 및 설정\nfrom dotenv import load_dotenv\n\n# LangChain 생태계\nfrom langchain_openai import ChatOpenAI\nfrom langchain_ollama import OllamaEmbeddings\nfrom langchain_chroma import Chroma\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser, JsonOutputParser\nfrom langchain_core.documents import Document\nfrom langchain.text_splitter import MarkdownHeaderTextSplitter\nfrom langchain_community.tools import TavilySearchResults\n\n# LangGraph\nfrom langgraph.graph import StateGraph, END\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom typing_extensions import TypedDict\n\n# 데이터 분석 및 시각화\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display, HTML, clear_output\nimport ipywidgets as widgets\n\n# 환경변수 로드 (절대 경로 지정)\nproject_root = Path(\"/Users/yundoun/Desktop/Project/legal_rag/coolstay_rag\")\nenv_file = project_root / \".env\"\nload_result = load_dotenv(env_file)\nprint(f\"📝 .env 파일 로드: {load_result} (경로: {env_file})\")\n\n# API 키 확인\nopenai_key = os.getenv(\"OPENAI_API_KEY\", \"NOT_FOUND\")\ntavily_key = os.getenv(\"TAVILY_API_KEY\", \"NOT_FOUND\")\nprint(f\"🔑 OpenAI API Key: {'설정됨' if openai_key != 'NOT_FOUND' and openai_key.startswith('sk-') else 'NOT_FOUND'}\")\nprint(f\"🔑 Tavily API Key: {'설정됨' if tavily_key != 'NOT_FOUND' and tavily_key.startswith('tvly-') else 'NOT_FOUND'}\")\n\n# 로깅 설정\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n# 시각화 설정\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (12, 8)\nsns.set_style(\"whitegrid\")\n\nprint(\"✅ 라이브러리 import 완료\")\nprint(f\"📅 테스트 시작 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 통합 시스템 설정 및 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로젝트 경로 및 설정\n",
    "PROJECT_ROOT = Path(\"/Users/yundoun/Desktop/Project/legal_rag/coolstay_rag\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "CHROMA_DB_DIR = PROJECT_ROOT / \"chroma_db\"\n",
    "NOTEBOOKS_DIR = PROJECT_ROOT / \"notebooks\"\n",
    "\n",
    "# 도메인 설정 (전체 시스템 통합용)\n",
    "DOMAIN_CONFIG = {\n",
    "    \"hr_policy\": {\n",
    "        \"file\": \"HR_Policy_Guide.md\",\n",
    "        \"description\": \"인사정책, 근무시간, 휴가, 급여, 복리후생\",\n",
    "        \"collection_name\": \"hr_policy_db\",\n",
    "        \"agent_name\": \"HR 정책 전문가\",\n",
    "        \"keywords\": [\"인사\", \"HR\", \"근무\", \"휴가\", \"연차\", \"급여\", \"보험\", \"복리후생\", \"채용\", \"퇴사\"]\n",
    "    },\n",
    "    \"tech_policy\": {\n",
    "        \"file\": \"Tech_Policy_Guide.md\",\n",
    "        \"description\": \"기술정책, 개발환경, 코딩표준, 보안정책\",\n",
    "        \"collection_name\": \"tech_policy_db\",\n",
    "        \"agent_name\": \"기술 정책 전문가\",\n",
    "        \"keywords\": [\"기술\", \"개발\", \"코딩\", \"코드\", \"프로그래밍\", \"보안\", \"개발환경\", \"IDE\", \"도구\"]\n",
    "    },\n",
    "    \"architecture\": {\n",
    "        \"file\": \"Architecture_Guide.md\",\n",
    "        \"description\": \"CMS 아키텍처, 시스템설계, 레이어구조\",\n",
    "        \"collection_name\": \"architecture_db\",\n",
    "        \"agent_name\": \"아키텍처 전문가\",\n",
    "        \"keywords\": [\"아키텍처\", \"시스템\", \"설계\", \"구조\", \"레이어\", \"모듈\", \"서비스\", \"API\", \"데이터베이스\"]\n",
    "    },\n",
    "    \"component\": {\n",
    "        \"file\": \"Component_Guide.md\",\n",
    "        \"description\": \"컴포넌트 가이드라인, UI/UX 표준\",\n",
    "        \"collection_name\": \"component_db\",\n",
    "        \"agent_name\": \"컴포넌트 개발 전문가\",\n",
    "        \"keywords\": [\"컴포넌트\", \"UI\", \"UX\", \"인터페이스\", \"디자인\", \"프론트엔드\", \"사용자\", \"화면\"]\n",
    "    },\n",
    "    \"deployment\": {\n",
    "        \"file\": \"Deployment_Guide.md\",\n",
    "        \"description\": \"배포프로세스, CI/CD, 환경관리\",\n",
    "        \"collection_name\": \"deployment_db\",\n",
    "        \"agent_name\": \"배포 전문가\",\n",
    "        \"keywords\": [\"배포\", \"CI/CD\", \"환경\", \"서버\", \"클라우드\", \"도커\", \"쿠버네티스\", \"파이프라인\"]\n",
    "    },\n",
    "    \"development\": {\n",
    "        \"file\": \"Development_Process_Guide.md\",\n",
    "        \"description\": \"개발프로세스, 워크플로우, 협업규칙\",\n",
    "        \"collection_name\": \"development_db\",\n",
    "        \"agent_name\": \"개발 프로세스 전문가\",\n",
    "        \"keywords\": [\"개발프로세스\", \"워크플로우\", \"협업\", \"프로세스\", \"방법론\", \"스크럼\", \"애자일\"]\n",
    "    },\n",
    "    \"business_policy\": {\n",
    "        \"file\": \"Business_Policy_Guide.md\",\n",
    "        \"description\": \"비즈니스정책, 운영규칙, 의사결정\",\n",
    "        \"collection_name\": \"business_policy_db\",\n",
    "        \"agent_name\": \"비즈니스 정책 전문가\",\n",
    "        \"keywords\": [\"비즈니스\", \"정책\", \"운영\", \"의사결정\", \"전략\", \"계획\", \"목표\", \"성과\"]\n",
    "    },\n",
    "    \"web_search\": {\n",
    "        \"description\": \"실시간 웹 검색을 통한 최신 정보 제공\",\n",
    "        \"agent_name\": \"웹 검색 전문가\",\n",
    "        \"keywords\": [\"최신\", \"트렌드\", \"뉴스\", \"동향\", \"현재\", \"실시간\", \"업데이트\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"✅ 프로젝트 설정 완료\")\n",
    "print(f\"   - 프로젝트 루트: {PROJECT_ROOT}\")\n",
    "print(f\"   - 데이터 디렉토리: {DATA_DIR}\")\n",
    "print(f\"   - ChromaDB 디렉토리: {CHROMA_DB_DIR}\")\n",
    "print(f\"   - 도메인 수: {len(DOMAIN_CONFIG)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시스템 초기화 상태 추적\n",
    "@dataclass\n",
    "class SystemInitStatus:\n",
    "    llm: bool = False\n",
    "    embeddings: bool = False\n",
    "    web_search: bool = False\n",
    "    vectorstores: Dict[str, bool] = field(default_factory=dict)\n",
    "    agents: Dict[str, bool] = field(default_factory=dict)\n",
    "    \n",
    "    def overall_status(self) -> float:\n",
    "        \"\"\"전체 초기화 성공률 계산\"\"\"\n",
    "        total_components = 3 + len(DOMAIN_CONFIG) * 2  # LLM, Embeddings, WebSearch + (Vectorstore + Agent) per domain\n",
    "        successful_components = (\n",
    "            int(self.llm) + \n",
    "            int(self.embeddings) + \n",
    "            int(self.web_search) +\n",
    "            sum(self.vectorstores.values()) +\n",
    "            sum(self.agents.values())\n",
    "        )\n",
    "        return (successful_components / total_components) * 100\n",
    "\n",
    "init_status = SystemInitStatus()\n",
    "\n",
    "def initialize_system_components():\n",
    "    \"\"\"시스템 컴포넌트 통합 초기화\"\"\"\n",
    "    \n",
    "    print(\"🔧 시스템 컴포넌트 초기화 시작...\\n\")\n",
    "    \n",
    "    # 1. LLM 초기화\n",
    "    print(\"1️⃣ LLM 초기화...\")\n",
    "    try:\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.1,\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        # 테스트 호출\n",
    "        test_response = llm.invoke(\"Hello\")\n",
    "        init_status.llm = True\n",
    "        print(f\"   ✅ LLM 초기화 성공: {llm.model_name}\")\n",
    "    except Exception as e:\n",
    "        llm = None\n",
    "        print(f\"   ❌ LLM 초기화 실패: {e}\")\n",
    "    \n",
    "    # 2. 임베딩 모델 초기화\n",
    "    print(\"\\n2️⃣ 임베딩 모델 초기화...\")\n",
    "    try:\n",
    "        embeddings = OllamaEmbeddings(\n",
    "            model=\"bge-m3\",\n",
    "            base_url=\"http://localhost:11434\"\n",
    "        )\n",
    "        # 테스트 임베딩\n",
    "        test_embedding = embeddings.embed_query(\"test\")\n",
    "        init_status.embeddings = True\n",
    "        print(f\"   ✅ 임베딩 모델 초기화 성공: bge-m3 ({len(test_embedding)}차원)\")\n",
    "    except Exception as e:\n",
    "        embeddings = None\n",
    "        print(f\"   ❌ 임베딩 모델 초기화 실패: {e}\")\n",
    "    \n",
    "    # 3. 웹 검색 도구 초기화\n",
    "    print(\"\\n3️⃣ 웹 검색 도구 초기화...\")\n",
    "    try:\n",
    "        web_search = TavilySearchResults(\n",
    "            max_results=3,\n",
    "            api_key=os.getenv(\"TAVILY_API_KEY\")\n",
    "        )\n",
    "        init_status.web_search = True\n",
    "        print(f\"   ✅ 웹 검색 도구 초기화 성공\")\n",
    "    except Exception as e:\n",
    "        web_search = None\n",
    "        print(f\"   ❌ 웹 검색 도구 초기화 실패: {e}\")\n",
    "    \n",
    "    # 4. 벡터 저장소 로딩\n",
    "    print(\"\\n4️⃣ 벡터 저장소 로딩...\")\n",
    "    vectorstores = {}\n",
    "    \n",
    "    if embeddings:\n",
    "        for domain in DOMAIN_CONFIG.keys():\n",
    "            if domain == \"web_search\":\n",
    "                continue\n",
    "                \n",
    "            collection_name = DOMAIN_CONFIG[domain][\"collection_name\"]\n",
    "            persist_directory = str(CHROMA_DB_DIR / domain)\n",
    "            \n",
    "            try:\n",
    "                if Path(persist_directory).exists():\n",
    "                    vectorstore = Chroma(\n",
    "                        collection_name=collection_name,\n",
    "                        embedding_function=embeddings,\n",
    "                        persist_directory=persist_directory\n",
    "                    )\n",
    "                    \n",
    "                    # 연결 테스트\n",
    "                    count = vectorstore._collection.count()\n",
    "                    vectorstores[domain] = vectorstore\n",
    "                    init_status.vectorstores[domain] = True\n",
    "                    print(f\"   ✅ {domain}: {count}개 문서\")\n",
    "                else:\n",
    "                    init_status.vectorstores[domain] = False\n",
    "                    print(f\"   ⚠️  {domain}: 벡터 저장소 없음\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                init_status.vectorstores[domain] = False\n",
    "                print(f\"   ❌ {domain}: 로딩 실패 - {e}\")\n",
    "    else:\n",
    "        print(\"   ❌ 임베딩 모델이 없어 벡터 저장소를 로딩할 수 없습니다.\")\n",
    "    \n",
    "    # 5. 에이전트 초기화 (간소화된 버전)\n",
    "    print(\"\\n5️⃣ RAG 에이전트 초기화...\")\n",
    "    agents = {}\n",
    "    \n",
    "    if llm:\n",
    "        for domain in DOMAIN_CONFIG.keys():\n",
    "            try:\n",
    "                if domain == \"web_search\":\n",
    "                    if web_search:\n",
    "                        # 간소화된 웹 검색 에이전트\n",
    "                        agents[domain] = {\"type\": \"web_search\", \"tool\": web_search, \"llm\": llm}\n",
    "                        init_status.agents[domain] = True\n",
    "                        print(f\"   ✅ {domain}: 웹 검색 에이전트\")\n",
    "                    else:\n",
    "                        init_status.agents[domain] = False\n",
    "                        print(f\"   ❌ {domain}: 웹 검색 도구 없음\")\n",
    "                else:\n",
    "                    if domain in vectorstores:\n",
    "                        # 간소화된 RAG 에이전트\n",
    "                        agents[domain] = {\n",
    "                            \"type\": \"rag\", \n",
    "                            \"vectorstore\": vectorstores[domain], \n",
    "                            \"llm\": llm,\n",
    "                            \"config\": DOMAIN_CONFIG[domain]\n",
    "                        }\n",
    "                        init_status.agents[domain] = True\n",
    "                        print(f\"   ✅ {domain}: RAG 에이전트\")\n",
    "                    else:\n",
    "                        init_status.agents[domain] = False\n",
    "                        print(f\"   ❌ {domain}: 벡터 저장소 없음\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                init_status.agents[domain] = False\n",
    "                print(f\"   ❌ {domain}: 에이전트 초기화 실패 - {e}\")\n",
    "    else:\n",
    "        print(\"   ❌ LLM이 없어 에이전트를 초기화할 수 없습니다.\")\n",
    "    \n",
    "    # 초기화 요약\n",
    "    success_rate = init_status.overall_status()\n",
    "    print(f\"\\n📊 시스템 초기화 완료\")\n",
    "    print(f\"   - 전체 성공률: {success_rate:.1f}%\")\n",
    "    print(f\"   - LLM: {'✅' if init_status.llm else '❌'}\")\n",
    "    print(f\"   - 임베딩: {'✅' if init_status.embeddings else '❌'}\")\n",
    "    print(f\"   - 웹 검색: {'✅' if init_status.web_search else '❌'}\")\n",
    "    print(f\"   - 벡터 저장소: {sum(init_status.vectorstores.values())}/{len([d for d in DOMAIN_CONFIG if d != 'web_search'])}개\")\n",
    "    print(f\"   - 에이전트: {sum(init_status.agents.values())}/{len(DOMAIN_CONFIG)}개\")\n",
    "    \n",
    "    return {\n",
    "        \"llm\": llm,\n",
    "        \"embeddings\": embeddings,\n",
    "        \"web_search\": web_search,\n",
    "        \"vectorstores\": vectorstores,\n",
    "        \"agents\": agents,\n",
    "        \"init_status\": init_status\n",
    "    }\n",
    "\n",
    "# 시스템 초기화 실행\n",
    "system_components = initialize_system_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 통합 RAG 파이프라인 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PipelineTestResult:\n",
    "    \"\"\"파이프라인 테스트 결과\"\"\"\n",
    "    test_id: str\n",
    "    question: str\n",
    "    answer: str\n",
    "    selected_domains: List[str]\n",
    "    processing_time: float\n",
    "    success: bool\n",
    "    error_message: Optional[str] = None\n",
    "    \n",
    "    # 상세 정보\n",
    "    question_analysis_time: float = 0.0\n",
    "    agent_execution_time: float = 0.0\n",
    "    response_integration_time: float = 0.0\n",
    "    \n",
    "    # 품질 정보\n",
    "    confidence_score: float = 0.0\n",
    "    source_count: int = 0\n",
    "    \n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "class IntegratedRAGPipeline:\n",
    "    \"\"\"통합 RAG 파이프라인\"\"\"\n",
    "    \n",
    "    def __init__(self, system_components: Dict[str, Any]):\n",
    "        self.llm = system_components[\"llm\"]\n",
    "        self.embeddings = system_components[\"embeddings\"]\n",
    "        self.web_search = system_components[\"web_search\"]\n",
    "        self.vectorstores = system_components[\"vectorstores\"]\n",
    "        self.agents = system_components[\"agents\"]\n",
    "        self.init_status = system_components[\"init_status\"]\n",
    "        \n",
    "        # 질문 분석 프롬프트\n",
    "        self.question_analysis_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        다음 질문을 분석하여 적절한 전문가 도메인을 선택해주세요.\n",
    "        \n",
    "        **질문:** {question}\n",
    "        \n",
    "        **사용 가능한 도메인:**\n",
    "        - hr_policy: 인사정책, 근무시간, 휴가, 급여, 복리후생\n",
    "        - tech_policy: 기술정책, 개발환경, 코딩표준, 보안정책\n",
    "        - architecture: CMS 아키텍처, 시스템설계, 레이어구조\n",
    "        - component: 컴포넌트 가이드라인, UI/UX 표준\n",
    "        - deployment: 배포프로세스, CI/CD, 환경관리\n",
    "        - development: 개발프로세스, 워크플로우, 협업규칙\n",
    "        - business_policy: 비즈니스정책, 운영규칙, 의사결정\n",
    "        - web_search: 실시간 웹 검색, 최신 정보\n",
    "        \n",
    "        최대 3개 도메인을 선택하고 JSON 형식으로 응답하세요:\n",
    "        {{\n",
    "            \"selected_domains\": [\"domain1\", \"domain2\"],\n",
    "            \"reasoning\": \"선택 근거\"\n",
    "        }}\n",
    "        \"\"\")\n",
    "        \n",
    "        # 답변 통합 프롬프트\n",
    "        self.integration_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        여러 전문가의 답변을 통합하여 최종 답변을 생성해주세요.\n",
    "        \n",
    "        **질문:** {question}\n",
    "        \n",
    "        **전문가 답변들:**\n",
    "        {expert_answers}\n",
    "        \n",
    "        **통합 지침:**\n",
    "        1. 각 전문가의 답변을 종합하여 완성도 높은 답변 생성\n",
    "        2. 중복 내용 제거 및 일관성 유지\n",
    "        3. 실용적이고 구체적인 정보 우선\n",
    "        4. 한국어로 자연스럽게 작성\n",
    "        \n",
    "        통합된 최종 답변:\n",
    "        \"\"\")\n",
    "        \n",
    "        # 체인 구성\n",
    "        if self.llm:\n",
    "            self.question_analysis_chain = (\n",
    "                self.question_analysis_prompt | \n",
    "                self.llm | \n",
    "                JsonOutputParser()\n",
    "            )\n",
    "            \n",
    "            self.integration_chain = (\n",
    "                self.integration_prompt |\n",
    "                self.llm |\n",
    "                StrOutputParser()\n",
    "            )\n",
    "    \n",
    "    def analyze_question(self, question: str) -> Tuple[List[str], str]:\n",
    "        \"\"\"질문 분석 및 도메인 선택\"\"\"\n",
    "        if not self.llm:\n",
    "            return [\"hr_policy\"], \"LLM 없음 - 기본 도메인 사용\"\n",
    "        \n",
    "        try:\n",
    "            result = self.question_analysis_chain.invoke({\"question\": question})\n",
    "            selected_domains = result.get(\"selected_domains\", [\"hr_policy\"])\n",
    "            reasoning = result.get(\"reasoning\", \"분석 완료\")\n",
    "            \n",
    "            # 사용 가능한 도메인만 필터링\n",
    "            available_domains = []\n",
    "            for domain in selected_domains:\n",
    "                if domain in self.agents:\n",
    "                    available_domains.append(domain)\n",
    "            \n",
    "            return available_domains or [\"hr_policy\"], reasoning\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"질문 분석 실패: {e}\")\n",
    "            return [\"hr_policy\"], f\"분석 실패: {e}\"\n",
    "    \n",
    "    def execute_agent(self, domain: str, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"개별 에이전트 실행\"\"\"\n",
    "        if domain not in self.agents:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"answer\": f\"{domain} 에이전트를 사용할 수 없습니다.\",\n",
    "                \"source_count\": 0,\n",
    "                \"confidence\": 0.0\n",
    "            }\n",
    "        \n",
    "        agent = self.agents[domain]\n",
    "        \n",
    "        try:\n",
    "            if agent[\"type\"] == \"web_search\":\n",
    "                # 웹 검색 실행\n",
    "                search_results = agent[\"tool\"].invoke({\"query\": question})\n",
    "                \n",
    "                # 검색 결과 포맷팅 및 답변 생성\n",
    "                if search_results:\n",
    "                    formatted_results = \"\\n\".join([\n",
    "                        f\"- {result.get('title', '')}: {result.get('content', '')[:100]}...\"\n",
    "                        for result in search_results[:3]\n",
    "                    ])\n",
    "                    \n",
    "                    web_prompt = f\"다음 웹 검색 결과를 바탕으로 '{question}'에 대한 답변을 한국어로 생성해주세요:\\n\\n{formatted_results}\"\n",
    "                    answer = agent[\"llm\"].invoke(web_prompt).content\n",
    "                    \n",
    "                    return {\n",
    "                        \"success\": True,\n",
    "                        \"answer\": answer,\n",
    "                        \"source_count\": len(search_results),\n",
    "                        \"confidence\": 0.8\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        \"success\": False,\n",
    "                        \"answer\": \"웹 검색 결과를 가져올 수 없습니다.\",\n",
    "                        \"source_count\": 0,\n",
    "                        \"confidence\": 0.1\n",
    "                    }\n",
    "            \n",
    "            else:  # RAG 에이전트\n",
    "                vectorstore = agent[\"vectorstore\"]\n",
    "                config = agent[\"config\"]\n",
    "                \n",
    "                # 문서 검색\n",
    "                docs = vectorstore.similarity_search(question, k=3)\n",
    "                \n",
    "                if docs:\n",
    "                    # 컨텍스트 구성\n",
    "                    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "                    \n",
    "                    # 답변 생성\n",
    "                    agent_name = config.get(\"agent_name\", f\"{domain} 전문가\")\n",
    "                    description = config.get(\"description\", \"전문가\")\n",
    "                    \n",
    "                    rag_prompt = f\"\"\"\n",
    "                    당신은 꿀스테이의 {agent_name}입니다.\n",
    "                    전문 분야: {description}\n",
    "                    \n",
    "                    다음 문서 정보를 바탕으로 질문에 답변해주세요.\n",
    "                    \n",
    "                    **질문:** {question}\n",
    "                    \n",
    "                    **관련 문서:**\n",
    "                    {context}\n",
    "                    \n",
    "                    **답변:**\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    answer = agent[\"llm\"].invoke(rag_prompt).content\n",
    "                    \n",
    "                    return {\n",
    "                        \"success\": True,\n",
    "                        \"answer\": answer,\n",
    "                        \"source_count\": len(docs),\n",
    "                        \"confidence\": 0.9\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        \"success\": False,\n",
    "                        \"answer\": f\"{domain} 도메인에서 관련 정보를 찾을 수 없습니다.\",\n",
    "                        \"source_count\": 0,\n",
    "                        \"confidence\": 0.2\n",
    "                    }\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"에이전트 실행 실패 ({domain}): {e}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"answer\": f\"{domain} 에이전트 실행 중 오류 발생: {e}\",\n",
    "                \"source_count\": 0,\n",
    "                \"confidence\": 0.0\n",
    "            }\n",
    "    \n",
    "    def integrate_responses(self, question: str, domain_responses: Dict[str, Dict]) -> str:\n",
    "        \"\"\"다중 에이전트 응답 통합\"\"\"\n",
    "        if not self.llm:\n",
    "            # LLM이 없는 경우 첫 번째 성공한 응답 반환\n",
    "            for domain, response in domain_responses.items():\n",
    "                if response[\"success\"]:\n",
    "                    return response[\"answer\"]\n",
    "            return \"답변을 생성할 수 없습니다.\"\n",
    "        \n",
    "        if len(domain_responses) == 1:\n",
    "            # 단일 응답인 경우 통합 없이 직접 반환\n",
    "            return list(domain_responses.values())[0][\"answer\"]\n",
    "        \n",
    "        try:\n",
    "            # 성공한 응답들만 수집\n",
    "            successful_responses = {\n",
    "                domain: response for domain, response in domain_responses.items()\n",
    "                if response[\"success\"]\n",
    "            }\n",
    "            \n",
    "            if not successful_responses:\n",
    "                return \"죄송합니다. 답변을 생성할 수 없습니다.\"\n",
    "            \n",
    "            # 전문가 답변 포맷팅\n",
    "            expert_answers = []\n",
    "            for domain, response in successful_responses.items():\n",
    "                agent_name = DOMAIN_CONFIG.get(domain, {}).get(\"agent_name\", f\"{domain} 전문가\")\n",
    "                expert_answers.append(f\"**{agent_name}:** {response['answer']}\")\n",
    "            \n",
    "            expert_answers_text = \"\\n\\n\".join(expert_answers)\n",
    "            \n",
    "            # 통합 답변 생성\n",
    "            integrated_answer = self.integration_chain.invoke({\n",
    "                \"question\": question,\n",
    "                \"expert_answers\": expert_answers_text\n",
    "            })\n",
    "            \n",
    "            return integrated_answer\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"응답 통합 실패: {e}\")\n",
    "            # 실패 시 첫 번째 성공한 응답 반환\n",
    "            for response in domain_responses.values():\n",
    "                if response[\"success\"]:\n",
    "                    return response[\"answer\"]\n",
    "            return f\"응답 통합 중 오류 발생: {e}\"\n",
    "    \n",
    "    def process_question(self, question: str) -> PipelineTestResult:\n",
    "        \"\"\"전체 파이프라인 실행\"\"\"\n",
    "        test_id = str(uuid.uuid4())[:8]\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # 1. 질문 분석\n",
    "            analysis_start = time.time()\n",
    "            selected_domains, reasoning = self.analyze_question(question)\n",
    "            analysis_time = time.time() - analysis_start\n",
    "            \n",
    "            # 2. 에이전트 실행\n",
    "            execution_start = time.time()\n",
    "            domain_responses = {}\n",
    "            \n",
    "            for domain in selected_domains:\n",
    "                response = self.execute_agent(domain, question)\n",
    "                domain_responses[domain] = response\n",
    "            \n",
    "            execution_time = time.time() - execution_start\n",
    "            \n",
    "            # 3. 응답 통합\n",
    "            integration_start = time.time()\n",
    "            final_answer = self.integrate_responses(question, domain_responses)\n",
    "            integration_time = time.time() - integration_start\n",
    "            \n",
    "            # 통계 계산\n",
    "            total_time = time.time() - start_time\n",
    "            successful_responses = [r for r in domain_responses.values() if r[\"success\"]]\n",
    "            avg_confidence = sum(r[\"confidence\"] for r in successful_responses) / len(successful_responses) if successful_responses else 0.0\n",
    "            total_sources = sum(r[\"source_count\"] for r in domain_responses.values())\n",
    "            \n",
    "            return PipelineTestResult(\n",
    "                test_id=test_id,\n",
    "                question=question,\n",
    "                answer=final_answer,\n",
    "                selected_domains=selected_domains,\n",
    "                processing_time=total_time,\n",
    "                success=True,\n",
    "                question_analysis_time=analysis_time,\n",
    "                agent_execution_time=execution_time,\n",
    "                response_integration_time=integration_time,\n",
    "                confidence_score=avg_confidence,\n",
    "                source_count=total_sources\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"파이프라인 실행 실패: {e}\")\n",
    "            return PipelineTestResult(\n",
    "                test_id=test_id,\n",
    "                question=question,\n",
    "                answer=f\"처리 중 오류 발생: {e}\",\n",
    "                selected_domains=[],\n",
    "                processing_time=time.time() - start_time,\n",
    "                success=False,\n",
    "                error_message=str(e)\n",
    "            )\n",
    "\n",
    "# 통합 파이프라인 초기화\n",
    "if system_components[\"init_status\"].overall_status() > 50:\n",
    "    integrated_pipeline = IntegratedRAGPipeline(system_components)\n",
    "    print(\"✅ 통합 RAG 파이프라인 초기화 완료\")\n",
    "else:\n",
    "    integrated_pipeline = None\n",
    "    print(f\"❌ 시스템 초기화 상태가 불충분합니다 ({system_components['init_status'].overall_status():.1f}%)\")\n",
    "    print(\"   통합 파이프라인을 실행하려면 더 많은 컴포넌트가 필요합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 종합 성능 테스트 시나리오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종합 테스트 시나리오\n",
    "comprehensive_test_scenarios = [\n",
    "    {\n",
    "        \"category\": \"단일 도메인\",\n",
    "        \"questions\": [\n",
    "            \"연차 휴가는 어떻게 신청하나요?\",\n",
    "            \"코딩 스타일 가이드라인을 알려주세요\",\n",
    "            \"시스템 아키텍처의 주요 구성요소는 무엇인가요?\",\n",
    "            \"배포 프로세스는 어떻게 진행하나요?\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"다중 도메인\",\n",
    "        \"questions\": [\n",
    "            \"개발자 채용부터 온보딩까지의 전체 프로세스를 설명해주세요\",\n",
    "            \"새로운 기능 개발 시 아키텍처 설계부터 배포까지 어떤 절차를 거치나요?\",\n",
    "            \"회사의 기술 스택과 개발 문화에 대해 알려주세요\",\n",
    "            \"UI 컴포넌트 개발 및 배포 가이드라인은 무엇인가요?\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"일반적 질문\",\n",
    "        \"questions\": [\n",
    "            \"회사의 핵심 가치와 문화는 무엇인가요?\",\n",
    "            \"새로 입사한 개발자가 알아야 할 것들은 무엇인가요?\",\n",
    "            \"프로젝트 관리는 어떻게 이루어지나요?\",\n",
    "            \"회사의 성장 전략과 비전을 설명해주세요\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"최신 정보\",\n",
    "        \"questions\": [\n",
    "            \"2024년 최신 웹 개발 트렌드는 무엇인가요?\",\n",
    "            \"AI 기술의 최근 동향을 알려주세요\",\n",
    "            \"클라우드 컴퓨팅의 최신 발전사항은 무엇인가요?\",\n",
    "            \"현재 인기있는 프로그래밍 언어는 무엇인가요?\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "def run_comprehensive_test(pipeline: IntegratedRAGPipeline, \n",
    "                         scenarios: List[Dict],\n",
    "                         max_questions_per_category: int = 2) -> List[PipelineTestResult]:\n",
    "    \"\"\"종합 성능 테스트 실행\"\"\"\n",
    "    \n",
    "    print(\"🚀 종합 성능 테스트 시작\")\n",
    "    print(f\"   - 테스트 카테고리: {len(scenarios)}개\")\n",
    "    print(f\"   - 카테고리당 최대 질문: {max_questions_per_category}개\\n\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        category = scenario[\"category\"]\n",
    "        questions = scenario[\"questions\"][:max_questions_per_category]\n",
    "        \n",
    "        print(f\"📋 카테고리: {category}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        category_results = []\n",
    "        \n",
    "        for i, question in enumerate(questions, 1):\n",
    "            print(f\"\\n{i}️⃣ 질문: {question}\")\n",
    "            \n",
    "            try:\n",
    "                # 파이프라인 실행\n",
    "                result = pipeline.process_question(question)\n",
    "                \n",
    "                # 결과 출력\n",
    "                print(f\"   ✅ 성공: {result.success}\")\n",
    "                print(f\"   🎯 선택 도메인: {', '.join(result.selected_domains)}\")\n",
    "                print(f\"   ⏱️  처리 시간: {result.processing_time:.2f}초\")\n",
    "                print(f\"   📊 신뢰도: {result.confidence_score:.2f}\")\n",
    "                print(f\"   📚 출처 수: {result.source_count}개\")\n",
    "                \n",
    "                # 답변 미리보기\n",
    "                answer_preview = result.answer[:100] + \"...\" if len(result.answer) > 100 else result.answer\n",
    "                print(f\"   💬 답변: {answer_preview}\")\n",
    "                \n",
    "                category_results.append(result)\n",
    "                all_results.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ 실패: {e}\")\n",
    "                logger.error(f\"테스트 실패 ({category} - {question}): {e}\")\n",
    "        \n",
    "        # 카테고리 요약\n",
    "        if category_results:\n",
    "            success_count = sum(1 for r in category_results if r.success)\n",
    "            avg_time = sum(r.processing_time for r in category_results) / len(category_results)\n",
    "            avg_confidence = sum(r.confidence_score for r in category_results) / len(category_results)\n",
    "            \n",
    "            print(f\"\\n📊 {category} 요약:\")\n",
    "            print(f\"   - 성공률: {success_count}/{len(category_results)} ({success_count/len(category_results)*100:.1f}%)\")\n",
    "            print(f\"   - 평균 처리 시간: {avg_time:.2f}초\")\n",
    "            print(f\"   - 평균 신뢰도: {avg_confidence:.2f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# 종합 테스트 실행\n",
    "if integrated_pipeline:\n",
    "    print(f\"📊 시스템 준비 상태: {system_components['init_status'].overall_status():.1f}%\\n\")\n",
    "    \n",
    "    comprehensive_results = run_comprehensive_test(\n",
    "        pipeline=integrated_pipeline,\n",
    "        scenarios=comprehensive_test_scenarios,\n",
    "        max_questions_per_category=2  # 성능을 위해 각 카테고리당 2개 질문만 테스트\n",
    "    )\n",
    "    \n",
    "    print(f\"🎉 종합 성능 테스트 완료: {len(comprehensive_results)}개 테스트\")\n",
    "    \n",
    "else:\n",
    "    comprehensive_results = []\n",
    "    print(\"❌ 통합 파이프라인이 준비되지 않아 종합 테스트를 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 성능 분석 및 벤치마크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceAnalyzer:\n",
    "    \"\"\"성능 분석 및 벤치마크\"\"\"\n",
    "    \n",
    "    def __init__(self, test_results: List[PipelineTestResult]):\n",
    "        self.test_results = test_results\n",
    "        self.df = self._create_dataframe()\n",
    "    \n",
    "    def _create_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"테스트 결과를 DataFrame으로 변환\"\"\"\n",
    "        if not self.test_results:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        data = []\n",
    "        for result in self.test_results:\n",
    "            row = {\n",
    "                'test_id': result.test_id,\n",
    "                'question': result.question[:50] + '...' if len(result.question) > 50 else result.question,\n",
    "                'success': result.success,\n",
    "                'domains_count': len(result.selected_domains),\n",
    "                'selected_domains': ', '.join(result.selected_domains),\n",
    "                'processing_time': result.processing_time,\n",
    "                'analysis_time': result.question_analysis_time,\n",
    "                'execution_time': result.agent_execution_time,\n",
    "                'integration_time': result.response_integration_time,\n",
    "                'confidence_score': result.confidence_score,\n",
    "                'source_count': result.source_count,\n",
    "                'answer_length': len(result.answer),\n",
    "                'timestamp': result.timestamp\n",
    "            }\n",
    "            data.append(row)\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def generate_performance_report(self) -> str:\n",
    "        \"\"\"성능 보고서 생성\"\"\"\n",
    "        if self.df.empty:\n",
    "            return \"분석할 데이터가 없습니다.\"\n",
    "        \n",
    "        successful_tests = self.df[self.df['success'] == True]\n",
    "        \n",
    "        report = []\n",
    "        report.append(\"🚀 꿀스테이 RAG 시스템 성능 분석 보고서\")\n",
    "        report.append(\"=\" * 60)\n",
    "        \n",
    "        # 기본 통계\n",
    "        report.append(f\"\\n📊 기본 통계:\")\n",
    "        report.append(f\"   - 총 테스트 수: {len(self.df)}개\")\n",
    "        report.append(f\"   - 성공한 테스트: {len(successful_tests)}개\")\n",
    "        report.append(f\"   - 성공률: {len(successful_tests)/len(self.df)*100:.1f}%\")\n",
    "        \n",
    "        if len(successful_tests) > 0:\n",
    "            # 성능 지표\n",
    "            report.append(f\"\\n⚡ 성능 지표 (성공한 테스트만):\")\n",
    "            report.append(f\"   - 평균 처리 시간: {successful_tests['processing_time'].mean():.2f}초\")\n",
    "            report.append(f\"   - 최대 처리 시간: {successful_tests['processing_time'].max():.2f}초\")\n",
    "            report.append(f\"   - 최소 처리 시간: {successful_tests['processing_time'].min():.2f}초\")\n",
    "            report.append(f\"   - 처리 시간 표준편차: {successful_tests['processing_time'].std():.2f}초\")\n",
    "            \n",
    "            # 처리 단계별 시간 분석\n",
    "            report.append(f\"\\n🔍 처리 단계별 평균 시간:\")\n",
    "            if 'analysis_time' in successful_tests.columns:\n",
    "                report.append(f\"   - 질문 분석: {successful_tests['analysis_time'].mean():.3f}초\")\n",
    "            if 'execution_time' in successful_tests.columns:\n",
    "                report.append(f\"   - 에이전트 실행: {successful_tests['execution_time'].mean():.3f}초\")\n",
    "            if 'integration_time' in successful_tests.columns:\n",
    "                report.append(f\"   - 응답 통합: {successful_tests['integration_time'].mean():.3f}초\")\n",
    "            \n",
    "            # 품질 지표\n",
    "            report.append(f\"\\n🎯 품질 지표:\")\n",
    "            report.append(f\"   - 평균 신뢰도: {successful_tests['confidence_score'].mean():.2f}\")\n",
    "            report.append(f\"   - 평균 출처 수: {successful_tests['source_count'].mean():.1f}개\")\n",
    "            report.append(f\"   - 평균 답변 길이: {successful_tests['answer_length'].mean():.0f}자\")\n",
    "            \n",
    "            # 도메인 사용 분석\n",
    "            report.append(f\"\\n🏷️  도메인 사용 분석:\")\n",
    "            domain_usage = successful_tests['domains_count'].value_counts().sort_index()\n",
    "            for domain_count, usage_count in domain_usage.items():\n",
    "                percentage = (usage_count / len(successful_tests)) * 100\n",
    "                report.append(f\"   - {domain_count}개 도메인 사용: {usage_count}회 ({percentage:.1f}%)\")\n",
    "            \n",
    "            # 자주 사용된 도메인\n",
    "            all_domains = []\n",
    "            for domains_str in successful_tests['selected_domains']:\n",
    "                all_domains.extend(domains_str.split(', '))\n",
    "            \n",
    "            domain_frequency = pd.Series(all_domains).value_counts()\n",
    "            report.append(f\"\\n📈 도메인 사용 빈도:\")\n",
    "            for domain, count in domain_frequency.head(5).items():\n",
    "                percentage = (count / len(successful_tests)) * 100\n",
    "                report.append(f\"   - {domain}: {count}회 ({percentage:.1f}%)\")\n",
    "        \n",
    "        # 실패 분석\n",
    "        failed_tests = self.df[self.df['success'] == False]\n",
    "        if len(failed_tests) > 0:\n",
    "            report.append(f\"\\n❌ 실패 분석:\")\n",
    "            report.append(f\"   - 실패한 테스트: {len(failed_tests)}개\")\n",
    "            report.append(f\"   - 실패율: {len(failed_tests)/len(self.df)*100:.1f}%\")\n",
    "        \n",
    "        return \"\\n\".join(report)\n",
    "    \n",
    "    def plot_performance_metrics(self, figsize=(15, 10)):\n",
    "        \"\"\"성능 지표 시각화\"\"\"\n",
    "        if self.df.empty:\n",
    "            print(\"시각화할 데이터가 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        successful_tests = self.df[self.df['success'] == True]\n",
    "        \n",
    "        if len(successful_tests) == 0:\n",
    "            print(\"성공한 테스트가 없어 시각화할 수 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=figsize)\n",
    "        fig.suptitle('꿀스테이 RAG 시스템 성능 분석', fontsize=16)\n",
    "        \n",
    "        # 1. 처리 시간 분포\n",
    "        axes[0, 0].hist(successful_tests['processing_time'], bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[0, 0].set_title('Processing Time Distribution')\n",
    "        axes[0, 0].set_xlabel('Processing Time (seconds)')\n",
    "        axes[0, 0].set_ylabel('Frequency')\n",
    "        \n",
    "        # 2. 신뢰도 분포\n",
    "        axes[0, 1].hist(successful_tests['confidence_score'], bins=10, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "        axes[0, 1].set_title('Confidence Score Distribution')\n",
    "        axes[0, 1].set_xlabel('Confidence Score')\n",
    "        axes[0, 1].set_ylabel('Frequency')\n",
    "        \n",
    "        # 3. 도메인 사용 수 분포\n",
    "        domain_counts = successful_tests['domains_count'].value_counts().sort_index()\n",
    "        axes[0, 2].bar(domain_counts.index, domain_counts.values, color='orange', alpha=0.7)\n",
    "        axes[0, 2].set_title('Number of Domains Used')\n",
    "        axes[0, 2].set_xlabel('Number of Domains')\n",
    "        axes[0, 2].set_ylabel('Frequency')\n",
    "        \n",
    "        # 4. 처리 시간 vs 신뢰도\n",
    "        axes[1, 0].scatter(successful_tests['processing_time'], successful_tests['confidence_score'], \n",
    "                          alpha=0.6, color='purple')\n",
    "        axes[1, 0].set_title('Processing Time vs Confidence')\n",
    "        axes[1, 0].set_xlabel('Processing Time (seconds)')\n",
    "        axes[1, 0].set_ylabel('Confidence Score')\n",
    "        \n",
    "        # 5. 출처 수 분포\n",
    "        axes[1, 1].hist(successful_tests['source_count'], bins=10, alpha=0.7, color='pink', edgecolor='black')\n",
    "        axes[1, 1].set_title('Source Count Distribution')\n",
    "        axes[1, 1].set_xlabel('Number of Sources')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        \n",
    "        # 6. 성공/실패 파이 차트\n",
    "        success_counts = self.df['success'].value_counts()\n",
    "        axes[1, 2].pie(success_counts.values, labels=['Success', 'Failure'], autopct='%1.1f%%',\n",
    "                      colors=['lightgreen', 'lightcoral'])\n",
    "        axes[1, 2].set_title('Success Rate')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def create_benchmark_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"벤치마크 요약 생성\"\"\"\n",
    "        if self.df.empty:\n",
    "            return {\"error\": \"데이터 없음\"}\n",
    "        \n",
    "        successful_tests = self.df[self.df['success'] == True]\n",
    "        \n",
    "        return {\n",
    "            \"system_info\": {\n",
    "                \"total_tests\": len(self.df),\n",
    "                \"successful_tests\": len(successful_tests),\n",
    "                \"success_rate\": len(successful_tests) / len(self.df) * 100 if len(self.df) > 0 else 0,\n",
    "                \"test_date\": datetime.now().isoformat()\n",
    "            },\n",
    "            \"performance_metrics\": {\n",
    "                \"avg_processing_time\": successful_tests['processing_time'].mean() if len(successful_tests) > 0 else 0,\n",
    "                \"max_processing_time\": successful_tests['processing_time'].max() if len(successful_tests) > 0 else 0,\n",
    "                \"min_processing_time\": successful_tests['processing_time'].min() if len(successful_tests) > 0 else 0,\n",
    "                \"std_processing_time\": successful_tests['processing_time'].std() if len(successful_tests) > 0 else 0\n",
    "            },\n",
    "            \"quality_metrics\": {\n",
    "                \"avg_confidence_score\": successful_tests['confidence_score'].mean() if len(successful_tests) > 0 else 0,\n",
    "                \"avg_source_count\": successful_tests['source_count'].mean() if len(successful_tests) > 0 else 0,\n",
    "                \"avg_answer_length\": successful_tests['answer_length'].mean() if len(successful_tests) > 0 else 0\n",
    "            },\n",
    "            \"component_status\": {\n",
    "                \"llm_available\": system_components[\"init_status\"].llm,\n",
    "                \"embeddings_available\": system_components[\"init_status\"].embeddings,\n",
    "                \"web_search_available\": system_components[\"init_status\"].web_search,\n",
    "                \"vectorstores_count\": sum(system_components[\"init_status\"].vectorstores.values()),\n",
    "                \"agents_count\": sum(system_components[\"init_status\"].agents.values())\n",
    "            }\n",
    "        }\n",
    "\n",
    "# 성능 분석 실행\n",
    "if comprehensive_results:\n",
    "    print(\"📊 성능 분석 및 벤치마크 생성 중...\\n\")\n",
    "    \n",
    "    analyzer = PerformanceAnalyzer(comprehensive_results)\n",
    "    \n",
    "    # 성능 보고서 출력\n",
    "    performance_report = analyzer.generate_performance_report()\n",
    "    print(performance_report)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"📈 성능 지표 시각화:\")\n",
    "    \n",
    "    # 성능 차트 생성\n",
    "    analyzer.plot_performance_metrics(figsize=(16, 10))\n",
    "    \n",
    "    # 벤치마크 요약\n",
    "    benchmark_summary = analyzer.create_benchmark_summary()\n",
    "    \n",
    "    print(\"\\n📋 벤치마크 요약 (JSON):\")\n",
    "    print(json.dumps(benchmark_summary, indent=2, ensure_ascii=False))\n",
    "    \n",
    "else:\n",
    "    print(\"❌ 분석할 테스트 결과가 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 상세 테스트 결과 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상세 테스트 결과 표시\n",
    "if comprehensive_results:\n",
    "    print(\"📋 상세 테스트 결과\\n\")\n",
    "    \n",
    "    # DataFrame으로 변환하여 표시\n",
    "    results_df = analyzer.df\n",
    "    \n",
    "    # 주요 컬럼만 선택해서 표시\n",
    "    display_columns = [\n",
    "        'test_id', 'question', 'success', 'selected_domains',\n",
    "        'processing_time', 'confidence_score', 'source_count'\n",
    "    ]\n",
    "    \n",
    "    display_df = results_df[display_columns].copy()\n",
    "    \n",
    "    # 시간 형식 정리\n",
    "    display_df['processing_time'] = display_df['processing_time'].round(2)\n",
    "    display_df['confidence_score'] = display_df['confidence_score'].round(2)\n",
    "    \n",
    "    print(\"상위 결과:\")\n",
    "    display(display_df.head(10))\n",
    "    \n",
    "    # 성공한 테스트의 답변 미리보기\n",
    "    print(\"\\n💬 성공한 테스트의 답변 미리보기:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    successful_results = [r for r in comprehensive_results if r.success]\n",
    "    \n",
    "    for i, result in enumerate(successful_results[:3], 1):  # 처음 3개만 표시\n",
    "        print(f\"\\n{i}. 질문: {result.question}\")\n",
    "        print(f\"   도메인: {', '.join(result.selected_domains)}\")\n",
    "        print(f\"   처리시간: {result.processing_time:.2f}초\")\n",
    "        print(f\"   답변 미리보기:\")\n",
    "        \n",
    "        # 답변을 200자로 제한하여 표시\n",
    "        answer_preview = result.answer[:200] + \"...\" if len(result.answer) > 200 else result.answer\n",
    "        print(f\"   {answer_preview}\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # 실패한 테스트 분석\n",
    "    failed_results = [r for r in comprehensive_results if not r.success]\n",
    "    if failed_results:\n",
    "        print(f\"\\n❌ 실패한 테스트 분석 ({len(failed_results)}개):\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for i, result in enumerate(failed_results[:3], 1):  # 처음 3개만 표시\n",
    "            print(f\"\\n{i}. 질문: {result.question}\")\n",
    "            print(f\"   오류: {result.error_message or '알 수 없는 오류'}\")\n",
    "            print(f\"   처리시간: {result.processing_time:.2f}초\")\n",
    "            print(\"-\" * 60)\n",
    "    \n",
    "else:\n",
    "    print(\"❌ 표시할 테스트 결과가 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 시스템 상태 및 배포 준비도 점검"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeploymentReadinessChecker:\n",
    "    \"\"\"배포 준비도 점검기\"\"\"\n",
    "    \n",
    "    def __init__(self, init_status: SystemInitStatus, test_results: List[PipelineTestResult]):\n",
    "        self.init_status = init_status\n",
    "        self.test_results = test_results\n",
    "    \n",
    "    def check_component_readiness(self) -> Dict[str, Dict[str, Any]]:\n",
    "        \"\"\"컴포넌트별 준비 상태 점검\"\"\"\n",
    "        \n",
    "        checks = {\n",
    "            \"core_components\": {\n",
    "                \"llm_available\": {\n",
    "                    \"status\": self.init_status.llm,\n",
    "                    \"importance\": \"Critical\",\n",
    "                    \"description\": \"OpenAI GPT-4o-mini 언어 모델\"\n",
    "                },\n",
    "                \"embeddings_available\": {\n",
    "                    \"status\": self.init_status.embeddings,\n",
    "                    \"importance\": \"Critical\",\n",
    "                    \"description\": \"Ollama bge-m3 임베딩 모델\"\n",
    "                },\n",
    "                \"web_search_available\": {\n",
    "                    \"status\": self.init_status.web_search,\n",
    "                    \"importance\": \"Optional\",\n",
    "                    \"description\": \"Tavily API 웹 검색 도구\"\n",
    "                }\n",
    "            },\n",
    "            \"data_components\": {},\n",
    "            \"agent_components\": {}\n",
    "        }\n",
    "        \n",
    "        # 벡터 저장소 점검\n",
    "        for domain, status in self.init_status.vectorstores.items():\n",
    "            checks[\"data_components\"][f\"{domain}_vectorstore\"] = {\n",
    "                \"status\": status,\n",
    "                \"importance\": \"High\" if domain in [\"hr_policy\", \"tech_policy\"] else \"Medium\",\n",
    "                \"description\": f\"{domain} 도메인 벡터 저장소\"\n",
    "            }\n",
    "        \n",
    "        # 에이전트 점검\n",
    "        for domain, status in self.init_status.agents.items():\n",
    "            checks[\"agent_components\"][f\"{domain}_agent\"] = {\n",
    "                \"status\": status,\n",
    "                \"importance\": \"High\" if domain in [\"hr_policy\", \"tech_policy\"] else \"Medium\",\n",
    "                \"description\": f\"{domain} 도메인 RAG 에이전트\"\n",
    "            }\n",
    "        \n",
    "        return checks\n",
    "    \n",
    "    def check_performance_readiness(self) -> Dict[str, Any]:\n",
    "        \"\"\"성능 준비 상태 점검\"\"\"\n",
    "        if not self.test_results:\n",
    "            return {\n",
    "                \"test_coverage\": False,\n",
    "                \"success_rate\": 0.0,\n",
    "                \"avg_processing_time\": 0.0,\n",
    "                \"performance_acceptable\": False\n",
    "            }\n",
    "        \n",
    "        successful_tests = [r for r in self.test_results if r.success]\n",
    "        success_rate = len(successful_tests) / len(self.test_results) * 100\n",
    "        \n",
    "        avg_processing_time = 0.0\n",
    "        if successful_tests:\n",
    "            avg_processing_time = sum(r.processing_time for r in successful_tests) / len(successful_tests)\n",
    "        \n",
    "        return {\n",
    "            \"test_coverage\": len(self.test_results) >= 5,  # 최소 5개 테스트\n",
    "            \"success_rate\": success_rate,\n",
    "            \"avg_processing_time\": avg_processing_time,\n",
    "            \"performance_acceptable\": success_rate >= 80 and avg_processing_time <= 10.0  # 80% 성공률, 10초 이내\n",
    "        }\n",
    "    \n",
    "    def generate_readiness_report(self) -> str:\n",
    "        \"\"\"배포 준비도 보고서 생성\"\"\"\n",
    "        component_checks = self.check_component_readiness()\n",
    "        performance_checks = self.check_performance_readiness()\n",
    "        \n",
    "        report = []\n",
    "        report.append(\"🚀 꿀스테이 RAG 시스템 배포 준비도 점검\")\n",
    "        report.append(\"=\" * 60)\n",
    "        \n",
    "        # 전체 점수 계산\n",
    "        total_components = 0\n",
    "        ready_components = 0\n",
    "        critical_ready = 0\n",
    "        critical_total = 0\n",
    "        \n",
    "        # 컴포넌트별 점검 결과\n",
    "        for category, components in component_checks.items():\n",
    "            report.append(f\"\\n📊 {category.replace('_', ' ').title()}:\")\n",
    "            \n",
    "            for comp_name, comp_info in components.items():\n",
    "                status_icon = \"✅\" if comp_info[\"status\"] else \"❌\"\n",
    "                importance = comp_info[\"importance\"]\n",
    "                description = comp_info[\"description\"]\n",
    "                \n",
    "                report.append(f\"   {status_icon} {comp_name}: {description} ({importance})\")\n",
    "                \n",
    "                total_components += 1\n",
    "                if comp_info[\"status\"]:\n",
    "                    ready_components += 1\n",
    "                \n",
    "                if importance == \"Critical\":\n",
    "                    critical_total += 1\n",
    "                    if comp_info[\"status\"]:\n",
    "                        critical_ready += 1\n",
    "        \n",
    "        # 성능 점검 결과\n",
    "        report.append(f\"\\n🎯 성능 점검:\")\n",
    "        report.append(f\"   {'✅' if performance_checks['test_coverage'] else '❌'} 테스트 커버리지: {len(self.test_results)}개 테스트\")\n",
    "        report.append(f\"   {'✅' if performance_checks['success_rate'] >= 80 else '❌'} 성공률: {performance_checks['success_rate']:.1f}% (목표: ≥80%)\")\n",
    "        report.append(f\"   {'✅' if performance_checks['avg_processing_time'] <= 10.0 else '❌'} 평균 처리시간: {performance_checks['avg_processing_time']:.2f}초 (목표: ≤10초)\")\n",
    "        \n",
    "        # 전체 준비도 계산\n",
    "        component_readiness = (ready_components / total_components * 100) if total_components > 0 else 0\n",
    "        critical_readiness = (critical_ready / critical_total * 100) if critical_total > 0 else 0\n",
    "        \n",
    "        report.append(f\"\\n📈 전체 준비도:\")\n",
    "        report.append(f\"   - 전체 컴포넌트: {ready_components}/{total_components} ({component_readiness:.1f}%)\")\n",
    "        report.append(f\"   - 핵심 컴포넌트: {critical_ready}/{critical_total} ({critical_readiness:.1f}%)\")\n",
    "        report.append(f\"   - 성능 준비도: {'✅' if performance_checks['performance_acceptable'] else '❌'}\")\n",
    "        \n",
    "        # 배포 권장사항\n",
    "        report.append(f\"\\n🎯 배포 권장사항:\")\n",
    "        \n",
    "        if critical_readiness == 100 and performance_checks['performance_acceptable']:\n",
    "            report.append(\"   🟢 배포 준비 완료! 프로덕션 환경에 배포할 수 있습니다.\")\n",
    "        elif critical_readiness == 100:\n",
    "            report.append(\"   🟡 핵심 기능은 준비되었으나 성능 최적화가 필요합니다.\")\n",
    "            report.append(\"   📝 권장: 성능 튜닝 후 배포\")\n",
    "        elif critical_readiness >= 50:\n",
    "            report.append(\"   🟠 일부 핵심 컴포넌트가 준비되지 않았습니다.\")\n",
    "            report.append(\"   📝 권장: 스테이징 환경에서 추가 테스트\")\n",
    "        else:\n",
    "            report.append(\"   🔴 배포 준비가 부족합니다.\")\n",
    "            report.append(\"   📝 권장: 핵심 컴포넌트 수정 후 재테스트\")\n",
    "        \n",
    "        # 개선 항목\n",
    "        improvements = []\n",
    "        \n",
    "        for category, components in component_checks.items():\n",
    "            for comp_name, comp_info in components.items():\n",
    "                if not comp_info[\"status\"] and comp_info[\"importance\"] in [\"Critical\", \"High\"]:\n",
    "                    improvements.append(f\"   - {comp_info['description']} 활성화 필요\")\n",
    "        \n",
    "        if not performance_checks['performance_acceptable']:\n",
    "            if performance_checks['success_rate'] < 80:\n",
    "                improvements.append(\"   - 성공률 향상 필요 (현재: {:.1f}%, 목표: ≥80%)\".format(performance_checks['success_rate']))\n",
    "            if performance_checks['avg_processing_time'] > 10.0:\n",
    "                improvements.append(\"   - 처리 시간 단축 필요 (현재: {:.2f}초, 목표: ≤10초)\".format(performance_checks['avg_processing_time']))\n",
    "        \n",
    "        if improvements:\n",
    "            report.append(f\"\\n🔧 개선 필요 항목:\")\n",
    "            report.extend(improvements)\n",
    "        \n",
    "        return \"\\n\".join(report)\n",
    "    \n",
    "    def get_deployment_score(self) -> float:\n",
    "        \"\"\"배포 준비도 점수 (0-100)\"\"\"\n",
    "        component_checks = self.check_component_readiness()\n",
    "        performance_checks = self.check_performance_readiness()\n",
    "        \n",
    "        # 컴포넌트 점수 계산 (가중치 적용)\n",
    "        component_score = 0.0\n",
    "        total_weight = 0.0\n",
    "        \n",
    "        for category, components in component_checks.items():\n",
    "            for comp_name, comp_info in components.items():\n",
    "                weight = 3.0 if comp_info[\"importance\"] == \"Critical\" else (\n",
    "                    2.0 if comp_info[\"importance\"] == \"High\" else 1.0\n",
    "                )\n",
    "                \n",
    "                if comp_info[\"status\"]:\n",
    "                    component_score += weight\n",
    "                total_weight += weight\n",
    "        \n",
    "        component_ratio = component_score / total_weight if total_weight > 0 else 0.0\n",
    "        \n",
    "        # 성능 점수 계산\n",
    "        performance_score = 0.0\n",
    "        if performance_checks['test_coverage']:\n",
    "            performance_score += 0.2\n",
    "        if performance_checks['success_rate'] >= 80:\n",
    "            performance_score += 0.4\n",
    "        if performance_checks['avg_processing_time'] <= 10.0:\n",
    "            performance_score += 0.4\n",
    "        \n",
    "        # 전체 점수 (컴포넌트 70%, 성능 30%)\n",
    "        total_score = (component_ratio * 0.7 + performance_score * 0.3) * 100\n",
    "        \n",
    "        return min(100.0, max(0.0, total_score))\n",
    "\n",
    "# 배포 준비도 점검\n",
    "if system_components[\"init_status\"] and comprehensive_results:\n",
    "    print(\"🔍 배포 준비도 점검 중...\\n\")\n",
    "    \n",
    "    readiness_checker = DeploymentReadinessChecker(\n",
    "        init_status=system_components[\"init_status\"],\n",
    "        test_results=comprehensive_results\n",
    "    )\n",
    "    \n",
    "    # 배포 준비도 보고서\n",
    "    readiness_report = readiness_checker.generate_readiness_report()\n",
    "    print(readiness_report)\n",
    "    \n",
    "    # 배포 점수\n",
    "    deployment_score = readiness_checker.get_deployment_score()\n",
    "    \n",
    "    print(f\"\\n⭐ 최종 배포 준비도 점수: {deployment_score:.1f}/100점\")\n",
    "    \n",
    "    # 점수별 권장사항\n",
    "    if deployment_score >= 90:\n",
    "        print(\"🟢 우수! 프로덕션 배포 준비 완료\")\n",
    "    elif deployment_score >= 70:\n",
    "        print(\"🟡 양호! 일부 개선 후 배포 가능\")\n",
    "    elif deployment_score >= 50:\n",
    "        print(\"🟠 보통! 주요 개선사항 해결 필요\")\n",
    "    else:\n",
    "        print(\"🔴 미흡! 전면적인 시스템 점검 필요\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ 배포 준비도를 점검할 데이터가 충분하지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 최종 요약 및 권장사항"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_summary() -> str:\n",
    "    \"\"\"최종 요약 보고서 생성\"\"\"\n",
    "    \n",
    "    current_time = datetime.now()\n",
    "    \n",
    "    summary = []\n",
    "    summary.append(\"🍯 꿀스테이 RAG 시스템 - 최종 통합 테스트 보고서\")\n",
    "    summary.append(\"=\" * 80)\n",
    "    summary.append(f\"📅 테스트 완료 시간: {current_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # 시스템 개요\n",
    "    summary.append(f\"\\n🏗️  시스템 개요:\")\n",
    "    summary.append(f\"   - 아키텍처: Multi-Agent RAG with Human-in-the-Loop\")\n",
    "    summary.append(f\"   - 도메인: 7개 전문 도메인 + 웹 검색\")\n",
    "    summary.append(f\"   - 핵심 기술: LangChain, LangGraph, ChromaDB, OpenAI GPT-4o-mini\")\n",
    "    summary.append(f\"   - 임베딩: Ollama bge-m3 (다국어 지원)\")\n",
    "    \n",
    "    # 구현 완료 현황\n",
    "    summary.append(f\"\\n✅ 구현 완료 현황:\")\n",
    "    summary.append(f\"   📝 01_data_processing: 문서 로딩 및 청킹 시스템\")\n",
    "    summary.append(f\"   📊 02_vector_stores: 도메인별 독립 벡터 저장소\")\n",
    "    summary.append(f\"   🤖 03_agents_development: Corrective RAG 에이전트 (8개)\")\n",
    "    summary.append(f\"   🧭 04_routing_integration: 질문 라우팅 및 답변 통합\")\n",
    "    summary.append(f\"   🧑‍⚖️ 05_hitl_evaluation: ReAct 평가 및 HITL 시스템\")\n",
    "    summary.append(f\"   🚀 99_full_pipeline_test: 전체 통합 테스트\")\n",
    "    \n",
    "    # 핵심 기능\n",
    "    summary.append(f\"\\n🎯 핵심 기능:\")\n",
    "    summary.append(f\"   🔍 지능형 질문 분석 및 도메인 라우팅\")\n",
    "    summary.append(f\"   📚 도메인별 전문 지식 검색 (7개 도메인)\")\n",
    "    summary.append(f\"   🔄 Corrective RAG (자가교정 메커니즘)\")\n",
    "    summary.append(f\"   🌐 실시간 웹 검색 통합 (Tavily API)\")\n",
    "    summary.append(f\"   🧠 다중 에이전트 답변 통합\")\n",
    "    summary.append(f\"   ⚖️ 6차원 품질 평가 시스템 (60점 만점)\")\n",
    "    summary.append(f\"   👥 Human-in-the-Loop 품질 검증\")\n",
    "    summary.append(f\"   📊 실시간 성능 모니터링\")\n",
    "    \n",
    "    # 시스템 현황\n",
    "    if system_components[\"init_status\"]:\n",
    "        init_status = system_components[\"init_status\"]\n",
    "        overall_status = init_status.overall_status()\n",
    "        \n",
    "        summary.append(f\"\\n📊 시스템 현황:\")\n",
    "        summary.append(f\"   - 전체 초기화 성공률: {overall_status:.1f}%\")\n",
    "        summary.append(f\"   - LLM (GPT-4o-mini): {'✅' if init_status.llm else '❌'}\")\n",
    "        summary.append(f\"   - 임베딩 (bge-m3): {'✅' if init_status.embeddings else '❌'}\")\n",
    "        summary.append(f\"   - 웹 검색 (Tavily): {'✅' if init_status.web_search else '❌'}\")\n",
    "        summary.append(f\"   - 벡터 저장소: {sum(init_status.vectorstores.values())}/7개\")\n",
    "        summary.append(f\"   - RAG 에이전트: {sum(init_status.agents.values())}/8개\")\n",
    "    \n",
    "    # 성능 결과\n",
    "    if comprehensive_results:\n",
    "        successful_tests = [r for r in comprehensive_results if r.success]\n",
    "        success_rate = len(successful_tests) / len(comprehensive_results) * 100\n",
    "        \n",
    "        if successful_tests:\n",
    "            avg_time = sum(r.processing_time for r in successful_tests) / len(successful_tests)\n",
    "            avg_confidence = sum(r.confidence_score for r in successful_tests) / len(successful_tests)\n",
    "            \n",
    "            summary.append(f\"\\n🎯 성능 결과:\")\n",
    "            summary.append(f\"   - 총 테스트: {len(comprehensive_results)}개\")\n",
    "            summary.append(f\"   - 성공률: {success_rate:.1f}%\")\n",
    "            summary.append(f\"   - 평균 처리 시간: {avg_time:.2f}초\")\n",
    "            summary.append(f\"   - 평균 신뢰도: {avg_confidence:.2f}\")\n",
    "            summary.append(f\"   - 평균 출처 수: {sum(r.source_count for r in successful_tests) / len(successful_tests):.1f}개\")\n",
    "    \n",
    "    # 배포 준비도\n",
    "    if 'readiness_checker' in locals():\n",
    "        deployment_score = readiness_checker.get_deployment_score()\n",
    "        summary.append(f\"\\n🚀 배포 준비도: {deployment_score:.1f}/100점\")\n",
    "        \n",
    "        if deployment_score >= 90:\n",
    "            summary.append(f\"   🟢 프로덕션 배포 준비 완료\")\n",
    "        elif deployment_score >= 70:\n",
    "            summary.append(f\"   🟡 일부 개선 후 배포 가능\")\n",
    "        elif deployment_score >= 50:\n",
    "            summary.append(f\"   🟠 주요 개선사항 해결 필요\")\n",
    "        else:\n",
    "            summary.append(f\"   🔴 전면적인 시스템 점검 필요\")\n",
    "    \n",
    "    # 차별화 요소\n",
    "    summary.append(f\"\\n🌟 차별화 요소:\")\n",
    "    summary.append(f\"   🎯 도메인별 전문화: 각 도메인에 특화된 RAG 에이전트\")\n",
    "    summary.append(f\"   🔄 자가교정 시스템: Corrective RAG로 답변 품질 자동 개선\")\n",
    "    summary.append(f\"   👥 품질 보증: AI+인간 이중 검증 시스템\")\n",
    "    summary.append(f\"   🧠 지능형 라우팅: 질문 내용 기반 최적 에이전트 선택\")\n",
    "    summary.append(f\"   📊 실시간 모니터링: 성능 및 품질 지표 추적\")\n",
    "    summary.append(f\"   🌐 하이브리드 검색: 내부 문서 + 실시간 웹 검색\")\n",
    "    \n",
    "    # 향후 개선사항\n",
    "    summary.append(f\"\\n🔧 권장 개선사항:\")\n",
    "    summary.append(f\"   📈 성능 최적화: 병렬 처리 및 캐싱 개선\")\n",
    "    summary.append(f\"   🎨 UI/UX 개발: Streamlit 웹 앱 고도화\")\n",
    "    summary.append(f\"   🔒 보안 강화: API 키 관리 및 액세스 제어\")\n",
    "    summary.append(f\"   📊 분석 고도화: 사용자 피드백 기반 학습\")\n",
    "    summary.append(f\"   🌐 다국어 지원: 영어 문서 및 질문 처리\")\n",
    "    summary.append(f\"   📱 모바일 최적화: 반응형 웹 인터페이스\")\n",
    "    \n",
    "    # 결론\n",
    "    summary.append(f\"\\n🎉 결론:\")\n",
    "    summary.append(f\"꿀스테이 RAG 시스템은 Multi-Agent 아키텍처와 Human-in-the-Loop 품질 검증을\")\n",
    "    summary.append(f\"통합한 차세대 기업용 지식 검색 시스템으로 성공적으로 구축되었습니다.\")\n",
    "    summary.append(f\"도메인별 전문화, Corrective RAG, 실시간 품질 평가 등의 혁신적 기능을\")\n",
    "    summary.append(f\"통해 기존 RAG 시스템 대비 높은 정확성과 신뢰성을 제공합니다.\")\n",
    "    \n",
    "    summary.append(f\"\\n✨ 이 시스템은 기업의 내부 지식 관리와 직원 질의응답을 혁신할 수 있는\")\n",
    "    summary.append(f\"강력한 도구로, 지속적인 학습과 개선을 통해 더욱 발전할 수 있습니다.\")\n",
    "    \n",
    "    return \"\\n\".join(summary)\n",
    "\n",
    "# 최종 요약 보고서 출력\n",
    "print(\"📄 최종 요약 보고서 생성 중...\\n\")\n",
    "\n",
    "final_summary_report = generate_final_summary()\n",
    "print(final_summary_report)\n",
    "\n",
    "# 테스트 완료 메시지\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎊 꿀스테이 RAG 시스템 통합 테스트 완료! 🎊\")\n",
    "print(f\"⏰ 테스트 소요 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"🚀 시스템이 성공적으로 구축되고 테스트되었습니다!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 테스트 결과 저장 (선택사항)\n",
    "\n",
    "### 완료된 전체 RAG 파이프라인 컴포넌트\n",
    "\n",
    "✅ **01_data_processing.ipynb**\n",
    "- 마크다운 문서 로딩 및 파싱\n",
    "- 헤더 기반 지능형 청킹\n",
    "- 메타데이터 추출 및 품질 분석\n",
    "\n",
    "✅ **02_vector_stores.ipynb**  \n",
    "- 7개 도메인별 독립 ChromaDB 구축\n",
    "- bge-m3 임베딩 모델 통합\n",
    "- 검색 성능 최적화 및 테스트\n",
    "\n",
    "✅ **03_agents_development.ipynb**\n",
    "- Corrective RAG 메커니즘\n",
    "- 8개 전문 에이전트 (7개 도메인 + 웹검색)\n",
    "- 4차원 품질 평가 시스템\n",
    "\n",
    "✅ **04_routing_integration.ipynb**\n",
    "- AI 기반 질문 분석 및 도메인 분류\n",
    "- 멀티 에이전트 답변 통합\n",
    "- LangGraph 워크플로우 오케스트레이션\n",
    "\n",
    "✅ **05_hitl_evaluation.ipynb**\n",
    "- ReAct 기반 6차원 평가 (60점 만점)\n",
    "- 인터럽트 기반 Human-in-the-Loop\n",
    "- 실시간 피드백 수집 및 분석\n",
    "\n",
    "✅ **99_full_pipeline_test.ipynb** (현재)\n",
    "- 전체 시스템 통합 테스트\n",
    "- 종합 성능 분석 및 벤치마크\n",
    "- 배포 준비도 점검\n",
    "\n",
    "### 🎯 시스템 핵심 특징\n",
    "\n",
    "1. **Multi-Agent RAG**: 도메인별 전문화된 8개 에이전트\n",
    "2. **Corrective RAG**: 자가교정 메커니즘으로 품질 자동 개선\n",
    "3. **Human-in-the-Loop**: AI+인간 이중 검증 품질 보증\n",
    "4. **Intelligent Routing**: 질문 내용 기반 최적 에이전트 선택\n",
    "5. **Real-time Monitoring**: 성능 및 품질 지표 실시간 추적\n",
    "6. **Hybrid Search**: 내부 문서 + 실시간 웹 검색\n",
    "\n",
    "### 🚀 차세대 기업용 RAG 시스템 완성!\n",
    "\n",
    "꿀스테이 RAG 시스템은 기존 RAG의 한계를 뛰어넘어 **도메인 전문화**, **품질 보증**, **지능형 라우팅**을 통해 기업용 지식 검색의 새로운 표준을 제시합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}