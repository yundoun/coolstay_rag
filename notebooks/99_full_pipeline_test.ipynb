{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ ê¿€ìŠ¤í…Œì´ RAG - ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” 1-5ë²ˆ ë…¸íŠ¸ë¶ì˜ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•©í•˜ì—¬ ì™„ì „í•œ RAG ì‹œìŠ¤í…œì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ëª©í‘œ\n",
    "1. ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ í†µí•©\n",
    "2. ì—”ë“œíˆ¬ì—”ë“œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n",
    "3. ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦\n",
    "4. ì‹œìŠ¤í…œ ë²¤ì¹˜ë§ˆí¬ ë° ì„±ëŠ¥ ë¶„ì„\n",
    "5. ìµœì¢… ë°°í¬ ì¤€ë¹„ ìƒíƒœ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport sys\nimport time\nimport json\nimport uuid\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Optional, Tuple, Union\nimport logging\nfrom datetime import datetime, timedelta\nfrom dataclasses import dataclass, field\nfrom enum import Enum\n\n# í™˜ê²½ ë° ì„¤ì •\nfrom dotenv import load_dotenv\n\n# LangChain ìƒíƒœê³„\nfrom langchain_openai import ChatOpenAI\nfrom langchain_ollama import OllamaEmbeddings\nfrom langchain_chroma import Chroma\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser, JsonOutputParser\nfrom langchain_core.documents import Document\nfrom langchain.text_splitter import MarkdownHeaderTextSplitter\nfrom langchain_community.tools import TavilySearchResults\n\n# LangGraph\nfrom langgraph.graph import StateGraph, END\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom typing_extensions import TypedDict\n\n# ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display, HTML, clear_output\nimport ipywidgets as widgets\n\n# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (ì ˆëŒ€ ê²½ë¡œ ì§€ì •)\nproject_root = Path(\"/Users/yundoun/Desktop/Project/legal_rag/coolstay_rag\")\nenv_file = project_root / \".env\"\nload_result = load_dotenv(env_file)\nprint(f\"ðŸ“ .env íŒŒì¼ ë¡œë“œ: {load_result} (ê²½ë¡œ: {env_file})\")\n\n# API í‚¤ í™•ì¸\nopenai_key = os.getenv(\"OPENAI_API_KEY\", \"NOT_FOUND\")\ntavily_key = os.getenv(\"TAVILY_API_KEY\", \"NOT_FOUND\")\nprint(f\"ðŸ”‘ OpenAI API Key: {'ì„¤ì •ë¨' if openai_key != 'NOT_FOUND' and openai_key.startswith('sk-') else 'NOT_FOUND'}\")\nprint(f\"ðŸ”‘ Tavily API Key: {'ì„¤ì •ë¨' if tavily_key != 'NOT_FOUND' and tavily_key.startswith('tvly-') else 'NOT_FOUND'}\")\n\n# ë¡œê¹… ì„¤ì •\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n# ì‹œê°í™” ì„¤ì •\nplt.rcParams['font.size'] = 10\nplt.rcParams['figure.figsize'] = (12, 8)\nsns.set_style(\"whitegrid\")\n\nprint(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ\")\nprint(f\"ðŸ“… í…ŒìŠ¤íŠ¸ ì‹œìž‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í†µí•© ì‹œìŠ¤í…œ ì„¤ì • ë° ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡œì íŠ¸ ê²½ë¡œ ë° ì„¤ì •\n",
    "PROJECT_ROOT = Path(\"/Users/yundoun/Desktop/Project/legal_rag/coolstay_rag\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "CHROMA_DB_DIR = PROJECT_ROOT / \"chroma_db\"\n",
    "NOTEBOOKS_DIR = PROJECT_ROOT / \"notebooks\"\n",
    "\n",
    "# ë„ë©”ì¸ ì„¤ì • (ì „ì²´ ì‹œìŠ¤í…œ í†µí•©ìš©)\n",
    "DOMAIN_CONFIG = {\n",
    "    \"hr_policy\": {\n",
    "        \"file\": \"HR_Policy_Guide.md\",\n",
    "        \"description\": \"ì¸ì‚¬ì •ì±…, ê·¼ë¬´ì‹œê°„, íœ´ê°€, ê¸‰ì—¬, ë³µë¦¬í›„ìƒ\",\n",
    "        \"collection_name\": \"hr_policy_db\",\n",
    "        \"agent_name\": \"HR ì •ì±… ì „ë¬¸ê°€\",\n",
    "        \"keywords\": [\"ì¸ì‚¬\", \"HR\", \"ê·¼ë¬´\", \"íœ´ê°€\", \"ì—°ì°¨\", \"ê¸‰ì—¬\", \"ë³´í—˜\", \"ë³µë¦¬í›„ìƒ\", \"ì±„ìš©\", \"í‡´ì‚¬\"]\n",
    "    },\n",
    "    \"tech_policy\": {\n",
    "        \"file\": \"Tech_Policy_Guide.md\",\n",
    "        \"description\": \"ê¸°ìˆ ì •ì±…, ê°œë°œí™˜ê²½, ì½”ë”©í‘œì¤€, ë³´ì•ˆì •ì±…\",\n",
    "        \"collection_name\": \"tech_policy_db\",\n",
    "        \"agent_name\": \"ê¸°ìˆ  ì •ì±… ì „ë¬¸ê°€\",\n",
    "        \"keywords\": [\"ê¸°ìˆ \", \"ê°œë°œ\", \"ì½”ë”©\", \"ì½”ë“œ\", \"í”„ë¡œê·¸ëž˜ë°\", \"ë³´ì•ˆ\", \"ê°œë°œí™˜ê²½\", \"IDE\", \"ë„êµ¬\"]\n",
    "    },\n",
    "    \"architecture\": {\n",
    "        \"file\": \"Architecture_Guide.md\",\n",
    "        \"description\": \"CMS ì•„í‚¤í…ì²˜, ì‹œìŠ¤í…œì„¤ê³„, ë ˆì´ì–´êµ¬ì¡°\",\n",
    "        \"collection_name\": \"architecture_db\",\n",
    "        \"agent_name\": \"ì•„í‚¤í…ì²˜ ì „ë¬¸ê°€\",\n",
    "        \"keywords\": [\"ì•„í‚¤í…ì²˜\", \"ì‹œìŠ¤í…œ\", \"ì„¤ê³„\", \"êµ¬ì¡°\", \"ë ˆì´ì–´\", \"ëª¨ë“ˆ\", \"ì„œë¹„ìŠ¤\", \"API\", \"ë°ì´í„°ë² ì´ìŠ¤\"]\n",
    "    },\n",
    "    \"component\": {\n",
    "        \"file\": \"Component_Guide.md\",\n",
    "        \"description\": \"ì»´í¬ë„ŒíŠ¸ ê°€ì´ë“œë¼ì¸, UI/UX í‘œì¤€\",\n",
    "        \"collection_name\": \"component_db\",\n",
    "        \"agent_name\": \"ì»´í¬ë„ŒíŠ¸ ê°œë°œ ì „ë¬¸ê°€\",\n",
    "        \"keywords\": [\"ì»´í¬ë„ŒíŠ¸\", \"UI\", \"UX\", \"ì¸í„°íŽ˜ì´ìŠ¤\", \"ë””ìžì¸\", \"í”„ë¡ íŠ¸ì—”ë“œ\", \"ì‚¬ìš©ìž\", \"í™”ë©´\"]\n",
    "    },\n",
    "    \"deployment\": {\n",
    "        \"file\": \"Deployment_Guide.md\",\n",
    "        \"description\": \"ë°°í¬í”„ë¡œì„¸ìŠ¤, CI/CD, í™˜ê²½ê´€ë¦¬\",\n",
    "        \"collection_name\": \"deployment_db\",\n",
    "        \"agent_name\": \"ë°°í¬ ì „ë¬¸ê°€\",\n",
    "        \"keywords\": [\"ë°°í¬\", \"CI/CD\", \"í™˜ê²½\", \"ì„œë²„\", \"í´ë¼ìš°ë“œ\", \"ë„ì»¤\", \"ì¿ ë²„ë„¤í‹°ìŠ¤\", \"íŒŒì´í”„ë¼ì¸\"]\n",
    "    },\n",
    "    \"development\": {\n",
    "        \"file\": \"Development_Process_Guide.md\",\n",
    "        \"description\": \"ê°œë°œí”„ë¡œì„¸ìŠ¤, ì›Œí¬í”Œë¡œìš°, í˜‘ì—…ê·œì¹™\",\n",
    "        \"collection_name\": \"development_db\",\n",
    "        \"agent_name\": \"ê°œë°œ í”„ë¡œì„¸ìŠ¤ ì „ë¬¸ê°€\",\n",
    "        \"keywords\": [\"ê°œë°œí”„ë¡œì„¸ìŠ¤\", \"ì›Œí¬í”Œë¡œìš°\", \"í˜‘ì—…\", \"í”„ë¡œì„¸ìŠ¤\", \"ë°©ë²•ë¡ \", \"ìŠ¤í¬ëŸ¼\", \"ì• ìžì¼\"]\n",
    "    },\n",
    "    \"business_policy\": {\n",
    "        \"file\": \"Business_Policy_Guide.md\",\n",
    "        \"description\": \"ë¹„ì¦ˆë‹ˆìŠ¤ì •ì±…, ìš´ì˜ê·œì¹™, ì˜ì‚¬ê²°ì •\",\n",
    "        \"collection_name\": \"business_policy_db\",\n",
    "        \"agent_name\": \"ë¹„ì¦ˆë‹ˆìŠ¤ ì •ì±… ì „ë¬¸ê°€\",\n",
    "        \"keywords\": [\"ë¹„ì¦ˆë‹ˆìŠ¤\", \"ì •ì±…\", \"ìš´ì˜\", \"ì˜ì‚¬ê²°ì •\", \"ì „ëžµ\", \"ê³„íš\", \"ëª©í‘œ\", \"ì„±ê³¼\"]\n",
    "    },\n",
    "    \"web_search\": {\n",
    "        \"description\": \"ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì„ í†µí•œ ìµœì‹  ì •ë³´ ì œê³µ\",\n",
    "        \"agent_name\": \"ì›¹ ê²€ìƒ‰ ì „ë¬¸ê°€\",\n",
    "        \"keywords\": [\"ìµœì‹ \", \"íŠ¸ë Œë“œ\", \"ë‰´ìŠ¤\", \"ë™í–¥\", \"í˜„ìž¬\", \"ì‹¤ì‹œê°„\", \"ì—…ë°ì´íŠ¸\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"âœ… í”„ë¡œì íŠ¸ ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"   - í”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}\")\n",
    "print(f\"   - ë°ì´í„° ë””ë ‰í† ë¦¬: {DATA_DIR}\")\n",
    "print(f\"   - ChromaDB ë””ë ‰í† ë¦¬: {CHROMA_DB_DIR}\")\n",
    "print(f\"   - ë„ë©”ì¸ ìˆ˜: {len(DOMAIN_CONFIG)}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œìŠ¤í…œ ì´ˆê¸°í™” ìƒíƒœ ì¶”ì \n",
    "@dataclass\n",
    "class SystemInitStatus:\n",
    "    llm: bool = False\n",
    "    embeddings: bool = False\n",
    "    web_search: bool = False\n",
    "    vectorstores: Dict[str, bool] = field(default_factory=dict)\n",
    "    agents: Dict[str, bool] = field(default_factory=dict)\n",
    "    \n",
    "    def overall_status(self) -> float:\n",
    "        \"\"\"ì „ì²´ ì´ˆê¸°í™” ì„±ê³µë¥  ê³„ì‚°\"\"\"\n",
    "        total_components = 3 + len(DOMAIN_CONFIG) * 2  # LLM, Embeddings, WebSearch + (Vectorstore + Agent) per domain\n",
    "        successful_components = (\n",
    "            int(self.llm) + \n",
    "            int(self.embeddings) + \n",
    "            int(self.web_search) +\n",
    "            sum(self.vectorstores.values()) +\n",
    "            sum(self.agents.values())\n",
    "        )\n",
    "        return (successful_components / total_components) * 100\n",
    "\n",
    "init_status = SystemInitStatus()\n",
    "\n",
    "def initialize_system_components():\n",
    "    \"\"\"ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ í†µí•© ì´ˆê¸°í™”\"\"\"\n",
    "    \n",
    "    print(\"ðŸ”§ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹œìž‘...\\n\")\n",
    "    \n",
    "    # 1. LLM ì´ˆê¸°í™”\n",
    "    print(\"1ï¸âƒ£ LLM ì´ˆê¸°í™”...\")\n",
    "    try:\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.1,\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        # í…ŒìŠ¤íŠ¸ í˜¸ì¶œ\n",
    "        test_response = llm.invoke(\"Hello\")\n",
    "        init_status.llm = True\n",
    "        print(f\"   âœ… LLM ì´ˆê¸°í™” ì„±ê³µ: {llm.model_name}\")\n",
    "    except Exception as e:\n",
    "        llm = None\n",
    "        print(f\"   âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # 2. ìž„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    print(\"\\n2ï¸âƒ£ ìž„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”...\")\n",
    "    try:\n",
    "        embeddings = OllamaEmbeddings(\n",
    "            model=\"bge-m3\",\n",
    "            base_url=\"http://localhost:11434\"\n",
    "        )\n",
    "        # í…ŒìŠ¤íŠ¸ ìž„ë² ë”©\n",
    "        test_embedding = embeddings.embed_query(\"test\")\n",
    "        init_status.embeddings = True\n",
    "        print(f\"   âœ… ìž„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ: bge-m3 ({len(test_embedding)}ì°¨ì›)\")\n",
    "    except Exception as e:\n",
    "        embeddings = None\n",
    "        print(f\"   âŒ ìž„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # 3. ì›¹ ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™”\n",
    "    print(\"\\n3ï¸âƒ£ ì›¹ ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™”...\")\n",
    "    try:\n",
    "        web_search = TavilySearchResults(\n",
    "            max_results=3,\n",
    "            api_key=os.getenv(\"TAVILY_API_KEY\")\n",
    "        )\n",
    "        init_status.web_search = True\n",
    "        print(f\"   âœ… ì›¹ ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™” ì„±ê³µ\")\n",
    "    except Exception as e:\n",
    "        web_search = None\n",
    "        print(f\"   âŒ ì›¹ ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # 4. ë²¡í„° ì €ìž¥ì†Œ ë¡œë”©\n",
    "    print(\"\\n4ï¸âƒ£ ë²¡í„° ì €ìž¥ì†Œ ë¡œë”©...\")\n",
    "    vectorstores = {}\n",
    "    \n",
    "    if embeddings:\n",
    "        for domain in DOMAIN_CONFIG.keys():\n",
    "            if domain == \"web_search\":\n",
    "                continue\n",
    "                \n",
    "            collection_name = DOMAIN_CONFIG[domain][\"collection_name\"]\n",
    "            persist_directory = str(CHROMA_DB_DIR / domain)\n",
    "            \n",
    "            try:\n",
    "                if Path(persist_directory).exists():\n",
    "                    vectorstore = Chroma(\n",
    "                        collection_name=collection_name,\n",
    "                        embedding_function=embeddings,\n",
    "                        persist_directory=persist_directory\n",
    "                    )\n",
    "                    \n",
    "                    # ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "                    count = vectorstore._collection.count()\n",
    "                    vectorstores[domain] = vectorstore\n",
    "                    init_status.vectorstores[domain] = True\n",
    "                    print(f\"   âœ… {domain}: {count}ê°œ ë¬¸ì„œ\")\n",
    "                else:\n",
    "                    init_status.vectorstores[domain] = False\n",
    "                    print(f\"   âš ï¸  {domain}: ë²¡í„° ì €ìž¥ì†Œ ì—†ìŒ\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                init_status.vectorstores[domain] = False\n",
    "                print(f\"   âŒ {domain}: ë¡œë”© ì‹¤íŒ¨ - {e}\")\n",
    "    else:\n",
    "        print(\"   âŒ ìž„ë² ë”© ëª¨ë¸ì´ ì—†ì–´ ë²¡í„° ì €ìž¥ì†Œë¥¼ ë¡œë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # 5. ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (ê°„ì†Œí™”ëœ ë²„ì „)\n",
    "    print(\"\\n5ï¸âƒ£ RAG ì—ì´ì „íŠ¸ ì´ˆê¸°í™”...\")\n",
    "    agents = {}\n",
    "    \n",
    "    if llm:\n",
    "        for domain in DOMAIN_CONFIG.keys():\n",
    "            try:\n",
    "                if domain == \"web_search\":\n",
    "                    if web_search:\n",
    "                        # ê°„ì†Œí™”ëœ ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸\n",
    "                        agents[domain] = {\"type\": \"web_search\", \"tool\": web_search, \"llm\": llm}\n",
    "                        init_status.agents[domain] = True\n",
    "                        print(f\"   âœ… {domain}: ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸\")\n",
    "                    else:\n",
    "                        init_status.agents[domain] = False\n",
    "                        print(f\"   âŒ {domain}: ì›¹ ê²€ìƒ‰ ë„êµ¬ ì—†ìŒ\")\n",
    "                else:\n",
    "                    if domain in vectorstores:\n",
    "                        # ê°„ì†Œí™”ëœ RAG ì—ì´ì „íŠ¸\n",
    "                        agents[domain] = {\n",
    "                            \"type\": \"rag\", \n",
    "                            \"vectorstore\": vectorstores[domain], \n",
    "                            \"llm\": llm,\n",
    "                            \"config\": DOMAIN_CONFIG[domain]\n",
    "                        }\n",
    "                        init_status.agents[domain] = True\n",
    "                        print(f\"   âœ… {domain}: RAG ì—ì´ì „íŠ¸\")\n",
    "                    else:\n",
    "                        init_status.agents[domain] = False\n",
    "                        print(f\"   âŒ {domain}: ë²¡í„° ì €ìž¥ì†Œ ì—†ìŒ\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                init_status.agents[domain] = False\n",
    "                print(f\"   âŒ {domain}: ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨ - {e}\")\n",
    "    else:\n",
    "        print(\"   âŒ LLMì´ ì—†ì–´ ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ì´ˆê¸°í™” ìš”ì•½\n",
    "    success_rate = init_status.overall_status()\n",
    "    print(f\"\\nðŸ“Š ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "    print(f\"   - ì „ì²´ ì„±ê³µë¥ : {success_rate:.1f}%\")\n",
    "    print(f\"   - LLM: {'âœ…' if init_status.llm else 'âŒ'}\")\n",
    "    print(f\"   - ìž„ë² ë”©: {'âœ…' if init_status.embeddings else 'âŒ'}\")\n",
    "    print(f\"   - ì›¹ ê²€ìƒ‰: {'âœ…' if init_status.web_search else 'âŒ'}\")\n",
    "    print(f\"   - ë²¡í„° ì €ìž¥ì†Œ: {sum(init_status.vectorstores.values())}/{len([d for d in DOMAIN_CONFIG if d != 'web_search'])}ê°œ\")\n",
    "    print(f\"   - ì—ì´ì „íŠ¸: {sum(init_status.agents.values())}/{len(DOMAIN_CONFIG)}ê°œ\")\n",
    "    \n",
    "    return {\n",
    "        \"llm\": llm,\n",
    "        \"embeddings\": embeddings,\n",
    "        \"web_search\": web_search,\n",
    "        \"vectorstores\": vectorstores,\n",
    "        \"agents\": agents,\n",
    "        \"init_status\": init_status\n",
    "    }\n",
    "\n",
    "# ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤í–‰\n",
    "system_components = initialize_system_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. í†µí•© RAG íŒŒì´í”„ë¼ì¸ í´ëž˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PipelineTestResult:\n",
    "    \"\"\"íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼\"\"\"\n",
    "    test_id: str\n",
    "    question: str\n",
    "    answer: str\n",
    "    selected_domains: List[str]\n",
    "    processing_time: float\n",
    "    success: bool\n",
    "    error_message: Optional[str] = None\n",
    "    \n",
    "    # ìƒì„¸ ì •ë³´\n",
    "    question_analysis_time: float = 0.0\n",
    "    agent_execution_time: float = 0.0\n",
    "    response_integration_time: float = 0.0\n",
    "    \n",
    "    # í’ˆì§ˆ ì •ë³´\n",
    "    confidence_score: float = 0.0\n",
    "    source_count: int = 0\n",
    "    \n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "class IntegratedRAGPipeline:\n",
    "    \"\"\"í†µí•© RAG íŒŒì´í”„ë¼ì¸\"\"\"\n",
    "    \n",
    "    def __init__(self, system_components: Dict[str, Any]):\n",
    "        self.llm = system_components[\"llm\"]\n",
    "        self.embeddings = system_components[\"embeddings\"]\n",
    "        self.web_search = system_components[\"web_search\"]\n",
    "        self.vectorstores = system_components[\"vectorstores\"]\n",
    "        self.agents = system_components[\"agents\"]\n",
    "        self.init_status = system_components[\"init_status\"]\n",
    "        \n",
    "        # ì§ˆë¬¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸\n",
    "        self.question_analysis_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì „ë¬¸ê°€ ë„ë©”ì¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.\n",
    "        \n",
    "        **ì§ˆë¬¸:** {question}\n",
    "        \n",
    "        **ì‚¬ìš© ê°€ëŠ¥í•œ ë„ë©”ì¸:**\n",
    "        - hr_policy: ì¸ì‚¬ì •ì±…, ê·¼ë¬´ì‹œê°„, íœ´ê°€, ê¸‰ì—¬, ë³µë¦¬í›„ìƒ\n",
    "        - tech_policy: ê¸°ìˆ ì •ì±…, ê°œë°œí™˜ê²½, ì½”ë”©í‘œì¤€, ë³´ì•ˆì •ì±…\n",
    "        - architecture: CMS ì•„í‚¤í…ì²˜, ì‹œìŠ¤í…œì„¤ê³„, ë ˆì´ì–´êµ¬ì¡°\n",
    "        - component: ì»´í¬ë„ŒíŠ¸ ê°€ì´ë“œë¼ì¸, UI/UX í‘œì¤€\n",
    "        - deployment: ë°°í¬í”„ë¡œì„¸ìŠ¤, CI/CD, í™˜ê²½ê´€ë¦¬\n",
    "        - development: ê°œë°œí”„ë¡œì„¸ìŠ¤, ì›Œí¬í”Œë¡œìš°, í˜‘ì—…ê·œì¹™\n",
    "        - business_policy: ë¹„ì¦ˆë‹ˆìŠ¤ì •ì±…, ìš´ì˜ê·œì¹™, ì˜ì‚¬ê²°ì •\n",
    "        - web_search: ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰, ìµœì‹  ì •ë³´\n",
    "        \n",
    "        ìµœëŒ€ 3ê°œ ë„ë©”ì¸ì„ ì„ íƒí•˜ê³  JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:\n",
    "        {{\n",
    "            \"selected_domains\": [\"domain1\", \"domain2\"],\n",
    "            \"reasoning\": \"ì„ íƒ ê·¼ê±°\"\n",
    "        }}\n",
    "        \"\"\")\n",
    "        \n",
    "        # ë‹µë³€ í†µí•© í”„ë¡¬í”„íŠ¸\n",
    "        self.integration_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        ì—¬ëŸ¬ ì „ë¬¸ê°€ì˜ ë‹µë³€ì„ í†µí•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
    "        \n",
    "        **ì§ˆë¬¸:** {question}\n",
    "        \n",
    "        **ì „ë¬¸ê°€ ë‹µë³€ë“¤:**\n",
    "        {expert_answers}\n",
    "        \n",
    "        **í†µí•© ì§€ì¹¨:**\n",
    "        1. ê° ì „ë¬¸ê°€ì˜ ë‹µë³€ì„ ì¢…í•©í•˜ì—¬ ì™„ì„±ë„ ë†’ì€ ë‹µë³€ ìƒì„±\n",
    "        2. ì¤‘ë³µ ë‚´ìš© ì œê±° ë° ì¼ê´€ì„± ìœ ì§€\n",
    "        3. ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì •ë³´ ìš°ì„ \n",
    "        4. í•œêµ­ì–´ë¡œ ìžì—°ìŠ¤ëŸ½ê²Œ ìž‘ì„±\n",
    "        \n",
    "        í†µí•©ëœ ìµœì¢… ë‹µë³€:\n",
    "        \"\"\")\n",
    "        \n",
    "        # ì²´ì¸ êµ¬ì„±\n",
    "        if self.llm:\n",
    "            self.question_analysis_chain = (\n",
    "                self.question_analysis_prompt | \n",
    "                self.llm | \n",
    "                JsonOutputParser()\n",
    "            )\n",
    "            \n",
    "            self.integration_chain = (\n",
    "                self.integration_prompt |\n",
    "                self.llm |\n",
    "                StrOutputParser()\n",
    "            )\n",
    "    \n",
    "    def analyze_question(self, question: str) -> Tuple[List[str], str]:\n",
    "        \"\"\"ì§ˆë¬¸ ë¶„ì„ ë° ë„ë©”ì¸ ì„ íƒ\"\"\"\n",
    "        if not self.llm:\n",
    "            return [\"hr_policy\"], \"LLM ì—†ìŒ - ê¸°ë³¸ ë„ë©”ì¸ ì‚¬ìš©\"\n",
    "        \n",
    "        try:\n",
    "            result = self.question_analysis_chain.invoke({\"question\": question})\n",
    "            selected_domains = result.get(\"selected_domains\", [\"hr_policy\"])\n",
    "            reasoning = result.get(\"reasoning\", \"ë¶„ì„ ì™„ë£Œ\")\n",
    "            \n",
    "            # ì‚¬ìš© ê°€ëŠ¥í•œ ë„ë©”ì¸ë§Œ í•„í„°ë§\n",
    "            available_domains = []\n",
    "            for domain in selected_domains:\n",
    "                if domain in self.agents:\n",
    "                    available_domains.append(domain)\n",
    "            \n",
    "            return available_domains or [\"hr_policy\"], reasoning\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì§ˆë¬¸ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "            return [\"hr_policy\"], f\"ë¶„ì„ ì‹¤íŒ¨: {e}\"\n",
    "    \n",
    "    def execute_agent(self, domain: str, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"ê°œë³„ ì—ì´ì „íŠ¸ ì‹¤í–‰\"\"\"\n",
    "        if domain not in self.agents:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"answer\": f\"{domain} ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\",\n",
    "                \"source_count\": 0,\n",
    "                \"confidence\": 0.0\n",
    "            }\n",
    "        \n",
    "        agent = self.agents[domain]\n",
    "        \n",
    "        try:\n",
    "            if agent[\"type\"] == \"web_search\":\n",
    "                # ì›¹ ê²€ìƒ‰ ì‹¤í–‰\n",
    "                search_results = agent[\"tool\"].invoke({\"query\": question})\n",
    "                \n",
    "                # ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ… ë° ë‹µë³€ ìƒì„±\n",
    "                if search_results:\n",
    "                    formatted_results = \"\\n\".join([\n",
    "                        f\"- {result.get('title', '')}: {result.get('content', '')[:100]}...\"\n",
    "                        for result in search_results[:3]\n",
    "                    ])\n",
    "                    \n",
    "                    web_prompt = f\"ë‹¤ìŒ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ '{question}'ì— ëŒ€í•œ ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”:\\n\\n{formatted_results}\"\n",
    "                    answer = agent[\"llm\"].invoke(web_prompt).content\n",
    "                    \n",
    "                    return {\n",
    "                        \"success\": True,\n",
    "                        \"answer\": answer,\n",
    "                        \"source_count\": len(search_results),\n",
    "                        \"confidence\": 0.8\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        \"success\": False,\n",
    "                        \"answer\": \"ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\",\n",
    "                        \"source_count\": 0,\n",
    "                        \"confidence\": 0.1\n",
    "                    }\n",
    "            \n",
    "            else:  # RAG ì—ì´ì „íŠ¸\n",
    "                vectorstore = agent[\"vectorstore\"]\n",
    "                config = agent[\"config\"]\n",
    "                \n",
    "                # ë¬¸ì„œ ê²€ìƒ‰\n",
    "                docs = vectorstore.similarity_search(question, k=3)\n",
    "                \n",
    "                if docs:\n",
    "                    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±\n",
    "                    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "                    \n",
    "                    # ë‹µë³€ ìƒì„±\n",
    "                    agent_name = config.get(\"agent_name\", f\"{domain} ì „ë¬¸ê°€\")\n",
    "                    description = config.get(\"description\", \"ì „ë¬¸ê°€\")\n",
    "                    \n",
    "                    rag_prompt = f\"\"\"\n",
    "                    ë‹¹ì‹ ì€ ê¿€ìŠ¤í…Œì´ì˜ {agent_name}ìž…ë‹ˆë‹¤.\n",
    "                    ì „ë¬¸ ë¶„ì•¼: {description}\n",
    "                    \n",
    "                    ë‹¤ìŒ ë¬¸ì„œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "                    \n",
    "                    **ì§ˆë¬¸:** {question}\n",
    "                    \n",
    "                    **ê´€ë ¨ ë¬¸ì„œ:**\n",
    "                    {context}\n",
    "                    \n",
    "                    **ë‹µë³€:**\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    answer = agent[\"llm\"].invoke(rag_prompt).content\n",
    "                    \n",
    "                    return {\n",
    "                        \"success\": True,\n",
    "                        \"answer\": answer,\n",
    "                        \"source_count\": len(docs),\n",
    "                        \"confidence\": 0.9\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        \"success\": False,\n",
    "                        \"answer\": f\"{domain} ë„ë©”ì¸ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\",\n",
    "                        \"source_count\": 0,\n",
    "                        \"confidence\": 0.2\n",
    "                    }\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨ ({domain}): {e}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"answer\": f\"{domain} ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\",\n",
    "                \"source_count\": 0,\n",
    "                \"confidence\": 0.0\n",
    "            }\n",
    "    \n",
    "    def integrate_responses(self, question: str, domain_responses: Dict[str, Dict]) -> str:\n",
    "        \"\"\"ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‘ë‹µ í†µí•©\"\"\"\n",
    "        if not self.llm:\n",
    "            # LLMì´ ì—†ëŠ” ê²½ìš° ì²« ë²ˆì§¸ ì„±ê³µí•œ ì‘ë‹µ ë°˜í™˜\n",
    "            for domain, response in domain_responses.items():\n",
    "                if response[\"success\"]:\n",
    "                    return response[\"answer\"]\n",
    "            return \"ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        if len(domain_responses) == 1:\n",
    "            # ë‹¨ì¼ ì‘ë‹µì¸ ê²½ìš° í†µí•© ì—†ì´ ì§ì ‘ ë°˜í™˜\n",
    "            return list(domain_responses.values())[0][\"answer\"]\n",
    "        \n",
    "        try:\n",
    "            # ì„±ê³µí•œ ì‘ë‹µë“¤ë§Œ ìˆ˜ì§‘\n",
    "            successful_responses = {\n",
    "                domain: response for domain, response in domain_responses.items()\n",
    "                if response[\"success\"]\n",
    "            }\n",
    "            \n",
    "            if not successful_responses:\n",
    "                return \"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "            \n",
    "            # ì „ë¬¸ê°€ ë‹µë³€ í¬ë§·íŒ…\n",
    "            expert_answers = []\n",
    "            for domain, response in successful_responses.items():\n",
    "                agent_name = DOMAIN_CONFIG.get(domain, {}).get(\"agent_name\", f\"{domain} ì „ë¬¸ê°€\")\n",
    "                expert_answers.append(f\"**{agent_name}:** {response['answer']}\")\n",
    "            \n",
    "            expert_answers_text = \"\\n\\n\".join(expert_answers)\n",
    "            \n",
    "            # í†µí•© ë‹µë³€ ìƒì„±\n",
    "            integrated_answer = self.integration_chain.invoke({\n",
    "                \"question\": question,\n",
    "                \"expert_answers\": expert_answers_text\n",
    "            })\n",
    "            \n",
    "            return integrated_answer\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì‘ë‹µ í†µí•© ì‹¤íŒ¨: {e}\")\n",
    "            # ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ ì„±ê³µí•œ ì‘ë‹µ ë°˜í™˜\n",
    "            for response in domain_responses.values():\n",
    "                if response[\"success\"]:\n",
    "                    return response[\"answer\"]\n",
    "            return f\"ì‘ë‹µ í†µí•© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\"\n",
    "    \n",
    "    def process_question(self, question: str) -> PipelineTestResult:\n",
    "        \"\"\"ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\"\"\"\n",
    "        test_id = str(uuid.uuid4())[:8]\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # 1. ì§ˆë¬¸ ë¶„ì„\n",
    "            analysis_start = time.time()\n",
    "            selected_domains, reasoning = self.analyze_question(question)\n",
    "            analysis_time = time.time() - analysis_start\n",
    "            \n",
    "            # 2. ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
    "            execution_start = time.time()\n",
    "            domain_responses = {}\n",
    "            \n",
    "            for domain in selected_domains:\n",
    "                response = self.execute_agent(domain, question)\n",
    "                domain_responses[domain] = response\n",
    "            \n",
    "            execution_time = time.time() - execution_start\n",
    "            \n",
    "            # 3. ì‘ë‹µ í†µí•©\n",
    "            integration_start = time.time()\n",
    "            final_answer = self.integrate_responses(question, domain_responses)\n",
    "            integration_time = time.time() - integration_start\n",
    "            \n",
    "            # í†µê³„ ê³„ì‚°\n",
    "            total_time = time.time() - start_time\n",
    "            successful_responses = [r for r in domain_responses.values() if r[\"success\"]]\n",
    "            avg_confidence = sum(r[\"confidence\"] for r in successful_responses) / len(successful_responses) if successful_responses else 0.0\n",
    "            total_sources = sum(r[\"source_count\"] for r in domain_responses.values())\n",
    "            \n",
    "            return PipelineTestResult(\n",
    "                test_id=test_id,\n",
    "                question=question,\n",
    "                answer=final_answer,\n",
    "                selected_domains=selected_domains,\n",
    "                processing_time=total_time,\n",
    "                success=True,\n",
    "                question_analysis_time=analysis_time,\n",
    "                agent_execution_time=execution_time,\n",
    "                response_integration_time=integration_time,\n",
    "                confidence_score=avg_confidence,\n",
    "                source_count=total_sources\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n",
    "            return PipelineTestResult(\n",
    "                test_id=test_id,\n",
    "                question=question,\n",
    "                answer=f\"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\",\n",
    "                selected_domains=[],\n",
    "                processing_time=time.time() - start_time,\n",
    "                success=False,\n",
    "                error_message=str(e)\n",
    "            )\n",
    "\n",
    "# í†µí•© íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”\n",
    "if system_components[\"init_status\"].overall_status() > 50:\n",
    "    integrated_pipeline = IntegratedRAGPipeline(system_components)\n",
    "    print(\"âœ… í†µí•© RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "else:\n",
    "    integrated_pipeline = None\n",
    "    print(f\"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ìƒíƒœê°€ ë¶ˆì¶©ë¶„í•©ë‹ˆë‹¤ ({system_components['init_status'].overall_status():.1f}%)\")\n",
    "    print(\"   í†µí•© íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ë ¤ë©´ ë” ë§Žì€ ì»´í¬ë„ŒíŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì¢…í•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤\n",
    "comprehensive_test_scenarios = [\n",
    "    {\n",
    "        \"category\": \"ë‹¨ì¼ ë„ë©”ì¸\",\n",
    "        \"questions\": [\n",
    "            \"ì—°ì°¨ íœ´ê°€ëŠ” ì–´ë–»ê²Œ ì‹ ì²­í•˜ë‚˜ìš”?\",\n",
    "            \"ì½”ë”© ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸ì„ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
    "            \"ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ì˜ ì£¼ìš” êµ¬ì„±ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "            \"ë°°í¬ í”„ë¡œì„¸ìŠ¤ëŠ” ì–´ë–»ê²Œ ì§„í–‰í•˜ë‚˜ìš”?\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"ë‹¤ì¤‘ ë„ë©”ì¸\",\n",
    "        \"questions\": [\n",
    "            \"ê°œë°œìž ì±„ìš©ë¶€í„° ì˜¨ë³´ë”©ê¹Œì§€ì˜ ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”\",\n",
    "            \"ìƒˆë¡œìš´ ê¸°ëŠ¥ ê°œë°œ ì‹œ ì•„í‚¤í…ì²˜ ì„¤ê³„ë¶€í„° ë°°í¬ê¹Œì§€ ì–´ë–¤ ì ˆì°¨ë¥¼ ê±°ì¹˜ë‚˜ìš”?\",\n",
    "            \"íšŒì‚¬ì˜ ê¸°ìˆ  ìŠ¤íƒê³¼ ê°œë°œ ë¬¸í™”ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
    "            \"UI ì»´í¬ë„ŒíŠ¸ ê°œë°œ ë° ë°°í¬ ê°€ì´ë“œë¼ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"ì¼ë°˜ì  ì§ˆë¬¸\",\n",
    "        \"questions\": [\n",
    "            \"íšŒì‚¬ì˜ í•µì‹¬ ê°€ì¹˜ì™€ ë¬¸í™”ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "            \"ìƒˆë¡œ ìž…ì‚¬í•œ ê°œë°œìžê°€ ì•Œì•„ì•¼ í•  ê²ƒë“¤ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "            \"í”„ë¡œì íŠ¸ ê´€ë¦¬ëŠ” ì–´ë–»ê²Œ ì´ë£¨ì–´ì§€ë‚˜ìš”?\",\n",
    "            \"íšŒì‚¬ì˜ ì„±ìž¥ ì „ëžµê³¼ ë¹„ì „ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"ìµœì‹  ì •ë³´\",\n",
    "        \"questions\": [\n",
    "            \"2024ë…„ ìµœì‹  ì›¹ ê°œë°œ íŠ¸ë Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "            \"AI ê¸°ìˆ ì˜ ìµœê·¼ ë™í–¥ì„ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
    "            \"í´ë¼ìš°ë“œ ì»´í“¨íŒ…ì˜ ìµœì‹  ë°œì „ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "            \"í˜„ìž¬ ì¸ê¸°ìžˆëŠ” í”„ë¡œê·¸ëž˜ë° ì–¸ì–´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "def run_comprehensive_test(pipeline: IntegratedRAGPipeline, \n",
    "                         scenarios: List[Dict],\n",
    "                         max_questions_per_category: int = 2) -> List[PipelineTestResult]:\n",
    "    \"\"\"ì¢…í•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\"\"\"\n",
    "    \n",
    "    print(\"ðŸš€ ì¢…í•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œìž‘\")\n",
    "    print(f\"   - í…ŒìŠ¤íŠ¸ ì¹´í…Œê³ ë¦¬: {len(scenarios)}ê°œ\")\n",
    "    print(f\"   - ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ ì§ˆë¬¸: {max_questions_per_category}ê°œ\\n\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        category = scenario[\"category\"]\n",
    "        questions = scenario[\"questions\"][:max_questions_per_category]\n",
    "        \n",
    "        print(f\"ðŸ“‹ ì¹´í…Œê³ ë¦¬: {category}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        category_results = []\n",
    "        \n",
    "        for i, question in enumerate(questions, 1):\n",
    "            print(f\"\\n{i}ï¸âƒ£ ì§ˆë¬¸: {question}\")\n",
    "            \n",
    "            try:\n",
    "                # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "                result = pipeline.process_question(question)\n",
    "                \n",
    "                # ê²°ê³¼ ì¶œë ¥\n",
    "                print(f\"   âœ… ì„±ê³µ: {result.success}\")\n",
    "                print(f\"   ðŸŽ¯ ì„ íƒ ë„ë©”ì¸: {', '.join(result.selected_domains)}\")\n",
    "                print(f\"   â±ï¸  ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.2f}ì´ˆ\")\n",
    "                print(f\"   ðŸ“Š ì‹ ë¢°ë„: {result.confidence_score:.2f}\")\n",
    "                print(f\"   ðŸ“š ì¶œì²˜ ìˆ˜: {result.source_count}ê°œ\")\n",
    "                \n",
    "                # ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°\n",
    "                answer_preview = result.answer[:100] + \"...\" if len(result.answer) > 100 else result.answer\n",
    "                print(f\"   ðŸ’¬ ë‹µë³€: {answer_preview}\")\n",
    "                \n",
    "                category_results.append(result)\n",
    "                all_results.append(result)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ ì‹¤íŒ¨: {e}\")\n",
    "                logger.error(f\"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ({category} - {question}): {e}\")\n",
    "        \n",
    "        # ì¹´í…Œê³ ë¦¬ ìš”ì•½\n",
    "        if category_results:\n",
    "            success_count = sum(1 for r in category_results if r.success)\n",
    "            avg_time = sum(r.processing_time for r in category_results) / len(category_results)\n",
    "            avg_confidence = sum(r.confidence_score for r in category_results) / len(category_results)\n",
    "            \n",
    "            print(f\"\\nðŸ“Š {category} ìš”ì•½:\")\n",
    "            print(f\"   - ì„±ê³µë¥ : {success_count}/{len(category_results)} ({success_count/len(category_results)*100:.1f}%)\")\n",
    "            print(f\"   - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.2f}ì´ˆ\")\n",
    "            print(f\"   - í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.2f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "if integrated_pipeline:\n",
    "    print(f\"ðŸ“Š ì‹œìŠ¤í…œ ì¤€ë¹„ ìƒíƒœ: {system_components['init_status'].overall_status():.1f}%\\n\")\n",
    "    \n",
    "    comprehensive_results = run_comprehensive_test(\n",
    "        pipeline=integrated_pipeline,\n",
    "        scenarios=comprehensive_test_scenarios,\n",
    "        max_questions_per_category=2  # ì„±ëŠ¥ì„ ìœ„í•´ ê° ì¹´í…Œê³ ë¦¬ë‹¹ 2ê°œ ì§ˆë¬¸ë§Œ í…ŒìŠ¤íŠ¸\n",
    "    )\n",
    "    \n",
    "    print(f\"ðŸŽ‰ ì¢…í•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(comprehensive_results)}ê°œ í…ŒìŠ¤íŠ¸\")\n",
    "    \n",
    "else:\n",
    "    comprehensive_results = []\n",
    "    print(\"âŒ í†µí•© íŒŒì´í”„ë¼ì¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ì¢…í•© í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì„±ëŠ¥ ë¶„ì„ ë° ë²¤ì¹˜ë§ˆí¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceAnalyzer:\n",
    "    \"\"\"ì„±ëŠ¥ ë¶„ì„ ë° ë²¤ì¹˜ë§ˆí¬\"\"\"\n",
    "    \n",
    "    def __init__(self, test_results: List[PipelineTestResult]):\n",
    "        self.test_results = test_results\n",
    "        self.df = self._create_dataframe()\n",
    "    \n",
    "    def _create_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "        if not self.test_results:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        data = []\n",
    "        for result in self.test_results:\n",
    "            row = {\n",
    "                'test_id': result.test_id,\n",
    "                'question': result.question[:50] + '...' if len(result.question) > 50 else result.question,\n",
    "                'success': result.success,\n",
    "                'domains_count': len(result.selected_domains),\n",
    "                'selected_domains': ', '.join(result.selected_domains),\n",
    "                'processing_time': result.processing_time,\n",
    "                'analysis_time': result.question_analysis_time,\n",
    "                'execution_time': result.agent_execution_time,\n",
    "                'integration_time': result.response_integration_time,\n",
    "                'confidence_score': result.confidence_score,\n",
    "                'source_count': result.source_count,\n",
    "                'answer_length': len(result.answer),\n",
    "                'timestamp': result.timestamp\n",
    "            }\n",
    "            data.append(row)\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def generate_performance_report(self) -> str:\n",
    "        \"\"\"ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±\"\"\"\n",
    "        if self.df.empty:\n",
    "            return \"ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        successful_tests = self.df[self.df['success'] == True]\n",
    "        \n",
    "        report = []\n",
    "        report.append(\"ðŸš€ ê¿€ìŠ¤í…Œì´ RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„ ë³´ê³ ì„œ\")\n",
    "        report.append(\"=\" * 60)\n",
    "        \n",
    "        # ê¸°ë³¸ í†µê³„\n",
    "        report.append(f\"\\nðŸ“Š ê¸°ë³¸ í†µê³„:\")\n",
    "        report.append(f\"   - ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {len(self.df)}ê°œ\")\n",
    "        report.append(f\"   - ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {len(successful_tests)}ê°œ\")\n",
    "        report.append(f\"   - ì„±ê³µë¥ : {len(successful_tests)/len(self.df)*100:.1f}%\")\n",
    "        \n",
    "        if len(successful_tests) > 0:\n",
    "            # ì„±ëŠ¥ ì§€í‘œ\n",
    "            report.append(f\"\\nâš¡ ì„±ëŠ¥ ì§€í‘œ (ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ë§Œ):\")\n",
    "            report.append(f\"   - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {successful_tests['processing_time'].mean():.2f}ì´ˆ\")\n",
    "            report.append(f\"   - ìµœëŒ€ ì²˜ë¦¬ ì‹œê°„: {successful_tests['processing_time'].max():.2f}ì´ˆ\")\n",
    "            report.append(f\"   - ìµœì†Œ ì²˜ë¦¬ ì‹œê°„: {successful_tests['processing_time'].min():.2f}ì´ˆ\")\n",
    "            report.append(f\"   - ì²˜ë¦¬ ì‹œê°„ í‘œì¤€íŽ¸ì°¨: {successful_tests['processing_time'].std():.2f}ì´ˆ\")\n",
    "            \n",
    "            # ì²˜ë¦¬ ë‹¨ê³„ë³„ ì‹œê°„ ë¶„ì„\n",
    "            report.append(f\"\\nðŸ” ì²˜ë¦¬ ë‹¨ê³„ë³„ í‰ê·  ì‹œê°„:\")\n",
    "            if 'analysis_time' in successful_tests.columns:\n",
    "                report.append(f\"   - ì§ˆë¬¸ ë¶„ì„: {successful_tests['analysis_time'].mean():.3f}ì´ˆ\")\n",
    "            if 'execution_time' in successful_tests.columns:\n",
    "                report.append(f\"   - ì—ì´ì „íŠ¸ ì‹¤í–‰: {successful_tests['execution_time'].mean():.3f}ì´ˆ\")\n",
    "            if 'integration_time' in successful_tests.columns:\n",
    "                report.append(f\"   - ì‘ë‹µ í†µí•©: {successful_tests['integration_time'].mean():.3f}ì´ˆ\")\n",
    "            \n",
    "            # í’ˆì§ˆ ì§€í‘œ\n",
    "            report.append(f\"\\nðŸŽ¯ í’ˆì§ˆ ì§€í‘œ:\")\n",
    "            report.append(f\"   - í‰ê·  ì‹ ë¢°ë„: {successful_tests['confidence_score'].mean():.2f}\")\n",
    "            report.append(f\"   - í‰ê·  ì¶œì²˜ ìˆ˜: {successful_tests['source_count'].mean():.1f}ê°œ\")\n",
    "            report.append(f\"   - í‰ê·  ë‹µë³€ ê¸¸ì´: {successful_tests['answer_length'].mean():.0f}ìž\")\n",
    "            \n",
    "            # ë„ë©”ì¸ ì‚¬ìš© ë¶„ì„\n",
    "            report.append(f\"\\nðŸ·ï¸  ë„ë©”ì¸ ì‚¬ìš© ë¶„ì„:\")\n",
    "            domain_usage = successful_tests['domains_count'].value_counts().sort_index()\n",
    "            for domain_count, usage_count in domain_usage.items():\n",
    "                percentage = (usage_count / len(successful_tests)) * 100\n",
    "                report.append(f\"   - {domain_count}ê°œ ë„ë©”ì¸ ì‚¬ìš©: {usage_count}íšŒ ({percentage:.1f}%)\")\n",
    "            \n",
    "            # ìžì£¼ ì‚¬ìš©ëœ ë„ë©”ì¸\n",
    "            all_domains = []\n",
    "            for domains_str in successful_tests['selected_domains']:\n",
    "                all_domains.extend(domains_str.split(', '))\n",
    "            \n",
    "            domain_frequency = pd.Series(all_domains).value_counts()\n",
    "            report.append(f\"\\nðŸ“ˆ ë„ë©”ì¸ ì‚¬ìš© ë¹ˆë„:\")\n",
    "            for domain, count in domain_frequency.head(5).items():\n",
    "                percentage = (count / len(successful_tests)) * 100\n",
    "                report.append(f\"   - {domain}: {count}íšŒ ({percentage:.1f}%)\")\n",
    "        \n",
    "        # ì‹¤íŒ¨ ë¶„ì„\n",
    "        failed_tests = self.df[self.df['success'] == False]\n",
    "        if len(failed_tests) > 0:\n",
    "            report.append(f\"\\nâŒ ì‹¤íŒ¨ ë¶„ì„:\")\n",
    "            report.append(f\"   - ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸: {len(failed_tests)}ê°œ\")\n",
    "            report.append(f\"   - ì‹¤íŒ¨ìœ¨: {len(failed_tests)/len(self.df)*100:.1f}%\")\n",
    "        \n",
    "        return \"\\n\".join(report)\n",
    "    \n",
    "    def plot_performance_metrics(self, figsize=(15, 10)):\n",
    "        \"\"\"ì„±ëŠ¥ ì§€í‘œ ì‹œê°í™”\"\"\"\n",
    "        if self.df.empty:\n",
    "            print(\"ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        successful_tests = self.df[self.df['success'] == True]\n",
    "        \n",
    "        if len(successful_tests) == 0:\n",
    "            print(\"ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ê°€ ì—†ì–´ ì‹œê°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=figsize)\n",
    "        fig.suptitle('ê¿€ìŠ¤í…Œì´ RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„', fontsize=16)\n",
    "        \n",
    "        # 1. ì²˜ë¦¬ ì‹œê°„ ë¶„í¬\n",
    "        axes[0, 0].hist(successful_tests['processing_time'], bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[0, 0].set_title('Processing Time Distribution')\n",
    "        axes[0, 0].set_xlabel('Processing Time (seconds)')\n",
    "        axes[0, 0].set_ylabel('Frequency')\n",
    "        \n",
    "        # 2. ì‹ ë¢°ë„ ë¶„í¬\n",
    "        axes[0, 1].hist(successful_tests['confidence_score'], bins=10, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "        axes[0, 1].set_title('Confidence Score Distribution')\n",
    "        axes[0, 1].set_xlabel('Confidence Score')\n",
    "        axes[0, 1].set_ylabel('Frequency')\n",
    "        \n",
    "        # 3. ë„ë©”ì¸ ì‚¬ìš© ìˆ˜ ë¶„í¬\n",
    "        domain_counts = successful_tests['domains_count'].value_counts().sort_index()\n",
    "        axes[0, 2].bar(domain_counts.index, domain_counts.values, color='orange', alpha=0.7)\n",
    "        axes[0, 2].set_title('Number of Domains Used')\n",
    "        axes[0, 2].set_xlabel('Number of Domains')\n",
    "        axes[0, 2].set_ylabel('Frequency')\n",
    "        \n",
    "        # 4. ì²˜ë¦¬ ì‹œê°„ vs ì‹ ë¢°ë„\n",
    "        axes[1, 0].scatter(successful_tests['processing_time'], successful_tests['confidence_score'], \n",
    "                          alpha=0.6, color='purple')\n",
    "        axes[1, 0].set_title('Processing Time vs Confidence')\n",
    "        axes[1, 0].set_xlabel('Processing Time (seconds)')\n",
    "        axes[1, 0].set_ylabel('Confidence Score')\n",
    "        \n",
    "        # 5. ì¶œì²˜ ìˆ˜ ë¶„í¬\n",
    "        axes[1, 1].hist(successful_tests['source_count'], bins=10, alpha=0.7, color='pink', edgecolor='black')\n",
    "        axes[1, 1].set_title('Source Count Distribution')\n",
    "        axes[1, 1].set_xlabel('Number of Sources')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        \n",
    "        # 6. ì„±ê³µ/ì‹¤íŒ¨ íŒŒì´ ì°¨íŠ¸\n",
    "        success_counts = self.df['success'].value_counts()\n",
    "        axes[1, 2].pie(success_counts.values, labels=['Success', 'Failure'], autopct='%1.1f%%',\n",
    "                      colors=['lightgreen', 'lightcoral'])\n",
    "        axes[1, 2].set_title('Success Rate')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def create_benchmark_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"ë²¤ì¹˜ë§ˆí¬ ìš”ì•½ ìƒì„±\"\"\"\n",
    "        if self.df.empty:\n",
    "            return {\"error\": \"ë°ì´í„° ì—†ìŒ\"}\n",
    "        \n",
    "        successful_tests = self.df[self.df['success'] == True]\n",
    "        \n",
    "        return {\n",
    "            \"system_info\": {\n",
    "                \"total_tests\": len(self.df),\n",
    "                \"successful_tests\": len(successful_tests),\n",
    "                \"success_rate\": len(successful_tests) / len(self.df) * 100 if len(self.df) > 0 else 0,\n",
    "                \"test_date\": datetime.now().isoformat()\n",
    "            },\n",
    "            \"performance_metrics\": {\n",
    "                \"avg_processing_time\": successful_tests['processing_time'].mean() if len(successful_tests) > 0 else 0,\n",
    "                \"max_processing_time\": successful_tests['processing_time'].max() if len(successful_tests) > 0 else 0,\n",
    "                \"min_processing_time\": successful_tests['processing_time'].min() if len(successful_tests) > 0 else 0,\n",
    "                \"std_processing_time\": successful_tests['processing_time'].std() if len(successful_tests) > 0 else 0\n",
    "            },\n",
    "            \"quality_metrics\": {\n",
    "                \"avg_confidence_score\": successful_tests['confidence_score'].mean() if len(successful_tests) > 0 else 0,\n",
    "                \"avg_source_count\": successful_tests['source_count'].mean() if len(successful_tests) > 0 else 0,\n",
    "                \"avg_answer_length\": successful_tests['answer_length'].mean() if len(successful_tests) > 0 else 0\n",
    "            },\n",
    "            \"component_status\": {\n",
    "                \"llm_available\": system_components[\"init_status\"].llm,\n",
    "                \"embeddings_available\": system_components[\"init_status\"].embeddings,\n",
    "                \"web_search_available\": system_components[\"init_status\"].web_search,\n",
    "                \"vectorstores_count\": sum(system_components[\"init_status\"].vectorstores.values()),\n",
    "                \"agents_count\": sum(system_components[\"init_status\"].agents.values())\n",
    "            }\n",
    "        }\n",
    "\n",
    "# ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰\n",
    "if comprehensive_results:\n",
    "    print(\"ðŸ“Š ì„±ëŠ¥ ë¶„ì„ ë° ë²¤ì¹˜ë§ˆí¬ ìƒì„± ì¤‘...\\n\")\n",
    "    \n",
    "    analyzer = PerformanceAnalyzer(comprehensive_results)\n",
    "    \n",
    "    # ì„±ëŠ¥ ë³´ê³ ì„œ ì¶œë ¥\n",
    "    performance_report = analyzer.generate_performance_report()\n",
    "    print(performance_report)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ“ˆ ì„±ëŠ¥ ì§€í‘œ ì‹œê°í™”:\")\n",
    "    \n",
    "    # ì„±ëŠ¥ ì°¨íŠ¸ ìƒì„±\n",
    "    analyzer.plot_performance_metrics(figsize=(16, 10))\n",
    "    \n",
    "    # ë²¤ì¹˜ë§ˆí¬ ìš”ì•½\n",
    "    benchmark_summary = analyzer.create_benchmark_summary()\n",
    "    \n",
    "    print(\"\\nðŸ“‹ ë²¤ì¹˜ë§ˆí¬ ìš”ì•½ (JSON):\")\n",
    "    print(json.dumps(benchmark_summary, indent=2, ensure_ascii=False))\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ë¶„ì„í•  í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ìƒì„¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í‘œì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒì„¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í‘œì‹œ\n",
    "if comprehensive_results:\n",
    "    print(\"ðŸ“‹ ìƒì„¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼\\n\")\n",
    "    \n",
    "    # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í‘œì‹œ\n",
    "    results_df = analyzer.df\n",
    "    \n",
    "    # ì£¼ìš” ì»¬ëŸ¼ë§Œ ì„ íƒí•´ì„œ í‘œì‹œ\n",
    "    display_columns = [\n",
    "        'test_id', 'question', 'success', 'selected_domains',\n",
    "        'processing_time', 'confidence_score', 'source_count'\n",
    "    ]\n",
    "    \n",
    "    display_df = results_df[display_columns].copy()\n",
    "    \n",
    "    # ì‹œê°„ í˜•ì‹ ì •ë¦¬\n",
    "    display_df['processing_time'] = display_df['processing_time'].round(2)\n",
    "    display_df['confidence_score'] = display_df['confidence_score'].round(2)\n",
    "    \n",
    "    print(\"ìƒìœ„ ê²°ê³¼:\")\n",
    "    display(display_df.head(10))\n",
    "    \n",
    "    # ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ì˜ ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°\n",
    "    print(\"\\nðŸ’¬ ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ì˜ ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    successful_results = [r for r in comprehensive_results if r.success]\n",
    "    \n",
    "    for i, result in enumerate(successful_results[:3], 1):  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ\n",
    "        print(f\"\\n{i}. ì§ˆë¬¸: {result.question}\")\n",
    "        print(f\"   ë„ë©”ì¸: {', '.join(result.selected_domains)}\")\n",
    "        print(f\"   ì²˜ë¦¬ì‹œê°„: {result.processing_time:.2f}ì´ˆ\")\n",
    "        print(f\"   ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "        \n",
    "        # ë‹µë³€ì„ 200ìžë¡œ ì œí•œí•˜ì—¬ í‘œì‹œ\n",
    "        answer_preview = result.answer[:200] + \"...\" if len(result.answer) > 200 else result.answer\n",
    "        print(f\"   {answer_preview}\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ë¶„ì„\n",
    "    failed_results = [r for r in comprehensive_results if not r.success]\n",
    "    if failed_results:\n",
    "        print(f\"\\nâŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ë¶„ì„ ({len(failed_results)}ê°œ):\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for i, result in enumerate(failed_results[:3], 1):  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ\n",
    "            print(f\"\\n{i}. ì§ˆë¬¸: {result.question}\")\n",
    "            print(f\"   ì˜¤ë¥˜: {result.error_message or 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}\")\n",
    "            print(f\"   ì²˜ë¦¬ì‹œê°„: {result.processing_time:.2f}ì´ˆ\")\n",
    "            print(\"-\" * 60)\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ í‘œì‹œí•  í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì‹œìŠ¤í…œ ìƒíƒœ ë° ë°°í¬ ì¤€ë¹„ë„ ì ê²€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeploymentReadinessChecker:\n",
    "    \"\"\"ë°°í¬ ì¤€ë¹„ë„ ì ê²€ê¸°\"\"\"\n",
    "    \n",
    "    def __init__(self, init_status: SystemInitStatus, test_results: List[PipelineTestResult]):\n",
    "        self.init_status = init_status\n",
    "        self.test_results = test_results\n",
    "    \n",
    "    def check_component_readiness(self) -> Dict[str, Dict[str, Any]]:\n",
    "        \"\"\"ì»´í¬ë„ŒíŠ¸ë³„ ì¤€ë¹„ ìƒíƒœ ì ê²€\"\"\"\n",
    "        \n",
    "        checks = {\n",
    "            \"core_components\": {\n",
    "                \"llm_available\": {\n",
    "                    \"status\": self.init_status.llm,\n",
    "                    \"importance\": \"Critical\",\n",
    "                    \"description\": \"OpenAI GPT-4o-mini ì–¸ì–´ ëª¨ë¸\"\n",
    "                },\n",
    "                \"embeddings_available\": {\n",
    "                    \"status\": self.init_status.embeddings,\n",
    "                    \"importance\": \"Critical\",\n",
    "                    \"description\": \"Ollama bge-m3 ìž„ë² ë”© ëª¨ë¸\"\n",
    "                },\n",
    "                \"web_search_available\": {\n",
    "                    \"status\": self.init_status.web_search,\n",
    "                    \"importance\": \"Optional\",\n",
    "                    \"description\": \"Tavily API ì›¹ ê²€ìƒ‰ ë„êµ¬\"\n",
    "                }\n",
    "            },\n",
    "            \"data_components\": {},\n",
    "            \"agent_components\": {}\n",
    "        }\n",
    "        \n",
    "        # ë²¡í„° ì €ìž¥ì†Œ ì ê²€\n",
    "        for domain, status in self.init_status.vectorstores.items():\n",
    "            checks[\"data_components\"][f\"{domain}_vectorstore\"] = {\n",
    "                \"status\": status,\n",
    "                \"importance\": \"High\" if domain in [\"hr_policy\", \"tech_policy\"] else \"Medium\",\n",
    "                \"description\": f\"{domain} ë„ë©”ì¸ ë²¡í„° ì €ìž¥ì†Œ\"\n",
    "            }\n",
    "        \n",
    "        # ì—ì´ì „íŠ¸ ì ê²€\n",
    "        for domain, status in self.init_status.agents.items():\n",
    "            checks[\"agent_components\"][f\"{domain}_agent\"] = {\n",
    "                \"status\": status,\n",
    "                \"importance\": \"High\" if domain in [\"hr_policy\", \"tech_policy\"] else \"Medium\",\n",
    "                \"description\": f\"{domain} ë„ë©”ì¸ RAG ì—ì´ì „íŠ¸\"\n",
    "            }\n",
    "        \n",
    "        return checks\n",
    "    \n",
    "    def check_performance_readiness(self) -> Dict[str, Any]:\n",
    "        \"\"\"ì„±ëŠ¥ ì¤€ë¹„ ìƒíƒœ ì ê²€\"\"\"\n",
    "        if not self.test_results:\n",
    "            return {\n",
    "                \"test_coverage\": False,\n",
    "                \"success_rate\": 0.0,\n",
    "                \"avg_processing_time\": 0.0,\n",
    "                \"performance_acceptable\": False\n",
    "            }\n",
    "        \n",
    "        successful_tests = [r for r in self.test_results if r.success]\n",
    "        success_rate = len(successful_tests) / len(self.test_results) * 100\n",
    "        \n",
    "        avg_processing_time = 0.0\n",
    "        if successful_tests:\n",
    "            avg_processing_time = sum(r.processing_time for r in successful_tests) / len(successful_tests)\n",
    "        \n",
    "        return {\n",
    "            \"test_coverage\": len(self.test_results) >= 5,  # ìµœì†Œ 5ê°œ í…ŒìŠ¤íŠ¸\n",
    "            \"success_rate\": success_rate,\n",
    "            \"avg_processing_time\": avg_processing_time,\n",
    "            \"performance_acceptable\": success_rate >= 80 and avg_processing_time <= 10.0  # 80% ì„±ê³µë¥ , 10ì´ˆ ì´ë‚´\n",
    "        }\n",
    "    \n",
    "    def generate_readiness_report(self) -> str:\n",
    "        \"\"\"ë°°í¬ ì¤€ë¹„ë„ ë³´ê³ ì„œ ìƒì„±\"\"\"\n",
    "        component_checks = self.check_component_readiness()\n",
    "        performance_checks = self.check_performance_readiness()\n",
    "        \n",
    "        report = []\n",
    "        report.append(\"ðŸš€ ê¿€ìŠ¤í…Œì´ RAG ì‹œìŠ¤í…œ ë°°í¬ ì¤€ë¹„ë„ ì ê²€\")\n",
    "        report.append(\"=\" * 60)\n",
    "        \n",
    "        # ì „ì²´ ì ìˆ˜ ê³„ì‚°\n",
    "        total_components = 0\n",
    "        ready_components = 0\n",
    "        critical_ready = 0\n",
    "        critical_total = 0\n",
    "        \n",
    "        # ì»´í¬ë„ŒíŠ¸ë³„ ì ê²€ ê²°ê³¼\n",
    "        for category, components in component_checks.items():\n",
    "            report.append(f\"\\nðŸ“Š {category.replace('_', ' ').title()}:\")\n",
    "            \n",
    "            for comp_name, comp_info in components.items():\n",
    "                status_icon = \"âœ…\" if comp_info[\"status\"] else \"âŒ\"\n",
    "                importance = comp_info[\"importance\"]\n",
    "                description = comp_info[\"description\"]\n",
    "                \n",
    "                report.append(f\"   {status_icon} {comp_name}: {description} ({importance})\")\n",
    "                \n",
    "                total_components += 1\n",
    "                if comp_info[\"status\"]:\n",
    "                    ready_components += 1\n",
    "                \n",
    "                if importance == \"Critical\":\n",
    "                    critical_total += 1\n",
    "                    if comp_info[\"status\"]:\n",
    "                        critical_ready += 1\n",
    "        \n",
    "        # ì„±ëŠ¥ ì ê²€ ê²°ê³¼\n",
    "        report.append(f\"\\nðŸŽ¯ ì„±ëŠ¥ ì ê²€:\")\n",
    "        report.append(f\"   {'âœ…' if performance_checks['test_coverage'] else 'âŒ'} í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€: {len(self.test_results)}ê°œ í…ŒìŠ¤íŠ¸\")\n",
    "        report.append(f\"   {'âœ…' if performance_checks['success_rate'] >= 80 else 'âŒ'} ì„±ê³µë¥ : {performance_checks['success_rate']:.1f}% (ëª©í‘œ: â‰¥80%)\")\n",
    "        report.append(f\"   {'âœ…' if performance_checks['avg_processing_time'] <= 10.0 else 'âŒ'} í‰ê·  ì²˜ë¦¬ì‹œê°„: {performance_checks['avg_processing_time']:.2f}ì´ˆ (ëª©í‘œ: â‰¤10ì´ˆ)\")\n",
    "        \n",
    "        # ì „ì²´ ì¤€ë¹„ë„ ê³„ì‚°\n",
    "        component_readiness = (ready_components / total_components * 100) if total_components > 0 else 0\n",
    "        critical_readiness = (critical_ready / critical_total * 100) if critical_total > 0 else 0\n",
    "        \n",
    "        report.append(f\"\\nðŸ“ˆ ì „ì²´ ì¤€ë¹„ë„:\")\n",
    "        report.append(f\"   - ì „ì²´ ì»´í¬ë„ŒíŠ¸: {ready_components}/{total_components} ({component_readiness:.1f}%)\")\n",
    "        report.append(f\"   - í•µì‹¬ ì»´í¬ë„ŒíŠ¸: {critical_ready}/{critical_total} ({critical_readiness:.1f}%)\")\n",
    "        report.append(f\"   - ì„±ëŠ¥ ì¤€ë¹„ë„: {'âœ…' if performance_checks['performance_acceptable'] else 'âŒ'}\")\n",
    "        \n",
    "        # ë°°í¬ ê¶Œìž¥ì‚¬í•­\n",
    "        report.append(f\"\\nðŸŽ¯ ë°°í¬ ê¶Œìž¥ì‚¬í•­:\")\n",
    "        \n",
    "        if critical_readiness == 100 and performance_checks['performance_acceptable']:\n",
    "            report.append(\"   ðŸŸ¢ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ! í”„ë¡œë•ì…˜ í™˜ê²½ì— ë°°í¬í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\")\n",
    "        elif critical_readiness == 100:\n",
    "            report.append(\"   ðŸŸ¡ í•µì‹¬ ê¸°ëŠ¥ì€ ì¤€ë¹„ë˜ì—ˆìœ¼ë‚˜ ì„±ëŠ¥ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "            report.append(\"   ðŸ“ ê¶Œìž¥: ì„±ëŠ¥ íŠœë‹ í›„ ë°°í¬\")\n",
    "        elif critical_readiness >= 50:\n",
    "            report.append(\"   ðŸŸ  ì¼ë¶€ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            report.append(\"   ðŸ“ ê¶Œìž¥: ìŠ¤í…Œì´ì§• í™˜ê²½ì—ì„œ ì¶”ê°€ í…ŒìŠ¤íŠ¸\")\n",
    "        else:\n",
    "            report.append(\"   ðŸ”´ ë°°í¬ ì¤€ë¹„ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.\")\n",
    "            report.append(\"   ðŸ“ ê¶Œìž¥: í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ìˆ˜ì • í›„ ìž¬í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        # ê°œì„  í•­ëª©\n",
    "        improvements = []\n",
    "        \n",
    "        for category, components in component_checks.items():\n",
    "            for comp_name, comp_info in components.items():\n",
    "                if not comp_info[\"status\"] and comp_info[\"importance\"] in [\"Critical\", \"High\"]:\n",
    "                    improvements.append(f\"   - {comp_info['description']} í™œì„±í™” í•„ìš”\")\n",
    "        \n",
    "        if not performance_checks['performance_acceptable']:\n",
    "            if performance_checks['success_rate'] < 80:\n",
    "                improvements.append(\"   - ì„±ê³µë¥  í–¥ìƒ í•„ìš” (í˜„ìž¬: {:.1f}%, ëª©í‘œ: â‰¥80%)\".format(performance_checks['success_rate']))\n",
    "            if performance_checks['avg_processing_time'] > 10.0:\n",
    "                improvements.append(\"   - ì²˜ë¦¬ ì‹œê°„ ë‹¨ì¶• í•„ìš” (í˜„ìž¬: {:.2f}ì´ˆ, ëª©í‘œ: â‰¤10ì´ˆ)\".format(performance_checks['avg_processing_time']))\n",
    "        \n",
    "        if improvements:\n",
    "            report.append(f\"\\nðŸ”§ ê°œì„  í•„ìš” í•­ëª©:\")\n",
    "            report.extend(improvements)\n",
    "        \n",
    "        return \"\\n\".join(report)\n",
    "    \n",
    "    def get_deployment_score(self) -> float:\n",
    "        \"\"\"ë°°í¬ ì¤€ë¹„ë„ ì ìˆ˜ (0-100)\"\"\"\n",
    "        component_checks = self.check_component_readiness()\n",
    "        performance_checks = self.check_performance_readiness()\n",
    "        \n",
    "        # ì»´í¬ë„ŒíŠ¸ ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ì¹˜ ì ìš©)\n",
    "        component_score = 0.0\n",
    "        total_weight = 0.0\n",
    "        \n",
    "        for category, components in component_checks.items():\n",
    "            for comp_name, comp_info in components.items():\n",
    "                weight = 3.0 if comp_info[\"importance\"] == \"Critical\" else (\n",
    "                    2.0 if comp_info[\"importance\"] == \"High\" else 1.0\n",
    "                )\n",
    "                \n",
    "                if comp_info[\"status\"]:\n",
    "                    component_score += weight\n",
    "                total_weight += weight\n",
    "        \n",
    "        component_ratio = component_score / total_weight if total_weight > 0 else 0.0\n",
    "        \n",
    "        # ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°\n",
    "        performance_score = 0.0\n",
    "        if performance_checks['test_coverage']:\n",
    "            performance_score += 0.2\n",
    "        if performance_checks['success_rate'] >= 80:\n",
    "            performance_score += 0.4\n",
    "        if performance_checks['avg_processing_time'] <= 10.0:\n",
    "            performance_score += 0.4\n",
    "        \n",
    "        # ì „ì²´ ì ìˆ˜ (ì»´í¬ë„ŒíŠ¸ 70%, ì„±ëŠ¥ 30%)\n",
    "        total_score = (component_ratio * 0.7 + performance_score * 0.3) * 100\n",
    "        \n",
    "        return min(100.0, max(0.0, total_score))\n",
    "\n",
    "# ë°°í¬ ì¤€ë¹„ë„ ì ê²€\n",
    "if system_components[\"init_status\"] and comprehensive_results:\n",
    "    print(\"ðŸ” ë°°í¬ ì¤€ë¹„ë„ ì ê²€ ì¤‘...\\n\")\n",
    "    \n",
    "    readiness_checker = DeploymentReadinessChecker(\n",
    "        init_status=system_components[\"init_status\"],\n",
    "        test_results=comprehensive_results\n",
    "    )\n",
    "    \n",
    "    # ë°°í¬ ì¤€ë¹„ë„ ë³´ê³ ì„œ\n",
    "    readiness_report = readiness_checker.generate_readiness_report()\n",
    "    print(readiness_report)\n",
    "    \n",
    "    # ë°°í¬ ì ìˆ˜\n",
    "    deployment_score = readiness_checker.get_deployment_score()\n",
    "    \n",
    "    print(f\"\\nâ­ ìµœì¢… ë°°í¬ ì¤€ë¹„ë„ ì ìˆ˜: {deployment_score:.1f}/100ì \")\n",
    "    \n",
    "    # ì ìˆ˜ë³„ ê¶Œìž¥ì‚¬í•­\n",
    "    if deployment_score >= 90:\n",
    "        print(\"ðŸŸ¢ ìš°ìˆ˜! í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "    elif deployment_score >= 70:\n",
    "        print(\"ðŸŸ¡ ì–‘í˜¸! ì¼ë¶€ ê°œì„  í›„ ë°°í¬ ê°€ëŠ¥\")\n",
    "    elif deployment_score >= 50:\n",
    "        print(\"ðŸŸ  ë³´í†µ! ì£¼ìš” ê°œì„ ì‚¬í•­ í•´ê²° í•„ìš”\")\n",
    "    else:\n",
    "        print(\"ðŸ”´ ë¯¸í¡! ì „ë©´ì ì¸ ì‹œìŠ¤í…œ ì ê²€ í•„ìš”\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ë°°í¬ ì¤€ë¹„ë„ë¥¼ ì ê²€í•  ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ìµœì¢… ìš”ì•½ ë° ê¶Œìž¥ì‚¬í•­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_summary() -> str:\n",
    "    \"\"\"ìµœì¢… ìš”ì•½ ë³´ê³ ì„œ ìƒì„±\"\"\"\n",
    "    \n",
    "    current_time = datetime.now()\n",
    "    \n",
    "    summary = []\n",
    "    summary.append(\"ðŸ¯ ê¿€ìŠ¤í…Œì´ RAG ì‹œìŠ¤í…œ - ìµœì¢… í†µí•© í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ\")\n",
    "    summary.append(\"=\" * 80)\n",
    "    summary.append(f\"ðŸ“… í…ŒìŠ¤íŠ¸ ì™„ë£Œ ì‹œê°„: {current_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # ì‹œìŠ¤í…œ ê°œìš”\n",
    "    summary.append(f\"\\nðŸ—ï¸  ì‹œìŠ¤í…œ ê°œìš”:\")\n",
    "    summary.append(f\"   - ì•„í‚¤í…ì²˜: Multi-Agent RAG with Human-in-the-Loop\")\n",
    "    summary.append(f\"   - ë„ë©”ì¸: 7ê°œ ì „ë¬¸ ë„ë©”ì¸ + ì›¹ ê²€ìƒ‰\")\n",
    "    summary.append(f\"   - í•µì‹¬ ê¸°ìˆ : LangChain, LangGraph, ChromaDB, OpenAI GPT-4o-mini\")\n",
    "    summary.append(f\"   - ìž„ë² ë”©: Ollama bge-m3 (ë‹¤êµ­ì–´ ì§€ì›)\")\n",
    "    \n",
    "    # êµ¬í˜„ ì™„ë£Œ í˜„í™©\n",
    "    summary.append(f\"\\nâœ… êµ¬í˜„ ì™„ë£Œ í˜„í™©:\")\n",
    "    summary.append(f\"   ðŸ“ 01_data_processing: ë¬¸ì„œ ë¡œë”© ë° ì²­í‚¹ ì‹œìŠ¤í…œ\")\n",
    "    summary.append(f\"   ðŸ“Š 02_vector_stores: ë„ë©”ì¸ë³„ ë…ë¦½ ë²¡í„° ì €ìž¥ì†Œ\")\n",
    "    summary.append(f\"   ðŸ¤– 03_agents_development: Corrective RAG ì—ì´ì „íŠ¸ (8ê°œ)\")\n",
    "    summary.append(f\"   ðŸ§­ 04_routing_integration: ì§ˆë¬¸ ë¼ìš°íŒ… ë° ë‹µë³€ í†µí•©\")\n",
    "    summary.append(f\"   ðŸ§‘â€âš–ï¸ 05_hitl_evaluation: ReAct í‰ê°€ ë° HITL ì‹œìŠ¤í…œ\")\n",
    "    summary.append(f\"   ðŸš€ 99_full_pipeline_test: ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸\")\n",
    "    \n",
    "    # í•µì‹¬ ê¸°ëŠ¥\n",
    "    summary.append(f\"\\nðŸŽ¯ í•µì‹¬ ê¸°ëŠ¥:\")\n",
    "    summary.append(f\"   ðŸ” ì§€ëŠ¥í˜• ì§ˆë¬¸ ë¶„ì„ ë° ë„ë©”ì¸ ë¼ìš°íŒ…\")\n",
    "    summary.append(f\"   ðŸ“š ë„ë©”ì¸ë³„ ì „ë¬¸ ì§€ì‹ ê²€ìƒ‰ (7ê°œ ë„ë©”ì¸)\")\n",
    "    summary.append(f\"   ðŸ”„ Corrective RAG (ìžê°€êµì • ë©”ì»¤ë‹ˆì¦˜)\")\n",
    "    summary.append(f\"   ðŸŒ ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ í†µí•© (Tavily API)\")\n",
    "    summary.append(f\"   ðŸ§  ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ë‹µë³€ í†µí•©\")\n",
    "    summary.append(f\"   âš–ï¸ 6ì°¨ì› í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ (60ì  ë§Œì )\")\n",
    "    summary.append(f\"   ðŸ‘¥ Human-in-the-Loop í’ˆì§ˆ ê²€ì¦\")\n",
    "    summary.append(f\"   ðŸ“Š ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\")\n",
    "    \n",
    "    # ì‹œìŠ¤í…œ í˜„í™©\n",
    "    if system_components[\"init_status\"]:\n",
    "        init_status = system_components[\"init_status\"]\n",
    "        overall_status = init_status.overall_status()\n",
    "        \n",
    "        summary.append(f\"\\nðŸ“Š ì‹œìŠ¤í…œ í˜„í™©:\")\n",
    "        summary.append(f\"   - ì „ì²´ ì´ˆê¸°í™” ì„±ê³µë¥ : {overall_status:.1f}%\")\n",
    "        summary.append(f\"   - LLM (GPT-4o-mini): {'âœ…' if init_status.llm else 'âŒ'}\")\n",
    "        summary.append(f\"   - ìž„ë² ë”© (bge-m3): {'âœ…' if init_status.embeddings else 'âŒ'}\")\n",
    "        summary.append(f\"   - ì›¹ ê²€ìƒ‰ (Tavily): {'âœ…' if init_status.web_search else 'âŒ'}\")\n",
    "        summary.append(f\"   - ë²¡í„° ì €ìž¥ì†Œ: {sum(init_status.vectorstores.values())}/7ê°œ\")\n",
    "        summary.append(f\"   - RAG ì—ì´ì „íŠ¸: {sum(init_status.agents.values())}/8ê°œ\")\n",
    "    \n",
    "    # ì„±ëŠ¥ ê²°ê³¼\n",
    "    if comprehensive_results:\n",
    "        successful_tests = [r for r in comprehensive_results if r.success]\n",
    "        success_rate = len(successful_tests) / len(comprehensive_results) * 100\n",
    "        \n",
    "        if successful_tests:\n",
    "            avg_time = sum(r.processing_time for r in successful_tests) / len(successful_tests)\n",
    "            avg_confidence = sum(r.confidence_score for r in successful_tests) / len(successful_tests)\n",
    "            \n",
    "            summary.append(f\"\\nðŸŽ¯ ì„±ëŠ¥ ê²°ê³¼:\")\n",
    "            summary.append(f\"   - ì´ í…ŒìŠ¤íŠ¸: {len(comprehensive_results)}ê°œ\")\n",
    "            summary.append(f\"   - ì„±ê³µë¥ : {success_rate:.1f}%\")\n",
    "            summary.append(f\"   - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.2f}ì´ˆ\")\n",
    "            summary.append(f\"   - í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.2f}\")\n",
    "            summary.append(f\"   - í‰ê·  ì¶œì²˜ ìˆ˜: {sum(r.source_count for r in successful_tests) / len(successful_tests):.1f}ê°œ\")\n",
    "    \n",
    "    # ë°°í¬ ì¤€ë¹„ë„\n",
    "    if 'readiness_checker' in locals():\n",
    "        deployment_score = readiness_checker.get_deployment_score()\n",
    "        summary.append(f\"\\nðŸš€ ë°°í¬ ì¤€ë¹„ë„: {deployment_score:.1f}/100ì \")\n",
    "        \n",
    "        if deployment_score >= 90:\n",
    "            summary.append(f\"   ðŸŸ¢ í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "        elif deployment_score >= 70:\n",
    "            summary.append(f\"   ðŸŸ¡ ì¼ë¶€ ê°œì„  í›„ ë°°í¬ ê°€ëŠ¥\")\n",
    "        elif deployment_score >= 50:\n",
    "            summary.append(f\"   ðŸŸ  ì£¼ìš” ê°œì„ ì‚¬í•­ í•´ê²° í•„ìš”\")\n",
    "        else:\n",
    "            summary.append(f\"   ðŸ”´ ì „ë©´ì ì¸ ì‹œìŠ¤í…œ ì ê²€ í•„ìš”\")\n",
    "    \n",
    "    # ì°¨ë³„í™” ìš”ì†Œ\n",
    "    summary.append(f\"\\nðŸŒŸ ì°¨ë³„í™” ìš”ì†Œ:\")\n",
    "    summary.append(f\"   ðŸŽ¯ ë„ë©”ì¸ë³„ ì „ë¬¸í™”: ê° ë„ë©”ì¸ì— íŠ¹í™”ëœ RAG ì—ì´ì „íŠ¸\")\n",
    "    summary.append(f\"   ðŸ”„ ìžê°€êµì • ì‹œìŠ¤í…œ: Corrective RAGë¡œ ë‹µë³€ í’ˆì§ˆ ìžë™ ê°œì„ \")\n",
    "    summary.append(f\"   ðŸ‘¥ í’ˆì§ˆ ë³´ì¦: AI+ì¸ê°„ ì´ì¤‘ ê²€ì¦ ì‹œìŠ¤í…œ\")\n",
    "    summary.append(f\"   ðŸ§  ì§€ëŠ¥í˜• ë¼ìš°íŒ…: ì§ˆë¬¸ ë‚´ìš© ê¸°ë°˜ ìµœì  ì—ì´ì „íŠ¸ ì„ íƒ\")\n",
    "    summary.append(f\"   ðŸ“Š ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§: ì„±ëŠ¥ ë° í’ˆì§ˆ ì§€í‘œ ì¶”ì \")\n",
    "    summary.append(f\"   ðŸŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: ë‚´ë¶€ ë¬¸ì„œ + ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰\")\n",
    "    \n",
    "    # í–¥í›„ ê°œì„ ì‚¬í•­\n",
    "    summary.append(f\"\\nðŸ”§ ê¶Œìž¥ ê°œì„ ì‚¬í•­:\")\n",
    "    summary.append(f\"   ðŸ“ˆ ì„±ëŠ¥ ìµœì í™”: ë³‘ë ¬ ì²˜ë¦¬ ë° ìºì‹± ê°œì„ \")\n",
    "    summary.append(f\"   ðŸŽ¨ UI/UX ê°œë°œ: Streamlit ì›¹ ì•± ê³ ë„í™”\")\n",
    "    summary.append(f\"   ðŸ”’ ë³´ì•ˆ ê°•í™”: API í‚¤ ê´€ë¦¬ ë° ì•¡ì„¸ìŠ¤ ì œì–´\")\n",
    "    summary.append(f\"   ðŸ“Š ë¶„ì„ ê³ ë„í™”: ì‚¬ìš©ìž í”¼ë“œë°± ê¸°ë°˜ í•™ìŠµ\")\n",
    "    summary.append(f\"   ðŸŒ ë‹¤êµ­ì–´ ì§€ì›: ì˜ì–´ ë¬¸ì„œ ë° ì§ˆë¬¸ ì²˜ë¦¬\")\n",
    "    summary.append(f\"   ðŸ“± ëª¨ë°”ì¼ ìµœì í™”: ë°˜ì‘í˜• ì›¹ ì¸í„°íŽ˜ì´ìŠ¤\")\n",
    "    \n",
    "    # ê²°ë¡ \n",
    "    summary.append(f\"\\nðŸŽ‰ ê²°ë¡ :\")\n",
    "    summary.append(f\"ê¿€ìŠ¤í…Œì´ RAG ì‹œìŠ¤í…œì€ Multi-Agent ì•„í‚¤í…ì²˜ì™€ Human-in-the-Loop í’ˆì§ˆ ê²€ì¦ì„\")\n",
    "    summary.append(f\"í†µí•©í•œ ì°¨ì„¸ëŒ€ ê¸°ì—…ìš© ì§€ì‹ ê²€ìƒ‰ ì‹œìŠ¤í…œìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    summary.append(f\"ë„ë©”ì¸ë³„ ì „ë¬¸í™”, Corrective RAG, ì‹¤ì‹œê°„ í’ˆì§ˆ í‰ê°€ ë“±ì˜ í˜ì‹ ì  ê¸°ëŠ¥ì„\")\n",
    "    summary.append(f\"í†µí•´ ê¸°ì¡´ RAG ì‹œìŠ¤í…œ ëŒ€ë¹„ ë†’ì€ ì •í™•ì„±ê³¼ ì‹ ë¢°ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    summary.append(f\"\\nâœ¨ ì´ ì‹œìŠ¤í…œì€ ê¸°ì—…ì˜ ë‚´ë¶€ ì§€ì‹ ê´€ë¦¬ì™€ ì§ì› ì§ˆì˜ì‘ë‹µì„ í˜ì‹ í•  ìˆ˜ ìžˆëŠ”\")\n",
    "    summary.append(f\"ê°•ë ¥í•œ ë„êµ¬ë¡œ, ì§€ì†ì ì¸ í•™ìŠµê³¼ ê°œì„ ì„ í†µí•´ ë”ìš± ë°œì „í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    return \"\\n\".join(summary)\n",
    "\n",
    "# ìµœì¢… ìš”ì•½ ë³´ê³ ì„œ ì¶œë ¥\n",
    "print(\"ðŸ“„ ìµœì¢… ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ì¤‘...\\n\")\n",
    "\n",
    "final_summary_report = generate_final_summary()\n",
    "print(final_summary_report)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì™„ë£Œ ë©”ì‹œì§€\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŽŠ ê¿€ìŠ¤í…Œì´ RAG ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ðŸŽŠ\")\n",
    "print(f\"â° í…ŒìŠ¤íŠ¸ ì†Œìš” ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"ðŸš€ ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ êµ¬ì¶•ë˜ê³  í…ŒìŠ¤íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ìž¥ (ì„ íƒì‚¬í•­)\n",
    "\n",
    "### ì™„ë£Œëœ ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ì»´í¬ë„ŒíŠ¸\n",
    "\n",
    "âœ… **01_data_processing.ipynb**\n",
    "- ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ë¡œë”© ë° íŒŒì‹±\n",
    "- í—¤ë” ê¸°ë°˜ ì§€ëŠ¥í˜• ì²­í‚¹\n",
    "- ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ë° í’ˆì§ˆ ë¶„ì„\n",
    "\n",
    "âœ… **02_vector_stores.ipynb**  \n",
    "- 7ê°œ ë„ë©”ì¸ë³„ ë…ë¦½ ChromaDB êµ¬ì¶•\n",
    "- bge-m3 ìž„ë² ë”© ëª¨ë¸ í†µí•©\n",
    "- ê²€ìƒ‰ ì„±ëŠ¥ ìµœì í™” ë° í…ŒìŠ¤íŠ¸\n",
    "\n",
    "âœ… **03_agents_development.ipynb**\n",
    "- Corrective RAG ë©”ì»¤ë‹ˆì¦˜\n",
    "- 8ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ (7ê°œ ë„ë©”ì¸ + ì›¹ê²€ìƒ‰)\n",
    "- 4ì°¨ì› í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ\n",
    "\n",
    "âœ… **04_routing_integration.ipynb**\n",
    "- AI ê¸°ë°˜ ì§ˆë¬¸ ë¶„ì„ ë° ë„ë©”ì¸ ë¶„ë¥˜\n",
    "- ë©€í‹° ì—ì´ì „íŠ¸ ë‹µë³€ í†µí•©\n",
    "- LangGraph ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜\n",
    "\n",
    "âœ… **05_hitl_evaluation.ipynb**\n",
    "- ReAct ê¸°ë°˜ 6ì°¨ì› í‰ê°€ (60ì  ë§Œì )\n",
    "- ì¸í„°ëŸ½íŠ¸ ê¸°ë°˜ Human-in-the-Loop\n",
    "- ì‹¤ì‹œê°„ í”¼ë“œë°± ìˆ˜ì§‘ ë° ë¶„ì„\n",
    "\n",
    "âœ… **99_full_pipeline_test.ipynb** (í˜„ìž¬)\n",
    "- ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸\n",
    "- ì¢…í•© ì„±ëŠ¥ ë¶„ì„ ë° ë²¤ì¹˜ë§ˆí¬\n",
    "- ë°°í¬ ì¤€ë¹„ë„ ì ê²€\n",
    "\n",
    "### ðŸŽ¯ ì‹œìŠ¤í…œ í•µì‹¬ íŠ¹ì§•\n",
    "\n",
    "1. **Multi-Agent RAG**: ë„ë©”ì¸ë³„ ì „ë¬¸í™”ëœ 8ê°œ ì—ì´ì „íŠ¸\n",
    "2. **Corrective RAG**: ìžê°€êµì • ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ í’ˆì§ˆ ìžë™ ê°œì„ \n",
    "3. **Human-in-the-Loop**: AI+ì¸ê°„ ì´ì¤‘ ê²€ì¦ í’ˆì§ˆ ë³´ì¦\n",
    "4. **Intelligent Routing**: ì§ˆë¬¸ ë‚´ìš© ê¸°ë°˜ ìµœì  ì—ì´ì „íŠ¸ ì„ íƒ\n",
    "5. **Real-time Monitoring**: ì„±ëŠ¥ ë° í’ˆì§ˆ ì§€í‘œ ì‹¤ì‹œê°„ ì¶”ì \n",
    "6. **Hybrid Search**: ë‚´ë¶€ ë¬¸ì„œ + ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰\n",
    "\n",
    "### ðŸš€ ì°¨ì„¸ëŒ€ ê¸°ì—…ìš© RAG ì‹œìŠ¤í…œ ì™„ì„±!\n",
    "\n",
    "ê¿€ìŠ¤í…Œì´ RAG ì‹œìŠ¤í…œì€ ê¸°ì¡´ RAGì˜ í•œê³„ë¥¼ ë›°ì–´ë„˜ì–´ **ë„ë©”ì¸ ì „ë¬¸í™”**, **í’ˆì§ˆ ë³´ì¦**, **ì§€ëŠ¥í˜• ë¼ìš°íŒ…**ì„ í†µí•´ ê¸°ì—…ìš© ì§€ì‹ ê²€ìƒ‰ì˜ ìƒˆë¡œìš´ í‘œì¤€ì„ ì œì‹œí•©ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}